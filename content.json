{"pages":[],"posts":[{"title":"D3笔记","text":"loading data onto the page 123456waitSeconds=numSeconds=&gt;new Promise(resolve=&gt;{ const message=`${numSeconds} seconds have passed!`; setTimeout(()=&gt;resolve(message),numSeconds*1000);})waitSeconds(2).then(message=&gt;console.log(message)); 结果：等待两秒后显示 2 seconds have passed! ECMAScript 6 FeaturesHTML CSS SVGScalable Vector Graph 1import{select,arc} from 'd3' 12345678910111213141516const width=+svg.attr('width') //string转换为floatconst width=parseFloat(svg.attr('width'))const circle=svg.append('circle') .attr('fill','yellow') .attr('stroke','black')const g=svg.append('g') .attr('transform','translate(${width/2},${height/2})');const mouth=svg.append('path') .attr('d',acr()({ innerRadius:80, outerRadius:100, startAngle:Math.PI/2, endAngle:Math,PI*3/2 })); d3csv comma seperated value customizing axisd3.format() 函数","link":"/2020/04/03/D3%E7%AC%94%E8%AE%B0/"},{"title":"gitbook+Typora打造舒适的笔记环境","text":"gitbook上手GitBook 是一个基于 Node.js 的命令行工具，可使用它来制作精美的电子书。gitbook简洁而且高效，能够用一种结构化的方式组织文章或者笔记，所以不管是学习的输入还是撰写文章的输出，gitbook都不失为一个很好的工具。 网上关于如何安装gitbook的文章有很多，此处不进行总结了。 为什么用Typora？Typora可以支持实时预览，比起印象笔记等分屏的markdown写作工具,Typora这种所见即所得的极简给做笔记或者写作带来的体验感是非常强的。Typora的大部分语言都是传统markdown，使用Typora在官网下载对应版本即可 。 emoji的使用方法，这个我之前不知道，是无意中触发的： 只要用:emoji-name:的形式就可以插入emoji，通常一个冒号后面加字母就会自动提示emoji了。 :accept::clinking_glasses::v::ok::zap: gitbook 常用命令1.gitbook init这个命令会在指定文件夹创建README.md和SUMMARY.md。 2.gitbook build运行该命令后会在书籍的文件夹中生成一个 _book 文件夹, 里面的内容即为生成的 html 文件,可以将这个文件发布自己到github的仓库中，可以作为项目的文档或者其他笔记等，使用nameofUser.github.io/nameofRepository域名就可以访问到在线笔记。 注意如果是一个有其他文件的仓库的话，需要在git中创建docs分支，然后将_book的内容传入该仓库的该分支中才能够访问。 3.gitbook serve这一命令能够让我们在浏览器预览gitbook，通常能够在http://localhost:4000 预览。 常用插件gitbook支持很多插件，能够更方便地帮助你使用gitbook。插件安装时需要在gitbook所在根目录下新建book.json， 并按照下面的配置进行修改或创建，最后使用gitbook install命令将对应的node_modules下载。 显示文章目录：toc一般来说如果想要显示文章目录的话，在Typora中可以在文章最开始加入[toc]，Typora就能够自动生成对应目录，但这个目录无法在gitbook中显示，这个插件让文档能够插入目录，在浏览器显示时也能够看见目录。 1234567891011{ \"plugins\" : [ \"toc\", ], \"pluginsConfig\": { \"toc\": { \"addClass\": true, \"className\": \"toc\" } }} 需要目录时须在文章开始添加&lt;!-- toc --&gt;，这样才会显示目录。 总目录折叠：expandable-chapters这个插件使目录具有折叠功能。 12345{ \"plugins\" : [ \"expandable-chapters\" ]} ！这里将不断继续更新 ！","link":"/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/"},{"title":"2019川大新生数据可视化（python wordcloud + echarts）","text":"8月底和同学一起为川大新生制作了一个新生数据可视化的推送。这篇推送中插入的图片，主要使用了python的wordcloud制作词云，用echarts中的一些图表。这篇博客主要会记录一下我制作的部分。 一、wordcloud制作姓名词云1.Anaconda下安装wordcloud模块如果没有安装wordcloud，可以在官网下载whl文件。下载好文件后，使用Anconda命令行，切到whl所在的文件目录，输入命令行：pip install wordcloud-1.5.0-cp36-cp36m-win_amd64.whl，然后安装成功后就可导入该模块了。 2.导入模块要制作词云，主要需导入wordcloud,matplotlib这两个模块。 1234567#!/usr/bin/python# -*- coding: UTF-8 -*-#导入wordcloud模块和matplotlib模块from wordcloud import WordCloud,ImageColorGenerator,STOPWORDSimport matplotlib.pyplot as pltfrom scipy.misc import imreadimport chardet 3. 处理数据由于当时得到的excel表格中，学生包括新疆、西藏等民族，姓名不是普通的姓+名的结构，给姓名的处理带来了一定困难。因此没有统计他们的姓氏。当时不了解python也可以处理excel，于是是将姓名按行存入一个txt文件，再通过python进行处理。 1） 处理名字123456789101112131415161718192021222324252627282930313233#读取原始的姓名txt文件fileObj = open('name4.txt','r',encoding='UTF-8-sig')ming=[]#按行读取,姓名是三个字的同学的姓删除line=fileObj.readline()while line: line=line.strip('\\n') if (len(line)&lt;=4 and len(line)&gt;0): line=line.replace(line[0],\"\") ming.append(line) line=fileObj.readline()m=\"\".join(ming)print(ming)fileObj2 = open('ming.txt', 'w', encoding='utf-8')fileObj2.write(m)fileObj2.close()# 姓名全部以单字形式排列，并存入新的文档name=open('ming.txt','r',encoding='UTF-8').read()name=name.replace('·','')name=name.replace('\\n','')result=[]for i in name: result.append(i) result.append(\" \")s = \"\".join(result) #列表转字符串save = open('name7.txt', 'w', encoding='utf-8')save.write(s)save.close() 得到处理的结果： 2）处理姓氏12345678910111213141516# 姓fileObj = open('name4.txt','r',encoding='UTF-8-sig')surname=[]line=fileObj.readline()while line: line=line.strip('\\n') if (len(line)&lt;=4 and len(line)&gt;0): surname.append(line[0]) surname.append(\" \") line=fileObj.readline()sur=\"\".join(surname)print(surname)fileObj2 = open('surname.txt', 'w', encoding='utf-8')fileObj2.write(sur)fileObj2.close() 得到处理的结果： 4.生成词云处理完名和姓的结果后，就可以使用wordcloud函数来绘制词云。当时遇到了一个问题就是词云只能生成两个字及以上的词云，对于单个字会认为这不是一个词。解决办法是修改参数中的regexp（正则表达式）有regexp=r&quot;\\w[\\w']*&quot;，这样wordcloud就会将单字也认为是词，从而生成字云。除此之外还使用到了以下几个参数： mask：设置为pic是为了让生成的词云具有图片的形状。#FFFFFF是不会显示字的，因此如果画面背景不是纯白也会显示字。prefer_horizontal： 这个属性是让竖直的字的出现概率为1，因此词云的所有字都是竖直排列的，可读性会更强。background_color=None和mode=’RGBA’ ：这两个一起设置，能够让图片的背景是透明的。（这里主要是需要和美工交接，让她帮忙上一个底色）stopwords：停止词，因为处理数据是先生成了姓，因此当时考虑将姓作为停止词（也就是不会出现在词云上），但鉴于有些姓同样会出现在名字中，会影响准确性，因此并没有这样做。 123456789101112131415161718#读入处理过的姓名文件text2= open('name7.txt','r',encoding='UTF-8').read()#读入背景图片pic = imread('panda16.png')#生成词云cloud = WordCloud(mask=pic,prefer_horizontal=1,#width=800,height=800, font_path='C:\\\\Windows\\\\Fonts\\\\Nk728iWCZ.TTF', background_color=None,scale=5,regexp=r\"\\w[\\w']*\", max_font_size = 100,mode='RGBA') #,stopwords=stop)cloud.generate(text2)image_colors = ImageColorGenerator(pic)cloud.recolor(color_func=image_colors)#显示词云图片plt.imshow(cloud)plt.axis('off')plt.show()#保存图片cloud.to_file('test26.png') 最后生成的词云如下： 二、用Python处理数据除了用python处理词云之外，python还用于处理一些数据，比如将数据从excel格式调成json格式(便于echarts使用）。当然，当时我python处理excel文件还不太熟，因此整个处理数据（包括年龄、星座等制作后面的表格时使用到的数据）的步骤可以归纳为以下的几点：1.在excel中用数据透视表进行统计，然后将得到的结果以txt文本保存。2.在notepad进行简单的查找替换，将文件编码设置为utf-8。3.转化为json数组时通过python读取txt文件，然后对其进行相应的处理，得到符合要求的json数组。（当然后续知道可以直接在excel中转json，不过写数据处理的代码也算是让我更熟悉了python) 这里放部分的代码： 1) 处理日期因为生日的日期有多种格式（斜杠、全数值、横杠），为了让他们格式相同，所以进行了处理。 12345678910111213141516171819while line: if(line.find('/')&gt;=0): print(line) line=line.replace('/','-') fileObj2.write(line) elif(line.find('-')&lt;0): line_list=[] line_list=list(line) line_list.insert(4,'-') print(line_list) line_list.insert(7,'-') print(line_list) newline=\"\".join(line_list) print(newline) fileObj2.write(newline) else: fileObj2.write(line) line=fileObj.readline()fileObj2.close() 2）其他数据转换成json数组这是用来生成桑基图中的links中的数组。 12345678910111213141516while line: index=line.find('\\n') blank=line.find(' ') line_list = list(line) line_list.insert(index+1,\"},\") line_list.insert(0,\"{ 'name':'\") line_list.insert(blank+2,\"',\\n\") line_list.insert(blank+3,\"value:\") print(line_list) #转回字符串 newline=''.join(line_list) print(newline) fileObj2.write(newline) line=fileObj.readline()fileObj2.close() 三、echarts制作其他图表1.矩形树图(Treemap)制作专业人数分布图在这张图中，主要通过矩形的大小来映射专业的人数多少。图片的尺寸考虑到看推送的清晰度问题，因此设置得较长。在做的时候，遇到的问题主要是字体不能够换行以及调整字体大小的问题。解决办法是用：series-&gt;upperLable-&gt;normal加入formatter: '{b}',，然后通过data中的name进行换行处理（由于矩形树图的特殊性，为了让排版更好看，手动对每一个需要换行的name进行了换行）。 series-&gt;levels中的两个元素分别表示的是学院层和学院下的专业层的不同设置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061var myChart = echarts.init(document.getElementById('treemap'));option = { series: [{ type: 'treemap', data: [ { name: '材料科学与工程学院', value: xxx, children: [{ name: '材料类', value: xx, }, { name: '生物医学工程', value: xx }] //每一个学院下的专业 }, ], upperLabel:{ normal:{ ellipsis:false, color: '#555', show:true, fontSize:10, fontWeight:'bold', formatter: '{b}', backgroundColor:'#e6eae3' } }, levels:[ { color:['#5bbdc8','#83ccd2','#7ebea5','#ffefa1'], itemStyle: { normal: { borderColor:'#e6eae3', borderWidth: 6, gapWidth: 5 } } }, { itemStyle: { normal: { borderColor:'#e6eae3', borderWidth: 4, gapWidth: 1 } } }, ], label:{ position:'insideLeft', ellipsis:false, color: '#555', fontWeight:'bold', fontSize:13, formatter:'{b}', } }]};myChart.setOption(option); 2.桑基图(Sankey)制作年龄流动图 从桑基图中，能够看到不同年龄占男女生总人数的比例，以及占学院总人数的比例。在制作桑基图时，主要遇到的问题是：年龄最小/大的人数过少，表现在echarts的图表中就会发现根本无法选中和显示出来，为了解决这个问题，将series-&gt;data-&gt;itemStyle-&gt;borderWidth中的数值改大（即增大边框宽度），这样就能够正常显示和交互了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778option = { series: { type: 'sankey', layout: 'none', layoutIterations: 0, nodeWidth: 30, nodeGap: 10, height: 300, focusNodeAdjacency: 'allEdges', orient: 'vertical', label: { show: true, position: 'bottom', //[-10,60], formatter: function(val) { //x轴的文字改为竖版显示 var str = val.name.split(\"\"); return str.join(\"\\n\"); }, }, data: [{ name: '14岁', itemStyle: { color: '#e95295', borderWidth: 6, borderColor: '#e95295', opacity: 1, }, }, //其余每一个年龄除了color的设置之外，其他都是相同的 { name: '材料科学与工程学院', itemStyle: { color: '#595857', borderWidth: 0, }, }, //其他所有学院的格式都如上所示 { name: '男', itemStyle: { color: '#595857', }, }, { name: '女', itemStyle: { color: '#595857', }, }], links: [{ source: '男', target: '15岁', value: 7, }, /*... 男和女两种性别和到每一个年龄的所有link 此处不公开数据*/ { source: '15岁', target: '材料科学与工程学院', value: 1 }, /*... 每一个年龄流动到每一个学院的所有link 此处不公开数据*/ ], lineStyle: { normal: { color: 'source', curveness: 0.75 } } },};// 使用刚指定的配置项和数据显示图表。myChart.setOption(option); 3.柱状图制作男女比例图柱状图制作的比较顺利。右侧的数值可以通过设置两个y轴来解决。另外，圆角的柱状图可以在series-&gt;itemStyle-&gt;barBorderRadius中设置圆角的半径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111var myChart = echarts.init(document.getElementById('gendermap'));option = { backgroundColor: '#fff', tooltip: { trigger: 'axis', axisPointer: {// 坐标轴指示器，坐标轴触发有效 type: 'shadow' // 默认为直线，可选为：'line'或'shadow' } }, legend: { data: ['男生', '女生'], }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, yAxis: [ { type: 'category', data: ['外国语学院', '文学与新闻学院', ...], /*这里存储的是图中左侧显示的每一个学院 为了减少篇幅就不写完了*/ splitLine: { show: true, ineStyle:{type:'dashed'} }, axisLine: { lineStyle: { color: '#000', } }, axisLabel: { color: '#000', fontSize:15 } }, { type: 'category', data: ['0.24:1',...], /*这里存储的是图中右边显示的所有的比例（用字符串存储） 为了减少篇幅就不写完了*/ text:'男女比', splitLine: { show: false }, axisLine: { lineStyle: { color: '#000', } }, axisLabel: { color: '#000', fontSize:15 } } ], xAxis: [ { show: false, type: 'value', } ], series : [ { name:'女生', type:'bar', stack: '总量', data:[], /*这里的data包括每一个学院的女生的数量 此处就不公开该数据了*/ itemStyle: { barBorderRadius: 20, //设置柱形的圆角，可以设置该半径 color: new echarts.graphic.LinearGradient(0, 0, 0, 1, [{ offset: 0.4, color: \"#ffefa1\" }, ]) }, }, { name:'男生', type:'bar', stack: '总量', data:[], /*这里的data包括每一个学院的男生的数量 需要将数量取成负数 这样能够让男女数量分布在坐标轴的两边（中轴对齐）*/ itemStyle: { barBorderRadius: 20, color: new echarts.graphic.LinearGradient(0, 0, 0, 1, [{ offset: 0.4, color: \"#5bbdc8\" }, ]) }, } ]};if (option &amp;&amp; typeof option === \"object\") { myChart.setOption(option, true);} 四、设计与配色使用了echarts和python，可视化看上去的确没有什么难度，但如果说要做出来能够放在推送上的视觉美观的作品，就不得不考虑设计和配色了。首先是两个姓氏和名字的词云，大川的美工小姐姐基于原图，帮我们画了底色，让整个图案变得更鲜明。其次，最初我们制作的图表的风格不统一，配色也非常混乱。在讨论后我们选择用了蓝色和黄色作为两种主色调。在这个基础上做好的图都要重新换一身衣服。当看到统一的配色的时候，风格自然地就融入在一起了。关于配色当时我们参考了一些网站，包括 配色方案，还有其他的一些网上常见的有RGB值的色卡，最后定下来颜色。 五、总结这个可视化推送我们断断续续做了一周左右。因为我python其实不算熟，做词云、数据处理的时候是边学边做，绕了不少弯路，配色那里也是反复修改，每张图都是十几稿，词云生成了差不多三十张（笑哭）。不过总算也将一个相对成熟的可视化作品完成了，3万点击量和很多令人感动的留言真的是让人成就感满满呐。还有一点我很惊讶，我司空见惯，甚至觉得有点难看的echarts，在不是计算机专业的美工看来非常稀奇，希望更多不是计算机的人也能使用这些可视化工具，如果这篇文章能有些帮助的话，那就太好了。","link":"/2019/09/09/2019%E5%B7%9D%E5%A4%A7%E6%96%B0%E7%94%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%88python-wordcloud-echarts%EF%BC%89/"},{"title":"git总结","text":"最近不知为什么git desktop崩了，遂重新使用命令行，总结一下git的相关命令。 本地库管理 切换到工作目录 将文件xxx（也可以添加文件夹）添加到仓库git add xxx 将文件提交到仓库git commit -m &quot;关于此次commit的描述&quot; 查看当前状态git status 查看修改内容 git diff 查看更新日志 git log 新建远程库 在github上创建仓库 切换到工作目录并与本地的库关联git remote add origin git@github.com:michaelliao/learngit.git 把本地库的内容推到远程库上（之后可以不用写-u)git push -u origin master 分支当使用github协同工作，使用分支可以使工作更加整洁。 切分支开发git的分支可以看作指向当前结点的指针，HEAD指针始终指向文件的最新的地方。 分支的创建：git branch branch1 分支的切换：git checkout branch1 分支切换意味着，如果在该分支上产生的所有改动add或commit都将是在该分支下。 分支的合并一、本地多个不同分支的合并本地有多个分支时，在branch1分支下，使用git merge branch2就会将branch2合并到branch1分支。 二、远程分支和本地分支的合并git pull拉取远程分之后直接与本地分支进行合并，其作用相当于git fetch和git merge 但是远程和本地合并时较长涉及到一致性的问题。 1.如果本地分支已有未提交的修改，此时又需要pull，可使用如下命令： 1）用git add将需要隐藏的文件保存在暂存区 2）隐藏本地分支工作：git stash save &quot;message&quot; 3）执行git pull命令，将远程分支下拉下来，此时不会出现冲突情况 4）使用git stash list可查看有哪些stash。使用git stash show stash@{num}可以看到第num-1个stash了存储了那些内容,默认是0号存储。 5） 若要恢复原来的文件，可使用git stash pop命令恢复。该命令会将缓存堆栈中的对应stash删除，并将对应修改应用到当前的工作目录下,默认为第一个stash。 6）若隐藏的文件可丢弃，则可使用git stash drop stash@{$num}丢弃该文件的内容。 注意，使用git stash后，暂存区的所有文件都会被隐藏，意味着如果再次进行git add 暂存区是不会有东西的，使用git commit也是无法提交更新的，只有恢复后才能解除文件的隐藏。 三、某个分支的diverged当出现了Your branch and origin/master have diverged,and have...different commits each respectively 此时可使用git rebase origin/master将分叉的分支重新合并。","link":"/2019/10/11/git%E6%80%BB%E7%BB%93/"},{"title":"hexo的坑和新博客","text":"hexo给一篇文章加多个tagstags:[‘a’,’b’] Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/03/31/hexo%E7%9A%84%E5%9D%91%E5%92%8C%E6%96%B0%E5%8D%9A%E5%AE%A2/"},{"title":"《JavaScript&jQuery 交互式Web前端开发》（一）","text":"一、基础知识1.什么是脚本？如何创建？脚本是一系列的指令，计算机执行后可达成目标 2.计算机如何融入它周围的世界中？window对象window对象的location属性告诉你当前页面的URL document对象属性title属性 告诉你web页面上title标签中的标题是什么lastModified属性 告诉你页面最后被修改的日期URL属性 事件load 页面和页面上的元素完成加载时click 用户在页面上点击鼠标时keypress 用户按下某个按键时 方法write() 向document中添加新的内容getElementById() 使用元素的id属性访问一个元素 浏览器如何看待web页面？1.以HTML代码方式接收页面2.创建页面模型 将模型存储在内存中3.使用渲染引擎将页面显示到屏幕上渲染引擎处理css规则 应用到对用的元素上4.浏览器中的脚本引擎解释js 翻译成对用的指令 然后被执行 （js 解释型编程语言 每一行代码被以此翻译 然后执行） 3.如何为Web页面编写一段脚本？内容层 html展现层 css行为层 javascript 渐进式增强web页面的创建方法1.仅有HTML2.HTML+CSS3.HTML+CSS+JS 使用对象和方法document.write('Good Afternoon!');document对象表示整个web页面 所有web浏览器都实现了这个对象document对象中的方法和属性被称为对象的成员 二、JavaScript基础指令变量命名必须以字母，$或_开头 数组数组里的值可以是不同类型的 三、函数、方法与对象声明函数function sayHello(){ document.write(&apos;hello!&apos;); }匿名方法和函数表达式匿名函数：没有名字的函数 var area=function(width,height){ return width*height; } var size=area(3,4)解释器到达第一句话时函数不会执行 立即调用函数表达式IIFEvar area=（function(){ var width=3; var height=2; return width*height; ()) } var size=area(3,4)最后一对括号告诉解释器马上调用此函数分组的括号确保解释器将这作为一个表达式对待 使用匿名函数与IIFE的时机1.当函数被调用时作为实参2.用于为对象的属性赋值3.用于事件处理程序和监听器4.防止两段脚本中因使用同样的变量名而产生冲突5.IIFE通常被用作一组代码的封装器 在此匿名函数中声明的任何变量能够非常有效地保护变量 变量作用域全局变量在页面载入浏览器地时候就进驻内存全局变量比局部变量占用更多的内存 增加命名冲突的风险 对象创建对象：字面量语法var hotel={ name:&apos;Quay&apos;, rooms:40, booked:25, checkAvailablity:function(){ return this.rooms-this.booked; } };访问对象访问对象的属性或方法 用点符号或方括号 创建对象：构造函数语法var hotel=new Object(); hotel.name=&apos;Quay&apos; hotel.rooms=40; hotel.booked=25; hotel.checkAvailability=function(){ return this.rooms-this.booked; };修改对象使用点符号或方括号适用于字面量语法或构造函数语法创建的对象 删除对象delete hotel.name删除对象的属性 创建很多对象：构造函数语法function Hotel(name,rooms,booked){ this.name=name; this.rooms=rooms; this.booked=booked; this.checkAvailability=function(){ return this.rooms-this.booked; }; } var quayHotel=new Hotel(&apos;Quay&apos;,40,25);数组和对象相关关系 内置对象浏览器附带了一系列内置的对象 代表当前窗口中网页的一些内容 这些内置对象的行为类似于创建交互式网页的工具。 1.浏览器对象模型（BOM)包含一系列表示当前窗口或标签的对象 比如浏览历史以及设备屏幕。 window //当前浏览器窗口或标签 document //窗口或标签 history //浏览过的网页 location //当前页的URL navigator //浏览器的信息 screen //设备的显示信息 window.alert() //创建含有消息的对话框window.open() //在新的浏览器窗口打开参数中指定的URL 2.文档对象模型（DOM)使用对象为当前页的创建展现，为页面中的每个元素创建一个新对象。 document.title //当前文档的标题document.lastModified //文档最后一次被修改的日期document.URL //返回包含当前文档URL的字符串document.domain //返回当前文档的域document.getElementById() //返回于ID属性值匹配的元素document.creatElement() //创建新元素document.creatTextNode() //创建新的文本节点 3.全局JavaScript对象不构成模型 是一些独立的对象StringNumberBooleanDate //展现和处理日期Math //处理数字和计算RegEx //匹配文本的字符串模式 数字对象isNaN() //检查值是否时数字toFixed() //将特定的数字四舍五入至指定小数位数 Math对象Math.PI //返回pi值Math.random() //获取一个[0,1)的随机数 获取1-10的随机数 var randomNum=math.floor((Math.random*10)+1);Date对象var today=new Date();//创建一个Date对象getSecond() setSecond() 返回/设置秒 四、判断和循环强制类型转换和弱类型(‘1’&gt;0) 字符串1会被转化成数字1 JS 弱类型语言推荐用严格等于和严格不等于=== 和 ！== 每个值都可以被当作true或false真值：true、非零数字、有内容的字符串、数字运算结果非零假值： false、数字零、空字符串、NAN、没有被赋值的变量 检测相等和存在对象或数组可以被视为真值 判断页面中的元素是否存在 if(document.getElementById(&apos;header&apos;)){ //found:do something } else { //not found: do something else; }","link":"/2019/05/19/%E3%80%8AJavaScript&jQuery%20%E4%BA%A4%E4%BA%92%E5%BC%8FWeb%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E3%80%8B%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"FCC-Front End-Basic Javascript-资料整理","text":"因为做辛卫的作业迅速入门js,但是还是感觉不太清晰，于是上fcc补了这部分，整理了一些笔记，以供参考。 当 JavaScript 中的变量被声明的时候，程序内部会给它一个初始值 undefined。当你对一个值为 undefined 的变量进行运算操作的时候，算出来的结果将会是NaN，NaN 的意思是 “Not a Number”。当你用一个没有定义的变量来做字符串连接操作的时候，它会如实的输出”undefined”。 var a=&quot;I am a string&quot;; 在 JavaScript 中所有的变量都是大小写敏感的。这意味着你要区别对待大写字母和小写字母。MYVAR与MyVar和myvar 是截然不同的变量。这就有可能导致多个截然不同的变量却有着有相似的名字。正是由于以上原因所以强烈地建议你, 不要 使用这一特性。（以免给自己带来麻烦）最佳实践使用 驼峰命名法 来书写一个 Javascript 变量，在 驼峰命名法 中，变量名的第一个单词的首写字母小写，后面的单词的第一个字母大写。举个栗子：var someVariable;var anotherVariableName;var thisVariableNameIsTooLong; 在 JavaScript 中的 字符串 要用单引号或双引号来包裹它，只要你在开始和结束都使用相同类型的引号，单引号和双引号的功能在JavaScript中是相同的。 在 JavaScript 中，当 + 操作符与 字符串 一起使用的时候，它被称作连接 操作符。你可以通过和其他字符串连接 来创建一个新的字符串。举个例子：'My name is Alan,' + ' I concatenate.'注意空格。连接操作不会添加两个字符串之外的空格，所以想加上空格的话，你需要自己在字符串里面添加。 你可以通过在字符串变量或字符串后面写上 .length 来获得字符串变量 字符串 值的长度。 Use Bracket Notation to Find the First Character in a String[]叫中括号，{}叫大括号，()叫小括号。JavaScript中只有字符串类型，没有字符类型。那么如何获取到字符串中的某个字符呢？我们通过[索引] 来获得对应的字符。大多数现代编程语言，如JavaScript，不同于人类从1开始计数。它们是从0开始计数，这被称为 基于零 的索引。例如, 在单词 “Charles” 中索引0上的字符为 “C”，所以在 var firstName = “Charles” 中，你可以使用 firstName[0] 来获得第一个位置上的字符。 Understand String Immutability当你搞懂不可变性后,immutable.js对于你就是小菜一碟了。在 JavaScript 中，字符串 的值是 不可变的，这意味着一旦字符串被创建就不能被改变。例如，下面的代码：var myStr = &quot;Bob&quot;;myStr[0] = “J”;是不会把变量 myStr 的值改变成 “Job” 的，因为变量 myStr 是不可变的。注意，这 并不 意味着 myStr 永远不能被改变，只是字符串字面量 string literal 的各个字符不能被改变。改变 myStr 中的唯一方法是重新给它赋一个值，就像这样：var myStr = &quot;Bob&quot;;myStr = &quot;Job&quot;; Word Blanks现在，我们来用字符串的相关知识实现一个造句函数。通过使用提供的变量参数：名词myNoun、形容词myAdjective、动词myVerb、副词myAdverb，来创建一个新的句子 result。请注意，在英文中，句中的单词是必须用空格来分隔的举个例子，如果名词为 “dog”，形容词为 “big”，动词为 “run”，副词为”quickly”，那么函数返回值为 “dog big run quickly” 就是没问题的此外，为了句子通顺，你可以在包含所有传入单词的前提下自己添加一些其他单词。对于上面的例子，函数返回值为 “That big brown dog just run quickly” 也是没问题的 Store Multiple Values in one Variable using JavaScript Arrays使用数组，我们可以在一个地方存储多个数据。你以左方括号[开始定义一个数组，以右方括号]结束定义，并把每个条目之间用逗号隔开，就像这样：var sandwich = [“peanut butter”, “jelly”, “bread”]。任务创建一个包含 字符串 和 数字 的数组 myArray。 你也可以在数组中包含其他数组，就像这样: [[“Bulls”, 23], [“White Sox”, 45]]。这被称为一个 多维数组。 一个简单的方法将数据追加到一个数组的末尾是通过 push() 函数。 改变数组中数据的另一种方法是用 .pop() 函数。.pop() 函数用来”抛出”一个数组末尾的值。我们可以把这个”抛出”的值赋给一个变量存储起来。数组中任何类型的条目（数值，字符串，甚至是数组）可以被”抛出来” 。举个例子, 对于这段代码 var oneDown = [1, 4, 6].pop();现在 oneDown 的值为 6 ，数组变成了 [1, 4]。 Manipulate Arrays With shiftpop()函数用来移出数组中最后一个元素。如果想要移出第一个元素要怎么办呢？这就是 .shift() 的用武之地。它的工作原理就像 .pop()，但它移除的是第一个元素，而不是最后一个。 你不仅可以 shift（移出）数组中的第一个元素，你也可以 unshift（移入）一个元素到数组的头部。.unshift() 函数用起来就像 .push() 函数一样, 但不是在数组的末尾添加元素，而是在数组的头部添加元素。 Write Reusable JavaScript with Functions在 JavaScript 中，我们可以把代码的重复部分抽取出来，放到一个函数（functions）中。这是一个函数（function）的例子： function functionName() { console.log(&quot;Hello World&quot;); }调用函数functionName();每次调用函数时它会打印出消息的”Hello World”到开发的控制台上。所有的大括号之间的代码将在每次函数调用时执行。 函数的参数parameters在函数中充当占位符(也叫形参)的作用，参数可以为一个或多个。调用一个函数时所传入的参数为实参，实参决定着形参真正的值。简单理解：形参即形式、实参即内容。这是带有两个参数的函数， param1 和 param2： function testFun(param1, param2) { console.log(param1, param2); }接着我们调用 testFun：testFun(“Hello”, “World”);我们传递了两个参数， “Hello” 和 “World”。在函数内部，param1 等于”Hello”，param2 等于”World”。请注意，testFun 函数可以多次调用，每次调用时传递的参数会决定形参的实际值。 Global Scope and Functions在 JavaScript 中， 作用域 涉及到变量的作用范围。在函数外定义的变量具有 全局 作用域。这意味着，具有全局作用域的变量可以在代码的任何地方被调用。这些没有使用var关键字定义的变量，会被自动创建在全局作用域中，形成全局变量。当在代码其他地方无意间定义了一个变量，刚好变量名与全局变量相同，这时会产生意想不到的后果。因此你应该总是使用var关键字来声明你的变量。 在一个函数内声明的变量，以及该函数的参数都是局部变量，意味着它们只在该函数内可见。这是在函数 myTest内声明局部变量loc 的最佳例子： function myTest() { var loc = &quot;foo&quot;; console.log(loc); } myTest(); // &quot;foo&quot; console.log(loc); // &quot;undefined&quot;在函数外，loc 是未定义的。 一个程序中有可能具有相同名称的 局部 变量 和 全局 变量。在这种情况下，局部 变量将会优先于 全局 变量。下面为例： var someVar = &quot;Hat&quot;; function myFun() { var someVar = &quot;Head&quot;; return someVar; }函数 myFun 将会返回 “Head”，因为 局部变量 优先级更高。 Stand in Line在计算机科学中 队列（queue）是一个抽象的数据结构，队列中的条目都是有秩序的。新的条目会被加到 队列 的末尾，旧的条目会从 队列 的头部被移出。写一个函数 queue ，用一个数组arr和一个数字item作为参数。数字item添加到数组的结尾，然后移出数组的第一个元素，最后队列函数应该返回被删除的元素。 Understanding Boolean Values另一种数据类型是布尔（Boolean）。布尔 值要么是true 要么是false。它非常像电路开关， true是”开”，false 是”关”。这两种状态是互斥的。注意Boolean 值绝不会写作被引号包裹起来的形式。字符串的 “true” 和 “false” 不是 布尔值，在 JavaScript 中也没有特殊含义。 Comparison with the Strict Equality Operator严格相等运算符（===）是相对于相等操作符（==）的一种操作符。与相等操作符不同的是，它会同时比较元素的值和 数据类型。举个例子3 === 3 // true3 === ‘3’ // false3 是一个数字类型的，而’3’ 是一个字符类型的，所以3不全等于’3’。 严格不相等运算符（!==）与全等运算符是相反的。这意味着严格不相等并返回 false 的地方，用严格相等运算符会返回 true，反之亦然。严格相等运算符不会转换值的数据类型。 使用大于运算符（&gt;）来比较两个数字。如果大于运算符左边的数字大于右边的数字，将会返回 true。否则，它返回 false。与相等运算符一样，大于运算符在比较的时候，会转换值的数据类型。 如果你有非常多的选项需要选择，可以使用switch语句。根据不同的参数值会匹配上不同的case分支，语句会从第一个匹配的case分支开始执行，直到碰到break就结束。这是一个伪代码案例： switch (num) { case value1: statement1; break; case value2: statement2; break; ... case valueN: statementN; break; }测试case 值使用严格相等运算符进行比较，break关键字告诉javascript停止执行语句。如果没有break关键字，下一个语句会继续执行。 Adding a default option in Switch statements在switch 语句中你可能无法用case来指定所有情况，这时你可以添加default语句。当再也找不到case匹配的时候default语句会执行，非常类似于if/else组合中的else语句。default语句应该是最后一个case。 switch (num) { case value1: statement1; break; case value2: statement2; break; ... default: defaultStatement; } Build JavaScript Objects你之前可能听说过对象 object 。对象和数组很相似，数组是通过索引来访问和修改数据，对象是通过属性来访问和修改数据的。这是一个示例对象： var cat = { &quot;name&quot;: &quot;Whiskers&quot;, &quot;legs&quot;: 4, &quot;tails&quot;: 1, &quot;enemies&quot;: [&quot;Water&quot;, &quot;Dogs&quot;] };对象适合用来存储结构化数据，就和真实世界的对象一模一样，比如一只猫。 Accessing Objects Properties with the Dot Operator有两种方式访问对象属性，一个是点操作符(.)，一个是中括号操作符([])。当你知道属性的名称的时候，使用点操作符。这是一个使用点操作符读取对象属性的例子： var myObj = { prop1: &quot;val1&quot;, prop2: &quot;val2&quot; }; var prop1val = myObj.prop1; // val1 var prop2val = myObj.prop2; // val2任务通过点操作符读取对象testObj，把hat的属性值赋给变量hatValue，把shirt的属性值赋给shirtValue。 Accessing Objects Properties with Bracket Notation第二种访问对象的方式就是中括号操作符([])，如果你想访问的属性的名称有一个空格，这时你只能使用中括号操作符([])。这是一个使用中括号操作符([])读取对象属性的例子： var myObj = { &quot;Space Name&quot;: &quot;Kirk&quot;, &quot;More Space&quot;: &quot;Spock&quot; }; myObj[&quot;Space Name&quot;]; // Kirk myObj[&apos;More Space&apos;]; // Spock提示：属性名称中如果有空格，必须把属性名称用单引号或双引号包裹起来。 中括号操作符的另一个使用方式是用变量来访问一个属性。当你需要遍历对象的属性列表或查表时，这种方式极为有用。 这有一个使用变量来访问属性的例子： var someProp = &quot;propName&quot;; var myObj = { propName: &quot;Some Value&quot; } myObj[someProp]; // &quot;Some Value&quot;还有更多： var myDog = &quot;Hunter&quot;; var dogs = { Fido: &quot;Mutt&quot;, Hunter: &quot;Doberman&quot;, Snoopie: &quot;Beagle&quot; } var breed = dogs[myDog]; console.log(breed)// &quot;Doberman&quot;提示：当我们通过变量名访问属性的时候，不需要给变量名包裹引号。因为实际上我们使用的是变量的值，而不是变量的名称。 添加可以直接添加我们同样可以删除对象的属性，例如：delete ourDog.bark; 对象和字典一样，可以用来存储键/值对。如果你的数据跟对象一样，你可以用对象来查找你想要的值，而不是使用switch或if/else语句。当你知道你的输入数据在某个范围时，这种查找方式极为有效。这是简单的反向字母表： var alpha = { 1:&quot;Z&quot;, 2:&quot;Y&quot;, 3:&quot;X&quot;, 4:&quot;W&quot;, ... 24:&quot;C&quot;, 25:&quot;B&quot;, 26:&quot;A&quot; }; alpha[2]; // &quot;Y&quot; alpha[24]; // &quot;C&quot; var value = 2; alpha[value]; // &quot;Y&quot; Testing Objects for Properties有时检查一个对象属性是否存在是非常有用的，我们可以用.hasOwnProperty(propname)方法来检查对象是否有该属性。如果有返回true，反之返回 false。举例： var myObj = { top: &quot;hat&quot;, bottom: &quot;pants&quot; }; myObj.hasOwnProperty(&quot;top&quot;); // true myObj.hasOwnProperty(&quot;middle&quot;); // false任务修改函数checkObj检查myObj 是否有checkProp属性，如果属性存在，返回属性对应的值，如果不存在，返回 &quot;Not Found&quot;。注意：如果你需要通过变量来访问对象的属性值，请用中括号操作符，点操作符不支持变量。 Introducing JavaScript Object Notation JSONJavaScript Object Notation 简称 JSON，它使用JavaScript对象的格式来存储数据。JSON是灵活的，因为它允许 数据结构 是 字符串，数字，布尔值，字符串，和 对象 的任意组合。这里是一个JSON对象的示例： var ourMusic = [ { &quot;artist&quot;: &quot;Daft Punk&quot;, &quot;title&quot;: &quot;Homework&quot;, &quot;release_year&quot;: 1997, &quot;formats&quot;: [ &quot;CD&quot;, &quot;Cassette&quot;, &quot;LP&quot; ], &quot;gold&quot;: true } ];这是一个对象数组，并且对象有各种关于专辑的 详细信息。它也有一个嵌套的 formats 的数组。附加专辑记录可以被添加到数组的最上层。提示数组中有多个 JSON 对象的时候，对象与对象之间要用逗号隔开。 Accessing Nested Objects in JSON通过串联起来的点操作符或中括号操作符来访问JSON对象的嵌套属性。下面是一个嵌套的JSON对象： var ourStorage = { &quot;desk&quot;: { &quot;drawer&quot;: &quot;stapler&quot; }, &quot;cabinet&quot;: { &quot;top drawer&quot;: { &quot;folder1&quot;: &quot;a file&quot;, &quot;folder2&quot;: &quot;secrets&quot; }, &quot;bottom drawer&quot;: &quot;soda&quot; } } ourStorage.cabinet[&quot;top drawer&quot;].folder2; // &quot;secrets&quot; ourStorage.desk.drawer; // &quot;stapler&quot; 正如我们在前面的例子所见，JSON对象可以嵌套对象和数组。与访问嵌套对象一样，用中括号操作符同样可以访问嵌套数组。下面是如何访问嵌套数组的例子： var ourPets = { &quot;cats&quot;: [ &quot;Meowzer&quot;, &quot;Fluffy&quot;, &quot;Kit-Cat&quot; ], &quot;dogs&quot;: [ &quot;Spot&quot;, &quot;Bowser&quot;, &quot;Frankie&quot; ] }; ourPets.cats[1]; // &quot;Fluffy&quot; ourPets.dogs[0]; // &quot;Spot&quot; Iterate with JavaScript For Loops一个条件语句只能执行一次代码，而一个循环语句可以多次执行代码。JavaScript 中最常见的循环就是”for循环”。for循环中的三个表达式用分号隔开：for ([初始化]; [条件判断]; [计数器])初始化语句只会在执行循环开始之前执行一次。它通常用于定义和设置你的循环变量。条件判断语句会在每一轮循环的开始执行，只要条件判断为 true 就会继续执行循环。当条件为 false的时候，循环将停止执行。这意味着，如果条件在一开始就为 false，这个循环将不会执行。计数器是在每一轮循环结束时执行，通常用于递增或递减。在下面的例子中，先初始化i = 0，条件 i &lt; 5 为真，进入第一次循环，执行大括号里的代码，第一次循环结束。递增i的值，条件判断，就这样依次执行下去，直到条件判断为假，整个循环结束。 var ourArray = []; for (var i = 0; i &lt; 5; i++) { ourArray.push(i); }最终 ourArray 的值为 [0,1,2,3,4]. Nesting For Loops如果你有一个二维数组，可以使用相同的逻辑，先遍历外面的数组，再遍历里面的子数组。下面是一个例子： var arr = [ [1,2], [3,4], [5,6] ]; for (var i=0; i &lt; arr.length; i++) { for (var j=0; j &lt; arr[i].length; j++) { console.log(arr[i][j]); } }一次输出 arr 中的每个子元素。提示，对于内部循环，我们可以通过 arr[i] 的 .length 来获得子数组的长度，因为 arr[i] 的本身就是一个数组。 Generate Random Fractions with JavaScript计算机的行为只有两种：确定性和随机性。当你一步步地闯关来到这里就是确定行为，当你随意点了个链接就来到这里就是随机行为。而随机数最适合用来创建这种随机行为。Math.random()用来生成一个在0(包括0)到1(不包括1)之间的随机小数，因此Math.random()可能返回0但绝不会返回1。提示随后的函数都会在return执行前调用，所以我们可以直接返回Math.random()的值。任务更改myFunction 来生成一个随机数取代 0。 Sift through Text with Regular ExpressionsRegular expressions 正则表达式被用来根据某种匹配模式来寻找strings中的某些单词。 举例：如果我们想要找到字符串The dog chased the cat中单词 the，我们可以使用下面的正则表达式: /the/gi我们可以把这个正则表达式分成几段：/ 是这个正则表达式的头部the 是我们想要匹配的模式/ 是这个正则表达式的尾部g 代表着 global(全局)，意味着返回所有的匹配而不仅仅是第一个。i 代表着忽略大小写，意思是当我们寻找匹配的字符串的时候忽略掉字母的大小写。 Find Numbers with Regular Expressions我们可以在正则表达式中使用特殊选择器来选取特殊类型的值。特殊选择器中的一种就是数字选择器\\d，意思是被用来获取一个字符串的数字。在JavaScript中, 数字选择器类似于: /\\d/g。在选择器后面添加一个加号标记(+)，例如：/\\d+/g，它允许这个正则表达式匹配一个或更多数字。尾部的g是’global’的简写，意思是允许这个正则表达式 找到所有的匹配而不是仅仅找到第一个匹配。","link":"/2019/05/05/FCC-Front%20End-Basic%20Javascript-%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"title":"《JavaScript&jQuery 交互式Web前端开发》（二）","text":"四、文档对象模型浏览器加载web 创建页面模型 这个模型被称为DOM树 被保存在浏览器的内存中 四种节点 文档节点 元素节点 属性节点 文本节点 使用DOM树访问并更新DOM树的两个步骤：1.定位到于需要操作的元素所对应的节点2.使用它的文本内容、子元素或属性 1.访问元素getElementById()querySelector() //使用CSS选择器getElementByClassName() //选择所有在class中使用了特定值的元素getElementByTagName() //选择所有使用了指定标记的元素querySelectorAll() //使用CSS选择器来选择所有匹配的元素parentNode //当前节点的父节点previousSibling/nextSibling //前一个或后一个兄弟节点firstChild/lastChild //当前节点的第一个或最后一个子节点 2.操作元素nodeValue 这个属性允许访问或修改文本节点中的内容innerHTML 这个属性可以访问子元素和文本内容textContent 这个属性仅访问文本内容createElement() 创建节点createTextNode()appendChild() 将节点添加到树中removeChild() 从树中移除节点className/id 可以获取更新class和id的属性hasAttribute() 检查属性是否存在getAttribute() 获取属性值setAttribute() 更新属性值removeAttribute() 移除属性值 3.访问元素DOM查询可能返回一个元素 也可能返回一个NodeList 节点的集合 4.返回多个元素的DOM查询length NodeList中一共有多少个项item() 方法：返回NodeList中特定的节点 需要在小括号中指定编号 5.重用NodeList动态NodeList 脚本更新页面之后，NodeList也同样会更新 静态的话 NodeList不会被更新 不会反映脚本所做的修改 getElementBy开头的方法都会返回动态NodeListquerySelector开头的方法会返回静态NodeList var elements=getElementByTagName(&apos;h1&apos;); if(elements.length&gt;=1){//检查nodelist至少包含一个节点 var firstItem=elements.item(0);//item()方法 var secondItem=elements[1];//数组语法 }数组语法的速度更快 更推荐使用 6.遍历DOM有些浏览器会在元素之间添加一个文本节点 不管它之间是不是真的有空白解决这一问题的方法 使用jQuery库 使用NodeValue属性获取和更新文本节点var itemTwo=document.getElementById(&apos;two&apos;); var elText=itemTwo.firstChild.nodeValue; elText=elText.replace(&apos;pine nuts&apos;,&apos;kale&apos;); itemTwo.firstChild.nodeValue=eltext;使用textContent和innerText获取和更新文本&lt;li id=&quot;one&quot;&gt;&lt;em&gt;fresh&lt;/em&gt;figs&lt;/li&gt;获取li元素中的文本 用textContent返回fresh figs同样可以使用这个属性来更新元素的内容 innerText应避免使用 FireFox不支持不会返回css隐藏的内容 需要考虑布局规则来判断元素的可见性 在获取文本内容的速度要比textContent慢 使用innerHTML获取和更新文本var firstItem=document.getElementById(&apos;one&apos;); var itemContent= firstItem.innerHTML; firstItem.innerHTML=&apos;&lt;a href=\\&quot;http://example.org\\&quot;&gt;&apos;+itemContent+&apos;&lt;/a&gt;&apos;;itemContent中包含如下字符串&lt;em&gt;fresh&lt;/em&gt; figs浏览器会把字符串中包含的任何元素都添加到DOM树中","link":"/2019/06/27/%E3%80%8AJavaScript&jQuery%20%E4%BA%A4%E4%BA%92%E5%BC%8FWeb%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E3%80%8B%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"【编译原理复习专题1】上下文无关文法和正则表达式","text":"扫描器是词法分析器，它接收输入的源程序，对源程序进行词法分析并识别出一个个单词符号，输出单词符号。 上下文无关语言表示上下文无关文法规则的形式被称为BNF，其扩展表示就是EBNF。 在BNF中，重复是使用递归表示的，重复实际分两种：嵌套重复和并列重复，并列重复对应到程序是可以用循环来实现的。 EBNF重复表示{…} 下面两种重复的递归形式表达的就是并列重复： $A\\rightarrow A \\alpha|\\beta$ $A\\rightarrow \\alpha A |\\beta$ 其中第一条中要求$\\beta$ 不能以A开头， 而第二条中要求$\\beta$不能以A结尾。对应的正则表达式为：$\\beta \\alpha^$和$\\alpha^\\beta$EBNF中使用{…}来表示这种重复：$A\\rightarrow \\beta {\\alpha}$ $A\\rightarrow{\\alpha} \\beta$ 可选表示[…] 有点类似消除左因子。 语句序列：$stmt-sequence \\rightarrow stmt; stmt-sequence | stmt$可以表示为：$stmt-sequence \\rightarrow stmt [ ; stmt-sequence ]$$stmt-sequence \\rightarrow stmt { ; stmt } $ 消除左递归直接简单左递归$A\\rightarrow A \\alpha |\\beta$ 改写文法为： $A\\rightarrow \\beta A’$ $A’\\rightarrow \\alpha A’ |\\epsilon$ 间接左递归会出现$A\\Rightarrow^*A$的左递归。 处理方法： 将文法的所有非终结符按任意一种顺序排序，得到$A_1,A_2…A_n$ 对每个$A_i$，如果存在一个编号比它小的非终结符，编号大的非终结符可以含有推出编号小的非终结符的句型，而且编号小的非终结符还能够推出一个句型，那么就可以进行代入操作。如果有直接左递归，那么直接消除即可。 $S\\rightarrow Qc|c$ $Q\\rightarrow Rb|b$ $R\\rightarrow Sa|a$ 1) 对S、Q、R编号1、2、3 2）i=1，无法代入，i=2，无法代入 i=3, 代入有 $R\\rightarrow Qca|ca|a$,可再次代入：$R\\rightarrow Rbca|bca|ca|a$ 3)化简直接左递归： $R\\rightarrow bcaR’|caR’|aR’$ $R\\rightarrow bcaR’|\\epsilon$ 消除左公因子对每个非终结符A，找出它的两个或多个选项之间的最长公共前缀$\\alpha$,如果$\\alpha$不为空，即存在一个非平凡的公共前缀，那么将所有A的产生式$A\\rightarrow \\alpha\\beta_1|\\alpha\\beta_2|…\\alpha\\beta_n|\\gamma$, 替换为： $A\\rightarrow \\alpha A’|\\gamma$ $A’\\rightarrow \\beta_1|\\beta_2|…|\\beta_n$ 递归构造上下文无关文法左递归：左侧非终结符出现在右侧第一个位置。$A\\rightarrow A a | a$右递归：左侧非终结符出现在右侧最后一个位置$A \\rightarrow a A | a$ 表示$\\alpha\\beta^*\\gamma$一样的语言： 1）$A\\rightarrow B\\gamma$ ,$B\\rightarrow B\\beta|\\alpha$ 2) $A\\rightarrow \\alpha B$ ,$B\\rightarrow \\beta B|\\gamma$ 3)$A\\rightarrow\\alpha B\\gamma$,$B\\rightarrow\\beta B| \\epsilon$ 所有的正则语言都能被上下文无关文法表示。","link":"/2020/05/21/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"【编译原理复习专题5】中间代码生成","text":"中间代码生成就是把经过语法分析和语义分析的源程序中间表示翻译为中间代码展示，中间表示可能有多个种类，如语法树、DAG、后缀式、三地址代码等。 如果中间代码独立于机器的话，那么各便于编译系统的建立和移植，并且便于进行独立于机器的代码优化工作。 三地址代码三地址代码包含一个运算和三个地址，两个地址用于存放运算对象，一个用于存放运算结果。 具体实现：四元式、三元式、间接三元式。 四元式op、arg1、arg2、result 三元式op、arg1、arg2 使用运算x op y 的位置来表示计算的结果 间接三元式类型和声明类型表达式是用于表示类型的结构的，如基本类型int、char、float， 类型表达式名也是类型表达式。 类型构造算子:作用于类型表达式可以构造新的类型表达式。 数组构造符array 类型 类型表达式 int[3] array(3,int) int[2][3] array(2,array(3,int)) 指针构造符pointer 笛卡尔乘积构造符x 函数构造符-&gt; 记录构造符record 类型检查 type checking保证参与的运算分量和运算符预期的类型相匹配。 如果两个类型表达式相等，那么返回某种类型，否则出错 类型等价 两种类型之间结构等价当且仅当下面某个条件为真： 1.是相同的类型 2.是相同的类型构造算子应用于结构等价的类型而构造得到的。 3.一个类型是另一个类型表达式的名字 类型检查有两种形式：类型综合和类型推导。 类型综合是根据子表达式的类型构造出表达式的类型，要求名字先声明再使用。表达式$E1+E2$的类型是根据$E1$和$E2$的类型定义的。 类型推导是根据一个语言结构的使用来确定结构的类型，就类似如果使用了某个类型才能用的函数的话，那么可以指出使用该函数的变量就是对应的类型。 类型转换浮点数和整型相加，编译器内部需要进行转换。 不同的语言有不同的类型转换，主要转换有两种：拓宽转换（保持信息）、窄化转换（丢失信息）。 类型翻译类型的声明语义分析在遇到声明语句时，主要做两件事情：1.收集标识符的类型等属性信息；2.为每一个名字分配一个相对地址。 声明的SDT表达式和赋值语句的翻译为赋值语句生成三地址码的SDDgen 一个函数，生成括号内代表信息的三地址码 Production Semantic Rules $S\\rightarrow id=E$ $S.code=E.code $E\\rightarrow E_1+E_2$ $E.addr=new Temp()$, $E.code=E1.code $E\\rightarrow -E_1$ $E.addr=new Temp()$ ,$E.code=E_1.code $E\\rightarrow (E_1)$ $E.addr=E1.addr$,$E.code=E_1.code$ $E\\rightarrow id$ $E.addr=top.get(id.lexeme)$, $E.code=’’$ 将$a=b+-c;$ 编译成三地址码： $S\\Rightarrow id=E_0;$ $\\Rightarrow id=E_1+E_2;$ $\\Rightarrow id=E_1+-E_3;$ $\\Rightarrow id=E_1+-id;$ $\\Rightarrow id=id+-id;$ 产生式 属性变化 $E_1\\rightarrow id$ $E_1.addr=addr(b)$, $E_1.code=’’$ $E3\\rightarrow id$ $E_3.addr=addr(c)$, $E_3.code=’’$ $E_2\\rightarrow -E_3$ $E_2.addr=t1$ ,$E_2.code=E_3.code $E_0\\rightarrow E_1+E_2$ $E_0.addr=t2$,$E_0.code=E_1.code $S\\rightarrow id=E_0$ $S.code=E_0.code 刚好三行就是赋值语句的三地址码。 布尔表达式的翻译短路代码跳转代码中&amp;&amp; || ！都被翻译成跳转指令。 语句： 12if(x&lt;100||x&gt;200 &amp;&amp; x!=y) x=0; 三地址代码： 12345678if x&lt;100 goto L2goto L3L3: if x&gt;200 goto L4goto L1L4: if x!=y goto L2goto L1L2:x=0L1: 其实运算符并不在代码中，布尔表达式的值是通过代码序列中的位置来表示的。 控制流语句控制流语句：(S表示语句，B表示布尔表达式) 1.$P\\rightarrow S$ 2.$S\\rightarrow assign$ 3.$S\\rightarrow if(B) S1$ 4.$S\\rightarrow if(B) \\quad S1 \\quad else \\quad S2$ 5.$S\\rightarrow while(B)\\quad S1$ 6.$S\\rightarrow S1 \\quad S2$ SDD $P\\rightarrow S$ $S.next=newlable()$ $S\\rightarrow assign$ $S.code=assign.code$ $S\\rightarrow if(B) S1$ $B.true=newlabel()$,$B.false=S_1.next=S.next$, $S.code=B.code $S\\rightarrow if(B) \\quad S1 \\quad else \\quad S2$ $B.true=newlabel()$,$B.false=newlabel()$,$S_1.next=S_2.next=S.next$,$S.code=B.code $S\\rightarrow while(B)\\quad S1$ (1) $B\\rightarrow E1 \\quad rel \\quad R2$ (假设形如$a&lt;b$) $B.true: if \\quad a&lt;b\\quad goto \\quad B.true$ (j&lt;,a,b,B.true) $B.FALSE: goto B.false$ (j,,,B.false) (2) B是常量, 就直接翻译为跳转指令。 (3) 不需要为$B\\rightarrow!B$产生新的代码，只需要将真假出口交换就可以了。(继承属性)。 (4) 对$B\\rightarrow B1||B2$, 如果B1为真则B为真，B1.true从B.true继承而来，如果B1为假，则对B2求值，B1.false就可以设置为B2的代码的第一条指令的标号。B2的真假出口标号可直接从B继承获得。","link":"/2020/05/23/%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"},{"title":"一个解决word页码错乱的小方法","text":"说实话，我常常因为word多此一举的方便用户而感到困扰。 比如拿到了一个页码错乱的文档模板，然后强迫症的我页码绝对不能错一个。 那么如果出现了这样恐怖的情况:文档页码在某一页开始一直往下都相同的话，其实是因为word看见的文档并不和你看见的一样，如果一个节没有结束的话，那么word就默认这一页还没有结束，可以理解为word看见的文档按照节来说实际上是一个不知道多长的羊皮卷。 通常如果出现页码相同的情况，可以双击页码并注意看导航栏里是否勾选了链接到前一节。我们看字面意思就能猜到，链接到前一节就指的是前后两个页面(不一定是你看到的页面，而是word认为的页面，总之）它们被绑定在一起了，修改一个另一个也会被更改。如果你发现勾选了这项的话，把它取消。我们不需要自作多情的链接。 但是还有一种情况是你发现链接到前一节没有被勾选，但页码也还是从某一页往下相同，那么就是因为word把”节“理解成了”页“，对于未完成的节，它是不会变换页码的。所以，你要做的就是告诉word这一页已经结束了。 那么具体的方法如下： 1.光标移动到相同页面中的第一张的最末尾，点击布局-&gt; 分隔符，选择下一页，就会在该页插入分节符（下一页） 2.选中第二页的页码，就会发现此时会显示勾选了链接到前一节，取消它 3.正确地命名页码 4.如此往复直到问题解决 不知道这个方法是不是正确，总之页码错乱问题是能够解决了，但是随之而来的是新的问题，自动目录并不能识别到对应的页码，还好自动页码可以手动改页码。 结尾也不知道要说我是该去学习一下Word呢，还是高喊”Latex真香“, 那就这样吧。","link":"/2020/05/20/%E4%B8%80%E4%B8%AA%E8%A7%A3%E5%86%B3word%E9%A1%B5%E7%A0%81%E9%94%99%E4%B9%B1%E7%9A%84%E5%B0%8F%E6%96%B9%E6%B3%95/"},{"title":"从停机问题到不可知论","text":"你被关在在一个房间里，房间里挤满了很多台机器。对于你眼前的一台机器P，有一个小矮人坐在机器前，不断地向机器里敲打着序列，这时机器大声地喊了一句”hello world!”，说明条件满足了 。如果机器没有动静，说明输入的序列并不满足让它大喊的条件。对于每一台机器来说，它们满足的条件各不相同。 我告诉你，你的任务是，造出一台超级机器，这样你才能够出去。这台机器我要求对于房间里任意的一台机器和对应的输入，如果这台机器能够喊出”hello world”， 那么超级机器就会说”yes”, 如果这台机器不能”hello world”， 那么超级机器就会说”no”。 这看起来是个很简单的任务，因为超级机器只需要判断其他机器能不能喊”hello world”就可以了。这时候，我又对你提出了新的要求：”如果超级机器判断的机器没有喊’hello world’ ，那就让这台超级机器代替它喊一句’hello world’。” 好像和之前的任务也没什么差别，只是改变了喊话的内容而已。 现在我告诉你，对于某一台机器来说，你输入的序列，也完全可以是那台机器本身。什么意思呢，其实说到底，这里说的机器并不是实际存在的东西，而是一串序列，这听上去有一点恐怖，你能够把机器编成一串序列，让小矮人把这个序列敲到机器里。 总之，小矮人们不太情愿地把这个序列敲进了机器，对于机器接下来会怎么样，小矮人也不清楚。但这时候你会发现，有些机器发出了”hello world”， 有些机器十分安静。说”hello world” 或是不说，就这两种结果。 对于超级机器来说，你大概发现了，这台机器至少要有两个输入，也就是说，一个小矮人输入的是你要判断能不能发出”hello world” 的那台机器（所代表的序列P），而另一个小矮人要输入你要输入到待判断的机器里的那个序列I。 但是现在我说，没必要再找两个小矮人，直接让你来，输入的序列就是机器代表的序列，不需要输入I了，机器也不需要有两个输入口，一个就够了。相当于说，之前说的两个输入，都是机器代表的序列P。你会输入两次机器代表的序列P，但是，鉴于这台超级机器只有一个输入，那么当你第一次输入P时，这台只由你控制的机器也会有一个输出，也就是说，当你输入P的时候，这台超级机器也有可能因为满足它自身的条件而大喊”hello world”。 我想你可能也想不出来这样的机器要怎么做，但总之，我指着角落的一台机器，告诉你，其实那台机器就是超级机器。我让你过去，并且我告诉了你超级机器所代表的序列。 “输入吧。” 我说。 你开始敲打超级机器代表的序列，就像把超级机器自己塞进了自己的输入口里。 但最终你发现了，我骗了你，那台机器根本就不是超级机器。 如果这台超级机器，输入自己的序列，喊出了”hello world”， 那么根据最开始定义的规则，它会喊出”yes”, 而如果这台超级机器输入自己的序列并没有发出声音，按照定义，它输入的机器没有喊出”hello world”的时候，它会代替输入的机器，喊出”hello world”。 这根本不可能，超级机器根本没办法造出来。就是这样，你没法逃出房间。 今天计算理论讲了停机问题，感觉非常有意思，于是写了一个小故事，尽可能简单地解释出这一构造的巧妙性，但是可能会有交代不清的地方，欢迎指正~ 另外，关于停机问题，老师还扯到了很多有意思的东西，非常之”哲学”。 比如说，如果故事里的机器是杀毒软件的话，其实可以发现，杀毒软件是不能够检测出所有的病毒的，因为它不能知道自己是不是就是病毒（细思极恐）。而且停机问题的推导其实涉及到了一种自我指涉的矛盾。说到”自我”，其实就会发现，按照这样的逻辑，一个人是无法完全认识自己的，或者说一个人是无法完全理解自身的。 如果故事里的机器是我们的脑子，用我们的脑子去研究我们的脑子，其实就会有不能够认识到的地方。脑子是研究的主体，也是研究的客体；就像机器作为程序，但同时又作为程序的输入，而这时候你是不能认识到机器的输出的，所以你其实不能认识到这种脑子研究脑子的正确性甚至是可行性。所以说这就某种程度上支持了不可知论。","link":"/2019/04/22/%E4%BB%8E%E5%81%9C%E6%9C%BA%E9%97%AE%E9%A2%98%E5%88%B0%E4%B8%8D%E5%8F%AF%E7%9F%A5%E8%AE%BA/"},{"title":"关于人工智能，最近想谈的一些东西","text":"最近终于把郝景芳《人之彼岸》书后面的小科普看完并且做完了思维导图，把这个拖了太久的事情结束是因为人工智能导论课的一次作业：“人工智能是否会超越人的智力？”，下面是正文： 人工智能是否会超越人的智力？我的答案是有可能，不过目前还有很多挑战。首先，这一问题将比较限定在了人的智力，更准确地说，就是人认识、理解事物并且运用知识、经验等解决问题的能力。此处不探讨人工智能是否会拥有人的情感、人的意识或是人的欲望，仅仅从“解决问题的能力”这一层面来探讨人工智能的“智力有没有可能超越人类。人工智能的研究和发展目的之一，就是因为人工智能可以借由计算机来模拟人的思考和行动，让计算机能够辅助甚至代替人类完成一系列复杂的工作。因此，目前的人工智能，可以说在某些特定的领域，已经超越了人的智力。就拿AlphaGo获胜的棋局来说，可以说在围棋这一领域，人工智能已经超越了人的智力。除了围棋，在语言翻译、语音识别、图像检测等诸多方面，人工智能都可以说是超越了人的智力。但承认人工智能在单个领域上的卓越性，并不等于我们认同人工智能完全超越了人的智力。且不说人工智能还没有应用完任何一个微小的分支领域，即使存在那么一个时间结点，人工智能在任何一个可以应用的小分支下都能够比人类完成得更高效、更好，在那时，人工智能也只是将在这些领域中的“经验”进行叠加。如果没有综合将多个领域的结果产生出创造性的洞见，那么人工智能也仅仅只是一个有强大思考和计算能力的机器罢了，它无法拥有人类的智力。人的思考过程并不只是多个领域结果的简单叠加，我们的智力不是单一的分辨图像，翻译句子或是解数学题，我们的智力高明在我们能够以我们的一切认识作为输入，输出一个非常复杂的结果。换句话说，我们能够综合地考虑问题，触类旁通，从多个角度去思考问题，而不是割裂地分解每个子问题，得到每一个答案。我们能够基于我们的常识，即使只知道一个线索，通过想象、推测出整个事件。我们能够根据我们的世界观，和一系列我们意识到或者没有意识到的规则，对某件事情进行决策。我们的智力在于“综合”，而这种综合，目前还没有人工智能能够做到。如果人工智能想要拥有超越人类的智力，那么它们至少需要大量的数据集，能够将整个世界的规则、机制全部都输入来训练。 上述提到的“综合的能力”，可以认为是一种需要靠智商的思考，但除此之外，人类的智力还运用在生活的方方面面，甚至在我们没有意识的情况下，就已经被使用到了。 通常，这种智力也被称为“快思考”，它们被本能驱动，但同样是由大脑的相互配合而完成的，也因此人产生了感知、情绪、情感等。而这种类型的智力，人工智能超越人类的难度要更大。另外，人还具有创造力（这是否算是一种智力）。在审美和艺术上，就算我们让人工智能学习绘画、写诗、写文章，那并不是真正的创造力，只是在既定的输入下精准的模仿。人类创作的艺术品通常都会被人的经历、性格、周遭发生的事情所影响，而人工智能因为常识体系没有构建，没有自己的世界观，也没有自己的意识、情感，它们的艺术作品仍然是缺乏灵魂的。如果想要让人工智能具有这一类型的智力，那么绕不开的还是得先实现“综合”能力，注入意识，将人工智能铸造得几乎和一个人类没有什么区别才有可能实现这种类型的创作。不过，如果以上所说，未来的人工智能都完美地实现了，那时人工智能会因为其强大的计算性和极高的效率而能够轻易地掌握人类所拥有的能力，在和人类的竞赛中成为永远的胜者，甚至发现了人类从未发现的规律和捷径，那时人工智能才算是真正超越了人类。当然，如果它们不存在感情、不存在个人意志，也无法超越人类，也不会对人类有什么威胁。而反过来想，作为人类的我们其实是一个比目前的人工智能神奇和有智慧千百倍的生物。我们有思想、有感情、具有创造力，虽然我们也没有那么理性，在但我觉得那也是作为人的骄傲，是我们的生气之所在。 当然我的观点也借鉴了郝景芳的那两篇科普文章，如果想了解可以先看看思维导图，或者直接找原文来看。 从大一开始，我的周围很多人都在学人工智能，不过彼时它还没有很吸引我。我对人工智能最初的印象是高中的时候，因为AlphaGo写过一篇关于人工智能的议论文，那时我也是第一次知道“深度学习”。（哎想想当时的我也根本不知道那些看起来无足轻重的词汇会在未来的日子支配我的时间）上了大学以后写过一些人工智能的短篇小说和小段落，不过也都是没有理论支撑的软科幻罢了。等到上学期选了机器学习的课，才稍微开始入了门，这学期也选了深度学习引论和人工智能导论两个选修。虽然我没读过几篇论文，网络也没跑过，但是我隐隐地感觉这是更加激动人心的事情。幸好我现在确实可以像一句话说的那样“做组里来无影去无踪的本科生”，真正的参与一点点事情，更多的是看到新的东西。如果真的做不出什么成绩也无所谓，我只希望回忆起来的时候，我会觉得幸好那时学会了那么有意思的东西。那就已经够好了。","link":"/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/"},{"title":"【编译原理复习专题2】关于语法分析","text":"这将是一个非常口语化的总结，因为这就是我口述的总结。 语法分析过程主要包括两种方法：自底向上的语法分析和自顶向下的语法分析。其中，“底”指的就是原始串，而“顶”指的是开始符号。分析的目的就是确定某一个确定的字符串是否属于文法描述的语言。 而这些分析方法，最终都是要让串形成对应的语法分析树，因此它们将一个判定问题，转化成了生成语法分析树的过程。 First集和Follow集First集和Follow集应该是对于任意的文法都是能够确定的。 文法中的任意文法符号串都是有First集的，First集相当于这个文法符号串能推出的串中最左侧的终结符的集合。First集可以包含$\\epsilon$。 求First集的规则： 把所有的终结符语法规则列出来（我感觉First集求的时候不能有或？还是也可以） 如果X是终结符或者$\\epsilon$,$First(X)={X}$ 如果X是非终结符，对每个产生式$X-&gt;X_1X_2…X_n$,$First(X_1)$是$First(X)$的子集。 如果有$X_1X_2…X_i\\Rightarrow\\epsilon(i&lt;n)$,那么$First(X_{i+1})$是$First(X)$的子集。 Follow集能够让一个非终结符消失（推出空），就是说Follow是确定当某一个非终结符后面出现了哪些终结符的时候，我们需要用推出空这个产生式。 求Follow集的规则： 1.先将$放入Follow(S)中，S为开始字符。(构建LL(1)分析表的时候，如果有$S\\Rightarrow\\epsilon$,那么就可以写在[S,$]里，表示如果接受的是一个空串，就可以用这个产生式) 2.如果存在产生式$A\\rightarrow\\alpha B\\beta$,那么求解Follow(B)的时候，要将$First(\\beta)$中除了$\\epsilon$所有的元素都加入Follow(B)。$\\beta$可包含终结符或非终结符。 3.产生式右侧被推导出之后，左侧的Follow集就是右侧最右（需要考虑右侧是否为空，若为空就不断考虑向左移动的符号）的非终结符的Follow集的子集。 【如果存在产生式$A\\rightarrow\\alpha B\\beta$,且$\\beta$可空（或者说B的First集包含$\\epsilon$)，那么$Follow(B)\\Leftarrow Follow(A)$】 因为我们确定某个非终结符的Follow集，都是通过它在右侧才能确定的，因此我们不需要考虑那些右侧全是终结符的产生式。 LL(1)分析表做的是这件事：横轴是预测的下一个字符，然后当前的栈顶的非终结符已知，那么要通过哪一个产生式能够最终推出预测的下一个字符。所以我们需要通过计算First集和Follow集来确定LL(1)分析表。 自顶向下的语法分析从开始符号最终到实际的字符串，自顶向下中主要分为回溯分析程序和预测分析程序。我们主要学了两种预测分析方法：递归下降和LL(1)。 为何叫“预测分析”，我们可以这么理解：首先，自顶向下分析方法的基础就是将字符串看成输入串，就是说从开始到结束，我们可以认为是逐步读取这个串的，因此字符之间有了先后被读取的，那么我们构建语法分析树也就是一个先根次序创建树的过程，我们也可以说自顶向下分析就是要找到对应串的最左推导。因此预测分析首先是要求给定的文法中没有左因子、左递归，文法不能是二义性的，其次预测分析需要看文法的下一个字符，也就是下一个输出符号，所以我们称之为“预测”。 回溯分析程序预测分析程序递归下降改写为$EBNF$(消除左递归、去除左因子) LL(1)分析算法第一个L表示从左向右扫描输入，第二个L表示最左推导，1表示每一步中只需要向前看一个输入符号来决定语法分析动作。 预测分析表的构建 $LL(1)$构建预测分析表的步骤： $First(\\alpha)$中的每个记号$s$，都将$A\\rightarrow\\alpha$添加至$M[A,s]$中。 $\\alpha$可空的话，对$Follow(A)$中的每一个元素$k$，将$A\\rightarrow\\alpha$添加到$M[A,k]$中。 如果$M[A,\\alpha]$没有产生式的话，就将其设置为$error$。 LL(1)文法一个文法若满足以下条件，则该文法就是LL(1)文法： 在每个产生式$A\\rightarrow{\\alpha}_1 |{\\alpha}_2⋯|{\\alpha}_n$中，对于所有的i和j:$1≤i, j≤n, i≠j$，$First(α_i )∩First(α_j )$为空。（若不为空，假设有一个相同元素$k$,那么在$M[A,k]$就会加入两个产生式：$A\\rightarrow{\\alpha}_i$和$A\\rightarrow{\\alpha}_j$) 若对于非终结符A可空，那么$First(A)∩Follow(A)$为空。(若有相同元素k，根据分析表也会发现$M[A,k]$有两个产生式) 如果一个文法G，由它构造的LL(1)分析表中的每个子项最多只含有一个产生式，那么它就是LL(1)文法。 在LL(1)分析表中有两项产生式的文法不一定是二义性的文法，可能是有左递归的。 一个不是$LL(1)$的文法同样可以用$LL(1)$方法。 LL(1）方法对应的是非递归的预测分析器，显示维护栈结构，应该和计算理论里的下推自动机类似。下推自动机所定义的语言恰好就是上下文无关语言。 自底向上的语法分析归约其实就是推导的反向操作。如果反向构造一个推导过程，那么就会是最右推导的。推导的方法是从记号串开始，使用产生式进行归约，期望得到开始符号，如果能够得到开始符号，那么这个字符串就是文法可以识别的语句。 两个动作：移进 shift和规约 reduce。 自底向下就是从输入串到开始符号的归约，归约的方向是从左到右，可以认为是最左归约，逆向的过程就是最右推导。 概念短语、直接短语和句柄短语就是在一个句型中对应的分析树，里以非终结符为根的子树的所有叶子节点构成的排列就是对于该非终结符的短语，如果子树只有两层，那么就是直接短语。最左侧的非终结符的子树对应的短语就是句柄。 句柄的定义：如果$S\\Rightarrow_{lm}^{*}\\alpha A\\omega \\Rightarrow_{lm} \\alpha \\beta \\omega$，A是输入串中最右的非终结符，则$\\beta$称为一个句柄。 句柄可以理解为一个归约点，可以允许解析器通过进一步的归约操作回到开始符号的位置。而实际上我们做的归约就是最左归约。 对于下列文法： $E\\rightarrow E+T|T$$T\\rightarrow T*F|F$$F\\rightarrow (E) |id$ 对于输入串$id*id$，从左到右相当于一个最左归约的过程。从左至右： 产生式 句柄 最右句型 $F\\rightarrow id$ $id$ id*id $T\\rightarrow F$ $F$ F*id $F\\rightarrow id $ $id$ T*id $T\\rightarrow T*F$ $T*F$ T*F $E\\rightarrow T$ $T$ T 可行前缀LR(0)分析算法LR(0)文法中L指的是从左到右扫描输入串，R代表了最右推导，0表示进行分析动作的决策只考虑栈顶状态，不需要看输入串。（没有lookahead) 1.扩展文法。 在决定状态间的转移前，我们必须先加入一条扩展文法：$S\\rightarrow E$其中$S$是新的起始符号（start symbol）而E是原先的起始符号。这一做法是为了保证分析器能有一个唯一的起始状态。 2.列LR(0)项。(点号的左侧是已经读入的，点号的剩余是还没有读入的) 3.起始状态是所有点在最左侧的LR(0)项组成的封闭集,构建LR(0)自动机 4.构建LR(0)分析表。 5.进行分析。 如果X是终结符，只要有移进项先移进。 LR(0)文法无歧义需要没有归约归约冲突或移进归约冲突。 SLR(1)分析算法如果当前栈顶状态可以支持终结符移进，并且下一个记号也就是该终结符，才会移进。如果当前栈顶状态包含了归约项$A\\rightarrow\\gamma.$，且下一个记号在$Follow（A)$时，才会使用$A\\rightarrow\\gamma$归约，如果不在$Follow(A)$也不会做归约。$GOTO$项与LR(0)类似。 歧义的产生： 1)有归约项和移进项，且移进项$A\\rightarrow \\alpha . X \\beta$的下一个字符$X$在$Follow（B）$中,当然如果下一个记号不是$X$那么就没有歧义了。 2)有两个不同的归约项$A\\rightarrow\\beta.$，$B\\rightarrow\\gamma.$，且下一个记号即在A的Follow集也在B的Follow集，或者两个Follow集都没有$X$,此时要报错。 当确认没有歧义的时候，归约项$r(A\\rightarrow \\gamma)$就会被填入A的Follow集对应的Input下。","link":"/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"},{"title":"数字人文&人文计算","text":"上周二和综英老师聊了一下关于计算机怎么和文学之类结合，然后获得一枚关键词”数字人文”，遂找了几篇综述、文章以及YouTube的视频大概学了一下。发现真的是，自己瞎想怎么结合、怎么交叉，抵不过老师直接说一个研究分支来得快得多。 下面把记录下来，方便自己，也能方便别人叭：） 这个应该会不断更新。 各种实验室/组织 武汉大学数字人文研究中心 台湾”中央研究院”数位文化中心 北京大学kvision实验室 清华大学自然语言处理与社会人文计算实验室 数字人文组织联盟 可视化平台作品1.北大Kvision 在数字人文方面主要的成果： “中国历史人物生卒迁徙”可视化平台 “中国古代学术师承”可视化平台 “宋代学术传承”知识图谱 有意思的论文&amp;文章 文学经典的大数据分析与文化增殖 人文学科与社会科学的分野 Youtube视频 An Introduction to Digital Humanities","link":"/2019/04/23/%E6%95%B0%E5%AD%97%E4%BA%BA%E6%96%87&%E4%BA%BA%E6%96%87%E8%AE%A1%E7%AE%97/"},{"title":"【论文精读笔记2】利用文本挖掘估计作者的出生死亡年份","text":"这篇文章发表于TKDD，作者的主要工作是提供了一种文本挖掘的方法来估计作者的出生死亡年份。 对于一本书来说，确定它所属的年代以及它作者的身份是一项有趣的工作，其中它的引用和被引能够帮助我们解决这样的问题。 研究实验的对象主要是一些没有标注日期的希伯来语文献。通过对文本中的关键短语、关键词以及引用等信息的利用，作者提出了Heuristic(探索式）和Greedy(贪心的）定律和算法来估计一位作者的出生年份以及死亡年份。 1.来源[1]Dror Moghaz,Yaakov Hacohen-Kerner,Dov Gabbay. Text Mining for Evaluating Authors’ Birth and Death Years[J]. ACM Transactions on Knowledge Discovery from Data (TKDD),2019,13(1).完整版本： https://dl.acm.org/citation.cfm?doid=3301280.3281631 2.背景我们常能发现一些古籍被发现，这些古籍可能对于历史研究非常重要，我们希望知道它的作者。因此通过估计作品完成的时间，就能够推测出完成该作品的作者的人选。从另一个角度，如果知道了作者的出生和死亡年份，我们也能够推算出它的作者。我们考虑古籍中不同的作者会有相互引用的关系，如果能发掘和分析这些引用，就能够实现我们的目的。这些用于挖掘时序数据的定理是基于两种引用：一种是常规的引用（没有特定词），另一种是具有特定的代表时间的词，比如”Late”(表示对提及的作者的怀念，即提及的作者已经逝世了），”Friend”，”Rabbi”等。但古籍和一般的学术论文不同。在一篇学术文章中，文档具有良好的结构，想要发现关键词和关键短语更容易；同时，学术论文中的引用格式有明确的规定。对于Rabbinic Responsa( 一本古籍的名称）来说，它使用的引用在结构上比学术论文更为复杂，这就使得检索的难度增大。具体地说有以下几点原因：1.犹太教文本并没有类似学术论文中地的引用部分。2.该文本由三种语言写成，语言的形态较多。3.自然语言处理需要处理三种语言（希伯来语、阿拉姆语和意第绪语），目前的工作还没有很多进展。4.许多引用是有歧义的。5.引用没有标注时间。6.在引用中有很多由不同的结构和语法风格组成的冗余和半结构化的数据。目前对于希伯来语文本的研究目前并不算多，Mughaz使用机器学习的方法来分辨作者的写作风格。他的研究基于一系列不同时期的不同作家，这一研究的丰富性让Mughaz将他们集合在一起作为特征，得到函数。词缀集的使用是有效的，词缀时识别任务所使用的主要特征。（还有其他的一些工作在综述中，关于使用引用、用引用估计时间、关键词和信息检索的等，这里不详述了） 3.研究过程3.1 原理我们用X表示我们要估计出生/死亡年份的作家，Yi表示其余他引用或者被他引用的作家。加是我们知道所有Yi作家的生平，但并不知道X的。用B表示出生年份，D表示死亡年份，MIN表示一个作家能够开始写作的最小岁数（因为一位作家并不是生下来就会写作），MAX表示一个作家的最大寿命，RABBI_DIS表示一位犹太作家成为father的最小年龄。 MIN、MAX和RABBI_DIS的取值是需要探索的。对于年份的古籍，作者提出了三种具有不同程度上的确定性的规律：Iron-rules(I)、Heuristic-rules(H)和Greedy-rules(G)。Iron-rules如其名铁律，就是在任何时间都成立，Heuristic-rules在大部分的时间都成立，一些例外可能会出现，因为MAX、MIN以及RABBI_DIS这些常数的估计值会有误。 Greedy-rules 在实验中是符合的，但是仍然会导致其他文本中的出生死亡年份的估计。 所有的I和H的公式首先，以下是根据经验推断出的所有的I和H的公式。D(X) &gt;= MAX(B(Yi)) (0(I))D(X) &gt;= MAX(B(Yi)) + MIN (1(H))B(X)&lt;= MIN(D(Yi))-MIN (2(H))D(X)&gt;= MAX(Y) (3(I))D(X)&lt;= MIN(D(Yi)) (4(I))D(X)&gt;= MAX(D(Yi)) (5(I))B(X)&gt;= MAX(D(Yi))-MAX (6(H))B(X)&gt;= MIN(B(Yi))-(MAX-MIN) (7(H))D(X)&lt;= MAX(D(Yi)) + (MAX-MIN) (8(H)). 0.X引用其他人的时候，他在最年轻的被引用者出生前还没有死去。1.MIN更限定了X的死亡时间 因为MIN是预估出来的人能够开始写作的时间(不是一出生就能写作的)。2.X的出生日期，一定比被引用的人中最年轻的那位的死亡时间减去MIN要早。3.如果在特定年限中出现了X的作品，那么他的死亡年龄必然比该年晚(或等于该年）4.如果引用X的Yi中都明确地说过X去世的话 那么X的死亡时间必然比这群人中最早死去的人要早。5.如果X引用Yi 其中明确提到了Yi已经逝世，那么X的死亡时间必然比这群人中最晚死去的人还晚。6.一个作者的出生时间必然晚于引用他并且提到他已经死亡的其他作者中死亡时间最晚者减去MAX。7. MAX和MIN的差表征的是一个作家能够进行写作的时间段。最早出生的引用X的作家出生后 X出生最多要在MAX-MIN年后（否则最早的出生的引用作家就去世了）。8.X在引用他的最后一个作家死去后 不可能再活过MAX-MIN年。 ALL函数ALL函数是使用Iron和Heuristic函数中的所有公式结合起来的。B min B = MIN ({ B’ (B ≤I (i) ∧B ≤H (i))∀ i} ).B max B = MAX ({ B’ (B ≥I (i) ∧B ≥H (i))∀ i} ).D min D = MIN ({ D’ (D ≤I (i) ∧D ≤H (i))∀ i} ).D max D = MAX ({ D’ (D ≥I (i) ∧D ≥H (i))∀ i} ).最终对年龄的估计就是B（D)的最大值和最小值的均值。 Greedy Constraints（ 贪心约束）B(X)&gt;= MAX(B(Yi))-MIN (9(G))B(X)&gt;= MAX(Y)-MIN (10(G))D(X)&lt;= MIN(D(Yi))-MIN (11(G))X引用Yi的情况：B(X)&gt;= MAX(D(Yi))-MIN (12(G))B(X)&lt;= MIN(B(Yi)) + RABBI_DIS (13(G))B(X)&lt;= MIN(B(Yi)) + RABBI_DIS (14(G))X被Yi引用的情况：D(X)&lt;= MIN(B(Yi)) + MIN (15(G))D(X)&gt;= MAX(D(Yi))-RABBI_DIS (16(G))D(X)&gt;= MAX(D(Yi))-RABBI_DIS (17(G)) 9.被X提到的Yi名作家 他们中最晚出生的不能超过X可以开始写作的年龄（BX+MIN) 假设在X能够写作时，Yi名作家都还不能写作。10.X能够写作的年龄不能超过他在Y年写作的年龄，假设X引用的并不都是比他小的作者。11.X死亡的年份不会超过最早死的那个他引用的作者。 Turning Rules如果出现计算结果是一个作家活的年纪太大或太小，或者另一个情况是作者的死亡年份大于当前年份，需要对结果进行合理化。Deinition: D - death year, B - birth year, age = D-B.Current Year: if (D&gt;2017) {D = 2017}, i.e., if the current year is 2017, then the algorithm cannotresult in a death year greater than 2017.Age: if (age&gt;101), {z = age-101; D = D-z/2; B = B+z/2}, and if (age &lt; 30), {z = 30 - age; D =D+z/2; B = B-z/2}.同时假设作者的年龄不能超过101岁，不能低于30岁。 算法1.清洗数据。2. 挖掘半结构化的引用，根据关键词确定。3.将引用的格式规范化。4.建立索引，计算关键词出现的频次。5.使用上述的三种算法进行计算。6.计算三种算法最优值的均值。 3.2 实验数据集来自Bar-Ilan大学的Responsa项目，包括24111篇Responsa（由36位作者完成）。时间跨度为1765-2015年。这些作品包括很多引用。将这些文章按照作者数量分为了三组（12位作者组，24位作者组合36位作者组）。由于分为了三组，三组的时间跨度不同，需要将结果标准化进行比较。实验用G算法，I+H算法，以及ALL函数算法对于由或者没有year-feature分别进行了实验。即每一个组需要进行六次实验。 通过实验想要解决的问题 哪一种算法是最优的算法？ 使用turning rules的manipulation的效果是什么？ 不同的常数会造成怎样的效果？ 结合出的ALL函数是否起了帮助？ ALL函数是怎么进行帮助的？ 定义year-feature 使用了作者写某部作品的特定年份得到的结果composition 使用了turning rules以及其他常数进行估计的结果constant robustness: robustness包括实验层面上的和提纯层面上的。衡量算法的好坏是通过鲁棒性。STDV:standard deviation 标准差，用这个衡量结果的好坏。 3.3 结论1.从鲁棒性的角度看，Iron 算法，其次是Iron-year(有year feature的）算法，然后是G 算法，最差的是G-year算法。2.当观测STDV是，ALL函数的结果具有连续性（当作者越多，STDV降低），这就意味着当我们有更多的作者信息时，一些常数的变化不会影响到最终结果。I+H算法就没有这种连续性。 结合table4 和5，ALL函数也明显得到了更好的结果，并且随着作者的增加，结果也在变好，STDV在降低。 对于Greedy算法有和没有year feature的比较，越多作家数量，估计出生年份结果越好，但估计死亡年份时，当没有使用year feature，同样具有相同的趋势，当使用了year feature时，就不具有这样的趋势了。 论文中还提出了很多结论，以上只阐述了其中的几条，整个实验的总结如下。 整个实验的总结从稳定性的角度来说，ALL函数时最好的。ALL具有连续性，当作者的数量越多，结果越好。对于估计死亡年份来说，ALL函数使用year feature的实验结果最好。对于估计出生年份来说，ALL函数没有year feature的实验结果最好。综合来看，ALL函数是最优，因为他良好的连续性、稳定性和结果质量。 3.4 评估和之前的研究的对比table11和12显示了ALL函数相较于其他函数的提升。 Mughaz et al的结果比较： 未来的研究 测试以上提出的定律的新的组合，比如说将关键词组合在一起的结果。 更新相应的规则，生成新的规则。 考虑古籍中更多的关键词，比如事件、人名等。 用更多的资料对算法进行探究。 测试为什么这几种算法会给出更多的值为正的差（预估的比实际的更高） 通过更改上界，测试我们还能够获得多大的提高，并将其应用于更古老的作者的语料库中。 4.贡献 标准化了选取不同数量作者得到的结果，对于年龄预测结果的比较更加准确。 在前人研究的基础上，提出了更准确预测的算法，同时分析了算法的稳健性、对于算法中涉及到的关键词和常数的选取等。 最后一点小感想： 算是看的第二篇数据挖掘方面的，感觉很多还是没有完全读懂。还有一个体会是看TVCG多了，感觉再看B类的语言好像确实没有顶刊精炼（会写论文好重要啊…关于算法部分，我的一个疑问在于，为什么没有给出具体的实现算法，比如说ALL函数到底是怎么计算的(遍历吗？ 作者完全没有给出一行代码。另外还有一点，我认为这篇文章的数学公式里面应该把引用和被引用两种关系区分开来，用Yi表示其他作者（不区分引用和被引用关系）使读者在阅读的时候会有一点错乱。","link":"/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/"},{"title":"实验室交流note整理","text":"今晚鲍芝峰老师（BAO ZHIFENG, RMIT University, Australia)到实验室交流，主要是三四个学长学姐就自己的研究问题进行了汇报，或是提出了相关问题，然后鲍老师提出了质疑、建议以及可能的解决思路。我国际周选了鲍老师的一门Big Data Exploration, 上课内容还是比较令我感兴趣的, 后面有机会再详述。鲍老师第一天的课恰好让我解释一个公式的内容，对我算有一点点印象。不过我觉得他今晚在实验室里展现出来的和上课时有很大的不同。一是因为目的不同，上课毕竟是普及知识，实验室交流需要直击痛点、发现问题；二是受众不同，对于本科生，只需清晰地解释明白固定的知识，而对于研究生来说，需要快速理解他们所做的工作，同时发现问题，提出质疑和建议，相较而言更能体现出他灵活的思维和在领域中丰富的经验。鲍老师提出的建议基于研究生这一层次水平，但当他在讲的时候，我也觉得很有收获，想明白了一些事，然后突然就有很想静下心来多读一些论文的冲动（假期安排上）。以下列一些今天我觉得很值得记下来的东西。 1.要看什么论文?1）大牛的，不是国内的；建立自己的排名系统 CCF分类 CORE(澳洲系统）作者要看google scholar2）了解某个领域 A类会议的tutorial(类似presentation形式的survey） 从会议网站上能找到，通过读这个分类 发掘自己的工作是否具有创新性3）在整场分享中提到的会议和刊物: WWW KDD NIPS ICML CVPR（图好漂亮哇） AAAI(没劲）RECSYS(推荐系统） 2.研究问题的创新性在于？1）问题的solution很难有创新型，创新的可以是问题，对于问题细分，定义2）进行大量且充分的实验（实验的完整性，对比实验不能忽略掉重要的算法）一种写论文的思路：paper 的introduction很引人入胜 solution没人能看懂但是其实没必要，要让即使不是这个领域的人也能看懂文章 可以有的方式是用一个漂亮的例子，以一贯之的例子（KDD最佳论文提名）3） 和其他的baseline的对比，解决了某种方法的某个缺点。 3. Related work有多重要？related work很重要，要对自己要求高一些，找文献看文献要看最好的，即使是你自己的工作只能发B类，也要瞄准A类的问题和缺点，说明你的工作和别人的工作的区别。 4. 只看自己领域的文章吗？要拓出自己的领域。比如说如果想做可视化的推荐系统，只看可视化领域的文章相关的研究就很少，而且会因为可视化研究相似的研究思路而思维受限。一定要抛弃掉“我不这样做我就不对”的想法，要多看到不同的见解。 5. 通常可视化面临的问题是做出来一个系统发一篇文章，工作难以延展和拓宽，怎么解决？完全可以把一个系统拆分成多块内容，对于底层/上层等多个模块完全可以写出一篇文章，告诉别人，这个问题是独立的问题（垂直问题） [database领域也很少有人做可视化的工作] 6.怎么根据时长、受众调整自己的presentation？跟导师、同学交流要进行research，跟产业界更多地交流应用。可以考虑做动画。（KDD展示他们文章的youtube视频） 7.做实验的要求？1）严谨2）最开始的时候就应该有一个实验计划，把所有想到的实验都写出来，做多少个实验，画多少幅图。3）对于没办法做的实验，可以合理回避，但是需要说明为什么不能做。 8.哪怕不是自己领域的科研交流seminar，怎么听？(大三要听seminar的tips)1.要抱着主动的心态，甚至可以主动找一找讲者的错误；或者抱着想要给讲者留下印象的想法，就可以思考一下。2.可以提前搞清楚讲者的研究领域，准备交流。 9. 其他零碎的东西1.算法真的很重要。(假期安排吧）2.周报可以写自己的工作思路，开会之后要提交post meeting update，这样才体现出收获。3.LaTex上手容易精通难。可以用LaTex管理自己的reference(medenley) 避免duplicate(重复的论文引用）4. 我们都很有热情，想要实现出自己的想法，不想“水”，是想着要做最好的工作的。5.我们的学生如果前一天知道自己要在领域内的专家面前做presentation，哪怕前一天不睡觉，也一定要做出最棒的presentation，要让领域内的专家看到最好的自己。 最后要加一张图，小wy制作。","link":"/2019/07/04/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E4%BA%A4%E6%B5%81note%E6%95%B4%E7%90%86/"},{"title":"文本数据的聚类分析综述","text":"一、引言聚类分析是一种无监督学习方法，在模式识别中，对于给定的数据样本，类别标号已知的情况下，分类问题通过训练，使得能够对未知类别的样本进行分类。而现实世界中，相当多的数据是没有已知类别的，它们的类别缺失或者需要大量的人工标注才能获取类别。为了发现数据的内在知识、检测并分析异常点和从数据中提取模式，聚类分析是非常重要的。 聚类分析依据相似性，将给定数据样本划分成若干个类别，相似性越高的两个物体划分为同一类，最终会将数据形成若干个簇，簇与簇可根据它们的形状、大小和密度等有所区别。 生活中的多个方面聚类都能够辅助模式识别和数据挖掘。在产品市场上，聚类可以基于用户的购买对商品进行聚类，使得市场营销人员能够利用这些知识开发有针对性地计划；在城市规划上，聚类可以将相似性高的区域进行划分，为土地建设提供选址方案等。 随着全球信息化的不断发展，大量文本数据隐含着潜在的信息和知识。文本数据是一种非常常见的非结构化数据，针对文本数据的聚类应用领域也很广泛。在信息检索方向，文本聚类可对搜索引擎进行聚类，提升用户获取信息的精确度；在信息推荐方向，聚类还可以提取出热点主题或发现事件、自动归档文本并帮助完善文本可视化。 实现文本聚类主要由三个步骤组成：1.文档的表示（提取文档特征并对特征降维处理）；2.文本聚类算法的选择和应用；3.评估文本聚类算法的有效性。三个步骤将在接下来的4章中进行详细的探讨。 二、文本数据的特征提取计算机难以直接对字符串文本进行处理，需要将实际的文字转化成数值型数据。对文本本身来说，它具有一些显式的特征，如字数、词频、停止词数量、单词平均长度等。为了实现文本的聚类，上述的特征需要进行处理和调整，按照某种完整的模型对文档进行数值化或向量化。 当前的主要的文档模型可被分为五个类别：布尔模型、向量空间模型、概率模型、统计语言模型和分布表示模型。 （一）布尔模型布尔模型具有简洁的形式，容易理解。它的基础是集合论和布尔代数。我们考虑单词在文档中出现或缺失时，一个文档能够用二进制向量表示。 （二）向量空间模型向量空间模型是将文档表达为向量空间的一个矢量或点，向量空间的维数是词的数量。在向量空间的文档向量的长度是由出现的词和词的权重共同决定的[1]。在向量空间中，单词的顺序并不被考虑，这种方法也称为词袋表示方法（Bag of Words）。它是一种简单、经典的表示方法，但它对出现在文本中的词无法判定其重要性的差异，导致准确率不高。 1983年，Salton等提出了扩展布尔模型[2]，它结合了布尔模型和向量空间模型，并表现出检索性能的提升。 1986年，TF-IDF被提出[3]，这种表示改进了词袋表示法，每个单词的词频都由逆文档频率（IDF）规范化。在单词集合中，出现频率更高的项权重更低，降低了常用词在文档中的重要性，保证后续文档聚类的结果更受文档出现频率低的词的影响。 （三）概率模型概率模型中，文档)与查询)的相似度有如下关系：)表示相关文档集，)表示的补集。 对文档而言，根据独立性假设，文档的各个词相互独立，用表示词可得到： 其中词权重。 用)表示相关文档数，)表示包含索引词)的文档数，相关文档中)的分布, 不相关文档中)的分布),)表示包含索引词的文档数。 则可推出： 概率模型的优点在于，文档可以按照相关概率递减顺序来计算秩；但概率模型需要把文档分为相关和不相关的两个集合，未考虑到单词的频率，没有权重系数[4]。 （四） 统计语言模型统计语言模型(Statistics Language Models)是基于统计学和概率论对语言进行建模的，主要思想是语言是字母表上的概率分布，该分布表示一种可能性：即任何一个字母序列成为该语言的一个句子。这一分布就是语言的统计语言模型。目前较流行的统计语言模型是n元模型（N-gram），表示一个词的出现与否和其前面的n-1个词有关。 （五）分布表示模型分布式表示模型不仅考虑将单词符号化，还考虑将语义信息融入到词表示中。 1954 年，Harris提出了分布假说（ distributional hypothesis）上下文相似的词，其语义也相似[5]，这一假说为语义信息的融入提供了理论基础。 分布式表示根据任务、算法的区别，可被分为基于矩阵的分布表示、基于聚类的分布表示和基于神经网络的分布表示。在基于聚类的分布表示中，较典型的算法为布朗聚类方法(Brown clustering)，在第四章会具体介绍该算法。 三、样本的相似性度量文本聚类根据不同的粒度可以分为文档、段落、语句或者单词的聚类。样本在不同的粒度下代表的事物也有所区别，如文档聚类时，每一个样本表示一个文档。对文档进行聚类时，我们需要获知文档样本与样本之间的相似度，需要相似性的度量标准。 相似性度量可使用空间两点的欧式距离、向量内积、余弦相似度、Jaccard相似度等。 相似度的度量会在一定程度上影响算法的效果，目前也有大量的研究针对聚类的相似性度量，如2009年，Luo[6]等人应用了邻居和链接的概念，将全局信息引入到两个文档的相似性度量上，提出了新的相似性度量方式：使用余弦和链接函数组合等，总而言之，相似性度量并不存在最优的方法，需要和聚类算法结合。 四、文本聚类方法传统的聚类分析算法不仅可以用在文本数据上，其他数据也是通用的。针对文本表示的不同形式，使用的聚类算法也有所区别，文本聚类主要可以分为三类方法：划分聚类方法、层次聚类方法和基于标准参数化模型的方法。 （一）划分聚类方法划分方法符合我们对聚类的直观感受，将多个样本点组织成多个簇，通常簇的个数会在聚类前被给定，融合了相关领域的主观知识。 划分方法最初指定类别的初始数目，并不断迭代分配样本点，最终收敛时确定所有簇。划分方法运用在文本领域的主要有K-means和K-medoids两种聚类算法。 1. K-means聚类算法K-means算法最早是从不同的科学领域中提出来的，包括1956年的Steinhaus[7], 和1957年的Lloyd[8]，至今已经提出了近60年，但它仍然是目前应用于聚类的算法之一。 K-means通过判断根据平方误差法计算出的目标函数是否达到最优解，而逐步对聚类结果进行优化。在运行前需要指定簇的类别、初始的簇的中心点，在每次迭代中，将每个点分配给中心最近的聚类。中心是群中所有点的平均值，平均点的坐标是簇中所有点上每个维度的算术平均值。 原始的K-means的缺点主要有以下几点：首先，它只考虑了样本点之间的距离，通常结果均为球状簇。若从样本点的密度考虑，以DBSCAN算法为代表的基于密度的方法能够发现任意形状的簇。其次，K值、初始化分方向等均是需要用户给定的，容易陷入局部最优。 2.K-medoids聚类算法K-medoids聚类算法使用类中的某个点来代表簇，最早提出的K-mediods算法之一PAM(Partitioning Around Medoids) [9]的基本思想就是最初选取k个代表对象作为初始的中心点，依据当前cluster中所有其他点到该中心点的距离之和最小的准则函数，不断迭代找到更好的中心点。 该算法在一定程度上削弱了异常值的影响，但缺点是计算较为复杂，耗费的计算机时间比K-means多。它能处理任意类型的属性，但对异常数据不敏感。 （二） 层次聚类方法按照层次的聚类方法源于对数据需要组成层次结构的需求，数据需要进行层次结构上的汇总和特征化，因此层次划分方法被引入。层次划分方法可分为凝聚和分裂两种策略。 凝聚策略是将每个样本点在聚类最初都形成一个簇，随着迭代的进行，会将所有簇合并，直到终止条件为止。分类策略与凝聚策略正好相反，它将所有的样本点都看成同一个簇，相当于层次结构的根，将簇不断划分为更小的簇，直到划分的每一个簇都达到凝聚的条件。 以文档聚类为例，凝聚层次聚类方法可以被分为三类[10]：单连接算法（Single Linkage Clustering）、平均连接算法（Group-Average Linkage Clustering）、全连接算法（Complete Linkage Clustering）。 单连接算法的基本思想是两个簇的距离度量是从两个簇中抽取的每一对样本的最小距离,一旦最近的两个簇的距离超过某个任意给定的阈值，则算法结束。平均连接的基本算法是两个簇的距离度量是所有样本对的距离的平均值，全连接算法的距离度量则是两个簇所有样本对的最坏情况。 在针对文本数据的聚类中流行的层次聚类算法包括：综合的层次聚类方法BIRCH[11]，其优点在于能够通过单词扫描获取一个较好的聚类效果，但它只适用于数值型数据；基于质心和代表对象方法的CURE聚类方法[12]从每个类中抽取固定数量、分布较好的点作为代表点，并乘收缩收缩因子，减小噪音对聚类的影响；适用于分类属性层次的聚类算法ROCK[13],和使用动态模型的层次聚类算法Chameleon[14]。 1992年提出的布朗聚类方法[15]是一种针对词汇聚类的算法，它借鉴了层次聚类的凝聚策略，它的输入时一个语料库，语料库是一个词序列，输出是一个二叉树，二叉树的叶子节点是词，中间节点是对应的类别。它的评价函数是对于)个连续的词)序列能否组成依据话的概率的对数的归一化结果，评价函数为:$Quality(C)=\\frac{1}{n}logP(w_1,w_2…w_n)$。该函数描述了某个词上下文单词对当前聚类中单词的出现的预测程度。 Gil-García[16]等在2006年提出了一个基于图的凝聚层次聚类的通用框架，这一框架指定簇间相似度度量、β-相似度图的子图和覆盖例程，可以得到不同的层次的凝聚型的聚类算法；在2010年[17]，作者又提出了针对文档聚类的动态层次算法，该算法在获取和其他传统分层算法相似的聚类质量的前提下，层次结构更小、更利于浏览，可用于创建文档分类法和分层主题检测等模式识别问题。 层次聚类的鲁棒性较强，因为它通常需要比较所有的文档，因此复杂度达到。为了提升层次聚类方法的效率，多种改进方法被提出。如2018年，Zhang等人[18]提出了一个分区合并方案（PMHC）用于快速分层群集，它将数据对象分成适当的组并将它们合并到组中以节省计算成本。 （三）基于标准参数化模型的方法给定文档)，获取该文档属于不同簇的概率向量q，也是文档聚类的任务之一。考虑第二章中用统计语言模型表示文档的方式，可假定文档的生成过程是先以一定概率)选择簇),然后再按照词)的概率分布)选择词生成文档d,观测的所有文档在混合模型中被生成的概率为： 其中为“聚簇参数”，可通过期望最大化算法学习。该方法会陷入局部最优导致收敛速度较慢。 基于EM算法进行聚类的研究主要是基于EM算法对聚类方法的改进和提升，如2005年，Rigutini[19]等人将EM算法与基于信息增益的特征选择技术相结合，该算法只需要少量文档初始化聚类，并且能够正确地提取隐藏在大量未标记集合中的规则。2011年，Kim[20]等人基于EM算法，提出了一种文本文档的主题聚类算法，使用EM方法确保文档被分配给正确的主题，从而收敛到局部最优解，其结果具有较好的性能和可解释性。 EM算法衍生出了主题建模，它是一种对文档进行聚类并提取主题的无监督学习方法，可用来识别大规模文档集或语料库中潜藏的主题信息，广泛应用在文本分类、文本聚类、摘要抽取、情感分析等领域。 主题建模起源于潜在语义分析（LSA）[21]，该方法通过奇异值分解，将高维文档向量近似地映射到一个低维潜在地语义空间上，以达到降低文档维数和消除词语存在的同义、多义等问题。在LSA基础上，Hofmann引入了概率统计的思想，提出了概率潜在语义分析模型[22]。然而pLSA模型的参数容易与特定的文档相关，有时会出现过拟合现象，因此，Blei等人在2003年提出了LDA概率主题模型[23]，把模型的参数也看作随机变量，引入控制参数的参数，实现进一步的概率化。LDA本质上是一种无监督无指导的机器学习模型，将高维文本单词空间表示为低维主题空间，忽略了和文本相关的类别信息。 （四）其他聚类学习方法除了上述三点主要的聚类算法之外，针对文本数据的部分其他聚类算法将在本节进行简短的阐述。 模糊聚类需要根据研究对象本身的属性来构造模糊矩阵，并根据隶属度来构造模糊矩阵，最终确定聚类关系。它可允许一个文档属于不同的局促，使得聚类结果更稳定[24]。 半监督聚类是一种更新的研究算法，半监督聚类的核心思想是把半监督学习的思想结合到聚类中，通过少量的标签数据和先验知识提高聚类性能，得到性能更优的结果。在文本聚类中，使用半监督获取少量标签的聚类算法也有部分研究。 Zhang W 等提出了基于频繁项集和相似度计算的最大获取的文本聚类方法[25]。 五、聚类结果的评价 聚类结果并没有没有适用于所有算法的统一的评价指标，聚类算法结果的好坏取决于聚类算法的使用的相似性度量和相应的聚类算法。首先好的聚类的簇需要满足两个特点：簇内高内聚，簇间低耦合。其次，好的聚类能够发现隐含的模式，簇的形状没有较大限制；最后从用户的角度来说，能够产生一个满足用户的聚类结果，结果具有可解释性、可理解性。 （一）分类评价指标 通常，聚类任务可以使用分类任务的数据集（包含分类标签），衡量聚类的质量可以使用分类任务的评价指标。 1.召回率和准确率对于信息检索的结果，其计算包括了两个指标：召回率（Recall Rate）和准确率（Precision Rate）。召回率表示检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率；准确率是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；F 值为两者的调和平均值。 2.宏平均和微平均宏平均（Macro-averaging），是先对每一个类统计指标值，然后在对所有类求算术平均值。微平均（Micro-averaging**），是对数据集中的每个实例不分类别进行统计建立全局混淆矩阵，然后计算相应指标[26]。 （二）交叉检验方法将用于聚类的数据集划分为m个部分，随机使用m-1个部分建立聚类模型，并用剩下的1个部分检验聚类的质量。这一部分可以计算与他们最近形心的距离平方和作为度量，重复m次后，总体质量度量由质量度量的平均值计算出来，对不同的k，可以比较总体质量度量，最终选取最佳拟合数据的簇数[27]。 （三）聚类质量的测定当有专家构建的基准时，可将聚类模型和基准进行比较，比较时聚类质量度量Q如满足以下4项基本标准：簇的同质性、簇的完全性、碎布袋、小簇保持性，那么可以使用Q进行比较和评估。 当基准不存在时，可以采用轮廓系数对距离进行内部评估。 假设数据集D有)个样本被分为)个类别，则对于任意一个样本),计算)与)所在簇中其他对象的平均距离),)与其他簇的最小平均距离为。轮廓系数的定义为： 当轮廓系数为越接近1时，包含的簇是紧凑的，当轮廓系数值为负时，这种情况是糟糕的，应该避免。 六、聚类的局限性和挑战不同的文本数据有不同的特性，目前文本数据聚类的局限性也给文本聚类这一领域带来了新的挑战。 目前文本数据仍存在数据稀疏等问题，文档的词汇可能很多，但这些词汇是相互关联的，数据中主成分的数量远小于特征空间的特征数量。因此上述的所有聚类方法并不能解决所有文本的聚类问题。 近年来社交网络媒体和在线聊天应用创造了大量的文本数据，特别是短文本，短文本表示维数大，如何探索出更有效率、更节省空间的数据表示形式、如何将表示形式与聚类算法更好地结合在一起，是未来仍值得研究的课题。 文本数据也越来越多地出现在异构应用程序中，有效地将基于文本的算法应用于异构多媒体场景是非常关键的。P2P分布式文档聚类算法解决了其中的一些难题[28]，但对于开发结合优化技术的新型混合算法的研究仍有很大的需求。近年来的研究热点也集中在高维数据的处理上，不断提高处理速度和规模。 【后记-如果你还能看到这里】这是模式识别课程的最终提交论文（我靠着这个论文得了98分），找了几十篇论文掐头去尾粗略的看了，还是有很多不懂的地方，但至少对于这个方向有了一个框架上的概念。写综述真的很锻炼人哇… 参考文献[1] Salton, G. Some experiments in the generation of word and document associations [A].Proceedings of the December 4–6, 1962, fall joint computer conference[C].1962.234–250. [2] Salton, G.&amp; E. A. Fox.&amp; H. Wu. Extended Boolean information retrieval[J]. Communications of the ACM, 1983,26(11):1022–1036. [3]Salton, G.&amp;M.J.McGill. Introduction to modern information retrieval[M].New York.The McGraw-Hill Companies,1986. [4]McCullagh, P. What is a statistical model?[J]. Annals of Statistics,2002,30:1225–1310. [5]Harris, Z. Distributional structure[J]. Word,1954,10(23):146-162. [6]Luo, C., Li, Y., &amp; Chung, S. M. Text document clustering based on neighbors[J]. Data &amp; Knowledge Engineering,2009,68(11):1271–1288. [7]Steinhaus, H. Sur la division des corp materiels en parties[J]. Bull. Acad. Polon. Sci,1956, IV (C1.III):801–804. [8]Lloyd, S. Least squares quantization in PCM[J].IEEE Trans Inform Theory.1982,28:129–137. [9]Kaufman,L.&amp;,P.J.Rousseeuw.,Clustering by means of Medoids[J].Statistical Data Analysis Based on the L1–Norm and Related Methods,1987: 405–416. [10]Aggarwal, C. C.&amp;C.Zhai.A Survey of Text Clustering Algorithms[J]. Mining Text Data,2012: 77–128. [11]Charikar,M.&amp;C.Chekuri. Incremental clustering and dynamic information retrieval[J]. SIAM J Comput, 2004,33(6):1417-1440. [12]Guha,S.&amp;R.Rastogi.CURE: an efficient clustering algorithm for large databases[J]. Inf Syst,2003,26(1):35-58. [13]Dutta,M.&amp;AK.Mahanta.QROCK: a quick version of the ROCK algorithm for clustering of categorical data[J]. Pattern Recognit Letter, 2005,26(15):2364-2373. [14]Karypi,G.&amp;EH.Han.Chameleon: a hierarchical clustering algorithm using dynamic modeling. Computer,1999,32:68-75. [15]Brown,P,F&amp;V.J.Della Pietra.Class-Based n-gram Models of Natural Language[J].Computational Linguistics,1992,18:467-480. [16]Gil-García,J.&amp;M. Badía-Contelles&amp;A.Pons-Porrata. Extended Star Clustering Algorithm[J]. Lecture Notes on Computer Sciences,2003,2905:480-487. [17]Gil-García,R.&amp;A.Pons-Porrata.Dynamic hierarchical algorithms for document clustering[J].Pattern Recognition Letters,2010,31(6):469-477. [18]Zhang, Y.&amp; Cheung, Y. A fast hierarchical clustering approach based on partition and merging scheme[A]. 2018 Tenth International Conference on Advanced Computational Intelligence (ICACI).[C].Xiamen,2018.846-851. [19]Kim, S.&amp; Wilbur, W. Thematic clustering of text documents using an EM-based approach[J]. Journal of Biomedical Semantics, 2012,3(Suppl 3), S6. [20]Rigutini,L&amp;U.Adegli Studi di Siena.A semi-supervised document clustering algorithm based on EM[A].IEEE/WIC/ACM International Conference on Web Intelligence[C], Compiègne (France): Proceedings of the IEEE/ACM/WI International Conference on Web Intelligence,2005.200-206. [21]Deerwester,S&amp;S.Dumais.Indexing by latent semantic analysis[J].Journal of the American Society for Informatlon Science,1990,41(6):391-407. [22]Hofmann,T.Probabilistic latent semantic analysis[A].Proc.of the Conference on Uncertainty in Artificial Intelligence[C].1999:289—296. [23]Blei,D&amp;A.Ng A.Latent Dirichlet Allocation[J].Journal of Machine Learning Research,2003,3:993—1022． [24]C. Borgelt and A. Nurnberger.Fast Fuzzy Clustering of Web Page Collections[A].Proc. of PKDD Workshop on Statistical Approaches for WebMining（SAWM)[C],Pisa(Italy) 2004. [25]Zhang,W.&amp;T.Yoshida.Text Clustering Using Frequent Itemsets[J]. Knowledge-Based Systems,2010,23(5):379-388. [26]Yang Y. An evaluation of statistical approaches to text categorization[J]. Information retrieval, 1999, 1(1-2): 69-90. [27]Han,J&amp;M.Kamber.数据挖掘：概念与技术(原书第3版)[M].北京：机械工业出版社.2012. [28]Judith, J.E.&amp;J.Jayakumari.Distributed document clustering algorithms: a recent survey[J].Int. J. Enterprise Network Management,2015,Vol. 6, No. 3:207–221.","link":"/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/"},{"title":"文档主题建模","text":"对于一篇文章来说，分析它的主题能够达到理解文本的效果。主题建模就是通过在文档集合里面学习、识别和提取主题的过程。对于一篇文章 或者说一个文档来说，它包含着多个主题，而如何去区分不同的主题，是通过主题下面包含的多个单词来进行分析，我们能够将文档转化为一个数值向量，每一个维度对应一个主题。 作用 分类文档 （比如说不同领域的新闻：科技、金融、体育新闻。通过对新闻的主题建模，能够将文本按照主题来归类） 检索（当用户输入关键字的时候，就能够确认检索的文本的主题，从而在数据库进行匹配，最终返回相符的文本） 文本模型的可交换性目前，大多数文本模型都基于“bag-of-words”的假设，即 1.一篇文档内N个词之间的顺序可以随意互换，不影响建模过程 2.一个语料库内M个文档可以随意互换顺序，哪个文档在前哪个文档在后都无所谓。这两个性质合称为文本模型的可交换性 四种流行的用于主题建模的算法1.LSA(Latent semantic analysis)LSA的核心思想就是将我们所拥有的文档-术语矩阵分解成相互独立的文档-主题矩阵和主题-术语矩阵。词和文档是用向量来表示的，通过向量之间的关系，来判断词与词之间 或者文档与文档之间的关系。 2.pLSApLSA，即概率潜在语义分析，采取概率方法替代 SVD 以解决问题。其核心思想是找到一个潜在主题的概率模型，该模型可以生成我们在文档-术语矩阵中观察到的数据。 3.LDA将狄利克雷视为「分布的分布」。本质上，它回答了这样一个问题：「给定某种分布，我看到的实际概率分布可能是什么样子？」 一篇文档，可以看成是一组有序的词的序列。从统计学角度来看，文档的生成可以看成是上帝抛掷骰子生成的结果，每一次抛掷骰子都生成一个词汇，抛掷N词生成一篇文档。在统计文本建模中，我们希望猜测出上帝是如何玩这个游戏的，这会涉及到两个最核心的问题：上帝都有什么样的骰子；上帝是如何抛掷这些骰子的；第一个问题就是表示模型中都有哪些参数，骰子的每一个面的概率都对应于模型中的参数；第二个问题就表示游戏规则是什么，上帝可能有各种不同类型的骰子，上帝可以按照一定的规则抛掷这些骰子从而产生词序列。 4.lda2vec社交媒体如微博、脸书上也会有大量值得研究的文本，这些文本规模大、更新速度更快而且语义信息不丰富、噪声高。传统的pLSA和LDA模型泛化能力弱、主题词可解释性差、分类准确性低。 文档向量表示随着word2vec模型的提出和深度学习的发展,近年来出现了很多相关研究成果。以LDA为代表的主题模型认为文档的生成是不同主题混合的结果;神经网络模型习惯于将文档表示为稠密向量。如果结合前者覆盖范围广和后者维度低的特点生成新的模型,可以做到快速检测,同对隐含语义的解释也会更好。lda2vec模型就是基于这一思想提出的。","link":"/2019/11/26/%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/"},{"title":"【论文精读笔记1】文物数据可视化系统调查综述","text":"来源[1]Windhager Florian,Federico Paolo,Schreder Gunther,Glinka Katrin,Dork Marian,Miksch Silvia,Mayr Eva. Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges.[J]. IEEE Transactions on Visualization and Computer graphics,2019. 背景经过数十年的现代化，网络上出现了大量的来自美术馆、图书馆、档案馆和博物馆的文化遗产藏品，数字文化遗产数据不断增加，相关学者和一般用户的访问量也不断增多。最近许多方法已经开始允许可视化地访问文化收藏，并通过交互可视化的方式将其作为复杂全面的信息空间进行解释。与传统的Web界面不同，转为文化遗产部门的藏品设计的可视化类型更具有创新型和交互的多样性。 研究方法和贡献1.论文作者团队调查并回顾了数字文化遗产藏品的信息可视化方法，分析了70个文化遗产藏品的可视化系统（主要搜索包括信息视觉、视觉分析、人机交互、数字人文关系、数字艺术史和博物馆研究领域中相关期刊、出版物和会议中的作品），多角度对文化遗产藏品可视化界面设计的现状进行了研究和分析，并设计了一个网站来探索这个集合的可视化。 2.作为一个跨学科的团队，论文作者团队讨论了新的设计原则和策略，以及它们是如何解决了文化遗产藏品相关研究的挑战的。 什么是“CH DATA”? （文化遗产藏品数据）Tangible Assets:objects, tools, artworks, building Intangible Assets: arts, performing arts, crafts, expressions, customs, rites… Visualization of CH collections 文物藏品的可视化系统 作者团队选取了70个可视化系统，其中50个来自学术文献，20个来自面向公众的文物展示平台。在选择研究可视化系统时，遵循了以下的一系列限制: focus on approaches andinterface designs utilize InfoVis techniques 3D objects × 2.the search space is restricted to the culture sector personal photo/music × &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scientific text documents × 3.focus on CH object and asset collections cultural-historical entities( e.g. actors, events) × 这张图片中左侧显示了所有类型的文物数据，右侧是展现了单个文物的类型以及与它相关联的其他信息，如时间、创造地点、作者、时间或是与其他文物的关联。 Classification作者先就所有的文物可视化系统进行了分类，一共分出了七类。 1.Data 1.Object-centric approach 2.Event-centric approach 2.UsersDistinguish 2 classes of users: 1.Experts 2.Casual users 3. Tasks 1.Elementary tasks 2.Synoptic tasks 4.Granularity1.Single Object Previews 2.Multi-Object Previews 3.Collection Overviews Utilizing Discrete Surrogates 4.Collection Overviews Utilizing Abstractions 5.Interactivity1.Object Search 2.Overview and Orientation 3.Vertical Immersion or Abstraction 4.Accessing Object Details 5.Horizontal Exploration 6.Curated Path 6.Temporal Visualization Methods7.Non-Temporal Visualization Methods 最终基于这些分类呈现出了一个很大的表格。 **Survey And Analysis of The Interface1.The development of CH visualization 2.Casual VS. Expert Use &nbsp;Interfaces for casual users focus more onimage objects **thanapproaches for professionalusers, andoften also display a thumbnail of the image itself; Expert interfaces use fewer lists, grids, and tagclouds than casualinterfaces. Casual users interface should be simpler and provide few ways of visualization data *3.A founding * No hybrid systems integrating InfoVis techniques with 3D rendering techniques( e.g. of real or virtual museums) a particularly interesting unexplored possibility and future potential (also for VR/AR guides) 4.Intangible CH data a remarkable shortage of interfaces enabling access to intangibleobjects or practices,such asmusic, film,performing arts,or linguistic entities(e.g., narratives, folk tales, orpoems). Discussion1.SerendipitySerendipity -&gt; concept inlibrary and information sciences “the faculty or phenomenon offinding valuable or agreeable things not sought for” Options for Operationalization 1.emulating the serendipitous information space of a library or museum in digital CH interfaces 2.offer a slightly more serendipitous access in the sense that related or similar objects to the one searched for are also recommended based on existing object taxonomies or user-generated tags 2.Generosityprovide rich and navigable representations that encourage exploration and browsing， while overviews establish context and maintain orientation duringaccess to details atmultiple scales. playful extensions of information seeking towards less goal-oriented information activities, such as satisfying curiosity, enjoying aesthetics, and avoiding boredom 3.criticalitycriticality -&gt; reflections and design strategies, that can help to meetspecific epistemic standards in various humanities,arts, and CH communities. the understanding of CH collections as dynamic entities *that can be formed, re-arranged, contextualized, and annotated through innovative forms of participation can be specifically supported. Equally, *InfoVis and interface design holds the potential to allow for multiple, uncertain, and sometimes even conflicting perspectives and narratives to surface. 4.User Guidance and NarrationUserGuidance: Existingmetadataof CHcollections oftensupport faceted browsing and recommendationscorrespondingto data dimensions narratingthe collection:telling a story by selectingand presentingobjects in a purposeful manner, accompanying themwith additional information, and even guidingvisitors throughand between exhibits &nbsp; narrativeguidance can be implemented, for example, as animatedmovements across a map,which mayinclude different textual and visual source materials . 5.Remote Access VS Being ThereInfoVis systems developed primarily for remote use will notnecessarily serve the information needs (or maybe ratherexpectations) of museumvisitors We consider the in-situ use of exploratory interfaces and collection visualizations inreal CH exhibition settings to be a largely unexplored area of application. 6.Facets of UncertaintyUncertainty:how to deal with uncertain data already belongs toone of the standardexercises ofthe field a lack of discussion on the same level challenging metadata :“date” The acknowledgment of imprecision and interpretative openness that is present in textual sources in the humanities have hardly been acknowledged in the design of CH interfaces and visualizations. 7.ContextualizationLinked data is a way of publishing structureddata that allowsmetadata ofdifferent local databases to be connected and enriched uniquely identifying entities (such as cultural artifacts, creators, institutions, places, or events) and drawing typified (e.g., temporal, spatial, contextual, and conceptual)links between them, linked data initiatives weave CH-specific knowledge graphs and relational tissues into the Semantic Web.","link":"/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/"},{"title":"【综述总结1】Analysis Methods in Neural Language Processing:A Survey","text":"行文结构论文进行综述时很善于从多个维度对工作进行分类，比如使用的方法、语言现象等。（作者也输出了一张表格、通过不同的维度归纳了相关的工作）。整体来说是按照不同角度下的方法进行综述，比如有一章专门写了自然语言处理中的可视化方法和衡量的难度性。同时最后将所有本文的结论写在了结语。 Section 1 Introduction对全文脉络进行梳理 Section 2 什么样的语言信息会被神经网络使用？阐述从三个方面回答这一问题（和小标题对应）： which method are used 使用什么方法 what kind of linguistic information is sought 什么信息 which objects in the neural network are being investigated 什么被观测 2.2 Linguistic Phenomena sentence length 句子长度 word position 单词位置 word presence 文字出现 simple word order 简单词序 morphological information 形态信息 syntactic information 句法信息 semantic information 语义信息 other phenomena Section 3 可视化方法和衡量可视化工作的难度性Section 4 用于细粒度评估的挑战集的编译datasets used for evaluating neural network models that diverge from the common average case evaluatio 分类数据集的依据： the task they seek to evaluate the linguistic phenomena they aim to study the language(s) they target their size their method of construction how performance is evaluated Section 5 对抗性例子的产生和使用、神经网络的弱点Section 6 解释模型预测的工作Section 7 其他不归于上述主题的方法引用他人工作的句式 see somebody for example They found … suggesting that In contrast, Somebody made some headway on this question. Somebody noted several key properties… conducted behavioral experiments 其他句式 enable them to draw conclusions about… synthesize a holistic picture from this diverse body of work Another theme that emerges in several studies is… Much recent work has focused on … … have gained renewed popularity in the NLP community. Most of the relevant analysis work is concerned with… Method … may shed new light on some of these questions. A long tradition in work on (domain) is to …","link":"/2020/04/30/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93/"},{"title":"知识：\"Why\"和未串好的项链","text":"“规律” 这个世界的发展不是随机的。目前的我认为，世界的演变是由一系列的因果组成的。就像函数的映射，原因映射到结果。而目前呈现的状态是由无数的参数经过某种映射关系得到的结果。计算理论告诉我，由一个状态变为另一个状态，需要有一个转移函数。那么世界当前的状态，可能是由一个接受前一个状态的转移函数通过计算而得到的。 &nbsp; 或许存在一个答案，或者一个公式，是宇宙的运行的依据，或者那种东西可以称之为”道”。而这个道，人类还没有完全抓住，完全理解。而道本身从何而来，为何产生，那就是更高阶的问题，更不可能回答。”道”就是宇宙的转移函数。 &nbsp; 而我之所以是我，没有变成其他的样子，没有思考到别的东西，是由这个规律决定的，或者可以说，从出生，甚至出生之前的时间，都决定了我的存在。我认为是有更高的意志无形地在统治这个世界，同时也统治着我，但是这种统治我无法感知， 也无法证明它的存在。很多时候，我以为是我自己的思考，主观意识在决定我的行动，但其实我现在的状态可能也只是宇宙的那个终极的公式计算出来的产物。 &nbsp; 按照这种想法，所有的一切都不需要感到奇怪，包括阴暗的、变态的、丑陋的、邪恶的一切，因为所有的东西都是”合理”的，也就是说，终极函数计算出的结果，是准确的。 &nbsp; “好奇心” 人类的美妙之处，在于好奇心。我们人类有源源不断的好奇心，这让我们去思考，我们看到苹果掉下来，看到日月星辰的变化，看到高高低低的豌豆，但我们没有忽略它们。我们提出了很多很多的”为什么”，而同时也不断回答着为什么。 &nbsp; 科学的发展，就像是无数好奇心旺盛的人类在试图破解那个统治世界的”规律”。只是那个规律太大，太复杂，于是我们把它不断拆解、细分，分出不同的学科和领域，在领域里，甚至还加上很多的限定。靠着实验和现象，或者猜想和假设，我们推理出很多适用在小范围内的规律。 &nbsp; 人类科学家们就像是一群裁缝，世界的”规律”就像是一串完美又巨大的项链，而为了完成这串项链，目前科学家的工作，仅仅是将找到的珠子进行了排列。他们发现有些珠子之间还缺少着很多颗珠子，因此串珠子的工作根本无法开始。 &nbsp; 这是一项艰巨的工作，好在我们还有”好奇心”，向未知发问的能力我们不会丧失，即使越来越多的人失去，但火种还在， 尽管是微弱的光，我认为光还是在。 &nbsp; “存在” 我记得大概是五岁的时候，我突然对这个世界的存在产生了怀疑。为什么我能看见所有的颜色；为什么我能听见妈妈的声音或者电视机里传来的声音；为什么我会有意识，为什么我会存在。这种感觉给我带来一种超脱感和异常感。然而我慢慢地接受了，也就再也没有想过这样的问题。 &nbsp; 而随着年龄的增大，”为什么我会存在”这种问题，逐步转变为，”我存在是为了什么。” 我曾经的想法是，存在的意义在于体验。我所经历的一切都可以被称之为体验。但是这个回答不太能让我满足，”体验”之后呢？ &nbsp; “体验”之后的东西太虚无了。我记得我在某个晚上突然想到，人是一个导管，苦乐流过，导管在这个过程中的颜色，形状都发生了改变，而最后，当时间河流停滞，我们这样的改变又有什么意义呢？仅仅如此吗？ &nbsp; “意义” 追求知识的人们是在干什么呢？探索答案的人们是在干什么呢？我们人类是要干什么呀？我们存在于此是要为什么呀？ &nbsp; 是为了想要学习从未认识到的东西，是为了解答所有内心深处的”为什么”，是为了满足我们最原初的好奇心，是为了最终能够串起那串代表着世界的终极规律的项链。因此，存储在数据库的所有论文，所有的书籍，所有用英文用中文用各种各样的语言写成的东西，所有的信息，所有能被数据保存下来的东西，都是排列好的小部分珠子。 &nbsp; 我们想要弄懂这个宇宙运行的规律。 &nbsp; 弄懂这个世界。 &nbsp; 我记得的大学里最美的一个场景，就是我走在一教A的走廊，当时两边的教室里都在上课，只言片语间，我仿佛置身于一条河流，不由自主地感觉到幸福和平静。尽管我不清楚每一间教室里讲的具体内容，但是我看见了那些前人所发现并排列好的珠子闪烁的光彩。 &nbsp; 如果从很大的层面来看，现在的我认为，人类的意义在于发现这个世界的规律。而对于个体来说，能够做的事情就是在串珠子这项工作中，再进行一些珠子的排列，这或许就是所谓”意义”。 &nbsp; “科学” 什么是科学？先前我说，这个世界是存在一个终极规律的，而科学就是发现这个终极规律的子集的过程。 &nbsp; 如果细分来说，科学又分为自然科学和人文科学。 &nbsp; 之前和LZX聊到科学的时候，我提到实验室学长分享的论文，有跟她说到终极规律这个问题。但是她说我们以为的因果关系很可能并不成立，我想到如果是自然科学依赖因果性推出的结论，很可能就根本不是正确的。而同时，对Humanities的短暂接触和阅读，也让我认同她说的，人文学科是建立在假设和猜想上的，它承认了它本身的主观性和不可靠。 &nbsp; 而某种程度上，我一直信仰的自然科学，或许根本就是一种宗教也不一定。依靠现想和推理产生的理论，正确率如我所想象的高吗？（这个问题我还没有想清楚，还是先读书叭） 而会不会还有一种可能，就是想得悲观一些，可能当我们终于串好了这串珠子，拿到上帝面前，去问他终极的规律究竟是什么的时候，他或许否认了终极规律的存在，或许答案就是一片混沌或是虚无的存在。（就像lulu之前讲过的上帝和科学家得故事，我们明白了事物的”为什么”，但是无法解答”为什么”本身的存在原因。） &nbsp; 不过我首先会认为这串珠子很难串得好啦。 &nbsp; 再说到人文学科，我现在觉得它的研究范畴和我曾经以为的有很大不同。文学理论研究者费尽心思地去研究某个作者，某部作品，绝不是什么”无用之学”，我认为是在研究人的思想，人的精神，人的本质的演变过程，看起来是在研究他人，实际上是在研究我们自己。如果说自然科学更多的是向外研究，那么人文社科其实是在对内，向内去探索。 &nbsp; “时间线” 周四学长分享的论文，是通过分析不同学生的学习规划（选的课、发的paper、参加的活动）以及最后的职业，当学生想要达到不同目标时能够基于之前的时间事件序列给出推荐的路线。 &nbsp; 每个人的时间事件序列就是一条线，然后沿着那条线往前，自然而然就会得到某种结果。这是”终极规律”决定的。然后我就想，如果真的能够把所有的人的时间线都收集起来，进行处理，是不是可能实现个人的最优时间线推荐呢？我想要达到这样的目标，那么我就按照这样的时间线去进行就好了？ &nbsp; 这听上去很理性，科学，计算机。所谓”人生路径推荐系统”这样的东西，或许真的有可能实现吧。不过要想实现这样的机器，还是需要弄懂”规律”，难就难在是要弄懂一些难以量化的、向内的、充满主观性的规律。（这已经是人文学科的范畴了，因此用主观的方法去研究，本身就很难统一发现的规律） &nbsp; “和解” 不过对于时间线的思考终究还是有它的意义。我感觉我终于慢慢地和自己和解了。 &nbsp; 由于实时性，我们能看见所有人在当下的状态，却不能知道他的整个时间线。看见了同时刻的人的优秀，十分浮躁。但是想想如果按照时间线的逻辑，我在我的时间线里本应该潜心输入的时候却在羡慕别人时间线他们的输出，反而没把自己的时间线做好。 &nbsp; 我时而想起高中。那个搞化竞眼睛发光的人，我再也没有在大学里看到那样的人，可能有些人的气质跟他相近，但也没有他那样的热情和执着；那是就很羡慕周围的同学，自己暗暗地躲在小角落里，或者去图书馆找书看；最开心的时候就是跟同桌严肃地讨论人生观价值观，而我也再没有在大学和周围人那么深入地探讨过无关情感的思考（现在比较严肃的是在讨论婚姻观、LGBT啥的）。 &nbsp; 但是我终于渐渐不因为自己菜而失落。尽管包含着对知识的热爱，但是也明白自己的能力可能找不到珠子。但是还是会把这个视为追求，努力去实现。 &nbsp; 世界仍是未知的，为了解答”why？”, 找到珠子，我们要掌握到尽可能多的已知的珠子。而终极规律是否存在，也是要等到我们基本上串完项链之后再说吧。 &nbsp; 其他 事实上，我觉得探索自己的内心和他人的关系，其实也是在找珠子，只不过那样的珠子没有被严肃地记录下来，但他们终究是智慧。 &nbsp; 比如说恋爱可能也是一种找珠子的过程，你在这一过程中不断地认识自己，你发现了适用于两个人范围之间的规律，但其实你并不会把它以理论形式记录下来，而是实实在在地运用于生活，这就很好。（我还是想谈恋爱，因为想找到那个珠子，所以想脱单是因为好奇心：） &nbsp; 但是当见识广了，找到想要发现的珠子所在的区域之后，这些生活上的小珠子带给我的好奇心，相比之下就没有那么大了。 &nbsp; 哎我竟然还有好多想写的，等我多读点书，应该就会又有不一样的思考吧，这时间段的思考先记录于此。","link":"/2019/05/02/%E7%9F%A5%E8%AF%86%EF%BC%9AWhy%E5%92%8C%E6%9C%AA%E4%B8%B2%E5%A5%BD%E7%9A%84%E9%A1%B9%E9%93%BE/"},{"title":"【综述总结2】More Data,More Relations,More Context and More Openness:A Review and Outlook for Relation Extraction","text":"行文结构先关注于现有的工作，按照模型分类，其次探讨了关系提取的更多方向，主要是从数据量、学习表现、场景、领域四个方面，恰好和题目呼应；最后提出了其他的挑战。 Section 1 IntroductionRE: relation extraction Section 2 背景和现有的工作2.1 模式提取模型2.2 统计关系提取模型2.3 神经网络关系提取模型Section 3 RE的更多方向3.1 使用更多数据3.2 学习表现更有效3.3 在更复杂的场景中实现3.4 面向更开放的领域Section 4 其他挑战4.1 从文本或实体名中学习4.2关系提取数据集","link":"/2020/05/02/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93-2/"},{"title":"【编译原理复习专题4】语法制导翻译","text":"语法制导翻译，边做语法分析，边做语义分析。它使用CFG引导对语言的翻译，是一种面向文法的翻译技术。 语义信息如何表示语义信息？ 将语言结构的语义以属性(attribute)的形式赋予代表此结构的文法符号。 如何计算语义属性？ 属性的计算以语义规则(semantic rules)的形式赋予由文法符号组成的产生式。在语法分析推导或归约的每一步骤中，通过语义规则实现对属性的计算，以达到对语义的处理。 换句话说就是：为每一个产生式配上语义规则并且在适当的时候执行这些规则。 SDD 语法制导定义SDD是一个上下文无关文法和属性及规则的结合。属性和文法符号相关联，而规则和产生式相关联，有时也称为属性文法。如果𝑿是一个符号，而𝒂是𝑿的一个属性，那么用𝑿.𝒂来表示在某个标号为𝑿的分析树节点上的属性值。属性可以有很多类型，比如变量的数据类型、表达式的值、变量的地址、数字的有效位数等等。 属性属性分为综合属性和继承属性。 综合属性只能由当前结点或者结点的子节点的属性值来计算。通常，产生式左侧的属性都来自右侧的话，那么左侧的属性就是综合属性。 继承属性是由当前结点的父节点或兄弟节点或本身的属性值来定义的。（只要有父节点或兄弟结点定义就是继承属性了） 终结符可以有综合属性，就是词法分析的词法值。终结符没有继承属性。 属性文法写成表格形式，相同的非终结符需要用下标区分。 S属性的SDD只包含综合属性的SDD称为S属性的SDD。它可以按照任何自底向上的顺序进行求值。 L属性SDD的特例。 L属性的SDD要么是综合属性，要么是继承属性，且满足以下i条件： 对于产生式$A\\rightarrow X_1 X_2 …X_n$,$X_i$的继承属性仅能依赖于： A的继承属性（如果是综合属性可能会有环路） 产生式$X_i$左侧的属性。（继承属性只能右侧的继承左侧的，规定了依赖图的边只能从左往右) SDD的求值如果是综合属性，就可以按照任何自底向上的顺序进行求值，如果是同时具有继承属性和综合属性的话，首先要看有没有出现环状的依赖关系，最好不要出现循环的情况。 1.绘制依赖图dependency graph 2.求DAG的依赖图的拓扑排序（如果图存在环，就不存在拓扑排序） 拓扑排序不是唯一的，平行关系可以交换。 SDT 语法制导的翻译方案SDT是在产生式中嵌入了程序片段的一个上下文无关文法。这些片段称为语义动作，它们可以出现在产生式的任何位置。默认用{}括起来。 SDD时语言翻译的高层次规格说明，隐藏了很多具体实现细节，使用户不必显式地说明翻译发生的顺序。 SDT是SDD的一种补充，是SDD的具体实施方案，显式地指明了语义规则的计算顺序，以便说明某些实现细节。 语法制导翻译可以用于抽象语法树的构建， 如何用SDT实现两类重要的SDD产生式右侧的动作在它左边的所有文法符号后被匹配后立即执行。 将内嵌语义动作替换成一个新的非终结符，可以执行相应的语义动作。 S属性的SDD后缀翻译方案： S属性的SDD可以构造出SDT: 每个动作都放在产生式的结尾。 所有属性都是综合属性。 产生式内部带有语义动作的SDT$B\\rightarrow X{a}Y$ 自底向上，X出现在分析栈栈顶时，立即执行动作a。 自顶向下，在展开Y的本次出现或者在输入中检测Y之前执行动作a。 L属性的SDD将计算某个非终结符号A的继承属性的动作插入到产生式右部中紧靠在A的本次出现之前的位置上。 将计算一个产生式左部符号的综合属性的动作放置在这个产生式右部的最右端 。 如果基本文法可以用LL分析，那么可以用递归下降、在LL预测分析过程中翻译(属性值存放在语法分析栈中)或者用LR分析。 在递归下降分析中加入语义翻译函数A的参数是非终结符A的继承属性函数A的返回值是非终结符A的综合属性","link":"/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/"},{"title":"【编译原理复习专题3】语法分析的例子整理","text":"SLR(1)考虑文法： $E\\rightarrow E+T|T$ $T\\rightarrow T*F|F$ $F\\rightarrow (E) |id$ 1.扩展文法： $E’\\rightarrow E$$E\\rightarrow E+T|T$$T\\rightarrow T*F|F$$F\\rightarrow (E) |id$ 2.LR(0)项： 3.绘制LR(0)自动机： 4.由状态1、2、9可发现，这个语法有移进归约冲突，因此不是LR(0)文法， 而在状态1中，Follow(E’)={$},+不在E’的Follow集里面的，因此无歧义，在状态2和9中，Follow(E)={+,(,$},*不在E的Follow集里，也无歧义，该文法是SLR(1)文法。 5.构建SLR(1)分析表。 6.串(id+id)*id的分析过程: stack input action 1 $0 (id+id)*id$ S4 2 $0(4 id+id)*id$ S5 3 $0(4id5 +id)*id$ $r(F\\rightarrow id)$ 4 $0(4F3 +id)*id$ $r(T\\rightarrow F)$ 5 $0(4T2 +id)*id$ $r(E\\rightarrow T)$ 6 $0(4E8 +id)*id$ S6 7 $0(4E8+6 id)*id$ S5 8 $0(4E8+6id5 )*id$ $r(F\\rightarrow id)$ 9 $0(4E8+6F3 )*id$ $r(T\\rightarrow F)$ 10 $0(4E8+6T9 )*id$ $r(E\\rightarrow E+T)$ 11 $0(4E8 )*id$ S11 12 $0(4E8)11 *id$ $r(F\\rightarrow (E))$ 13 $0F3 *id$ $r(T\\rightarrow F)$ 14 $0T2 *id$ S7 15 $0T2*7 id$ S5 16 $0T2*7id5 $ $r(F\\rightarrow id)$ 17 $0T2*7F10 $ $r(T\\rightarrow T*F)$ 18 $0T2 $ $r(E\\rightarrow T)$ 19 $0E1 $ accept 因此该串被接受。","link":"/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/"}],"tags":[{"name":"gitbook","slug":"gitbook","link":"/tags/gitbook/"},{"name":"小技巧","slug":"小技巧","link":"/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"数据可视化","slug":"数据可视化","link":"/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"编译原理","slug":"编译原理","link":"/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"word","slug":"word","link":"/tags/word/"},{"name":"知其所以然","slug":"知其所以然","link":"/tags/%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"杂谈","slug":"杂谈","link":"/tags/%E6%9D%82%E8%B0%88/"},{"name":"数字人文","slug":"数字人文","link":"/tags/%E6%95%B0%E5%AD%97%E4%BA%BA%E6%96%87/"},{"name":"TKDD","slug":"TKDD","link":"/tags/TKDD/"},{"name":"数据挖掘","slug":"数据挖掘","link":"/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"name":"文本挖掘","slug":"文本挖掘","link":"/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"},{"name":"论文笔记","slug":"论文笔记","link":"/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"论文","slug":"论文","link":"/tags/%E8%AE%BA%E6%96%87/"},{"name":"交流","slug":"交流","link":"/tags/%E4%BA%A4%E6%B5%81/"},{"name":"科研","slug":"科研","link":"/tags/%E7%A7%91%E7%A0%94/"},{"name":"聚类分析","slug":"聚类分析","link":"/tags/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"},{"name":"主题建模","slug":"主题建模","link":"/tags/%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/"},{"name":"TVCG","slug":"TVCG","link":"/tags/TVCG/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"综述","slug":"综述","link":"/tags/%E7%BB%BC%E8%BF%B0/"}],"categories":[]}