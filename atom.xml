<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ruoting Wu&#39;s Blog</title>
  
  
  <link href="https://wuruoting.club/atom.xml" rel="self"/>
  
  <link href="https://wuruoting.club/"/>
  <updated>2021-04-09T13:40:52.261Z</updated>
  <id>https://wuruoting.club/</id>
  
  <author>
    <name>Ruoting Wu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图神经网络里的监督/半监督和转导/归纳概念解析</title>
    <link href="https://wuruoting.club/2021/04/09/2021-04-09-GNN-classification/"/>
    <id>https://wuruoting.club/2021/04/09/2021-04-09-GNN-classification/</id>
    <published>2021-04-09T13:23:45.000Z</published>
    <updated>2021-04-09T13:40:52.261Z</updated>
    
    <content type="html"><![CDATA[<p>监督(supervised)和半监督(semi-supervised)其实是转导（transductive)和归纳(inductive)</p><p>对于节点分类来说，如何区分监督学习和半监督学习的关键在于节点在训练过程中被使用的区别，也就是训练集节点是否被用在GNN的消息传递操作中，并且会被用于计算损失。</p><p>transductive的测试节点是无标签的，并且不会被使用在损失计算中，但是这些点和相关的边会被用于消息传递中，也就是说图神经网络会生成测试集节点的潜在表示中，但是最后一层的表示不会被用在损失函数的计算中。</p><p>indutive的测试节点既不会用在GNN的消息传递过程中，也不会用在损失函数计算中，也就是说，inductive在GNN训练的过程中完全不会被包括。</p><p>半监督指的就是GNN会使用transductive的测试节点组成的测试集，也就是说在训练的过程中实际上是能够看到测试的节点的（但不能看到label）。监督指的就是在做归纳式的节点分类时，测试的节点是完全不会被检测到的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;监督(supervised)和半监督(semi-supervised)其实是转导（transductive)和归纳(inductive)&lt;/p&gt;
&lt;p&gt;对于节点分类来说，如何区分监督学习和半监督学习的关键在于节点在训练过程中被使用的区别，也就是训练集节点是否被用在GNN的消</summary>
      
    
    
    
    
    <category term="图" scheme="https://wuruoting.club/tags/%E5%9B%BE/"/>
    
    <category term="机器学习" scheme="https://wuruoting.club/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>关于Keras</title>
    <link href="https://wuruoting.club/2021/04/08/2021-04-08-keras/"/>
    <id>https://wuruoting.club/2021/04/08/2021-04-08-keras/</id>
    <published>2021-04-08T02:47:25.000Z</published>
    <updated>2021-04-09T09:28:47.190Z</updated>
    
    <content type="html"><![CDATA[<h2 id="生成模型的关键步骤"><a href="#生成模型的关键步骤" class="headerlink" title="生成模型的关键步骤"></a>生成模型的关键步骤</h2><h3 id="model-add"><a href="#model-add" class="headerlink" title="model.add()"></a><code>model.add()</code></h3><h3 id="model-summary"><a href="#model-summary" class="headerlink" title="model.summary()"></a><code>model.summary()</code></h3><p><code>model.summary() #打印神经网络结构，统计参数数目</code></p><h3 id="model-compile"><a href="#model-compile" class="headerlink" title="model.compile()"></a><code>model.compile()</code></h3><p>在配置训练方法时，告知训练时用的优化器、损失函数和准确率评测标准</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer = 优化器</span><br><span class="line">              loss = 损失函数，</span><br><span class="line">              metrics = [<span class="string">"准确率”])</span></span><br></pre></td></tr></table></figure><h3 id="model-fit"><a href="#model-fit" class="headerlink" title="model.fit()"></a><code>model.fit()</code></h3><p>The history object returned by model.fit() is a simple class with some fields, e.g. a reference to the model, a params dict and, most importantly, a history dict. It stores the values of loss and acc (or any other used metric) at the end of each epoch.</p><h2 id="模型的保存"><a href="#模型的保存" class="headerlink" title="模型的保存"></a>模型的保存</h2><h3 id="保存模型参数：model-to-json"><a href="#保存模型参数：model-to-json" class="headerlink" title="保存模型参数：model.to_json()"></a>保存模型参数：<code>model.to_json()</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(model_json)</span><br></pre></td></tr></table></figure><h3 id="保存-weights-model-save-weights"><a href="#保存-weights-model-save-weights" class="headerlink" title="保存 weights:model.save_weights()"></a>保存 weights:<code>model.save_weights()</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save_weights(<span class="string">"model.h5"</span>)</span><br></pre></td></tr></table></figure><p>.h5 文件</p><h3 id="保存某一层的输出：model-layers-index-output"><a href="#保存某一层的输出：model-layers-index-output" class="headerlink" title="保存某一层的输出：model.layers[index].output"></a>保存某一层的输出：<code>model.layers[index].output</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inp = model.input</span><br><span class="line">outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers]</span><br></pre></td></tr></table></figure><p>outputs 里的元素的类型是：<br><code>&lt;class &#39;tensorflow.python.framework.ops.Tensor&#39;&gt;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># serialize model to JSON</span></span><br><span class="line">model_json = model.to_json()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(model_json)</span><br><span class="line"><span class="comment"># serialize weights to HDF5</span></span><br><span class="line">model.save_weights(<span class="string">"model.h5"</span>)</span><br><span class="line">print(<span class="string">"Saved model to disk"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># later...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load json and create model</span></span><br><span class="line">json_file = open(<span class="string">'model.json'</span>, <span class="string">'r'</span>)</span><br><span class="line">loaded_model_json = json_file.read()</span><br><span class="line">json_file.close()</span><br><span class="line">loaded_model = model_from_json(loaded_model_json)</span><br><span class="line"><span class="comment"># load weights into new model</span></span><br><span class="line">loaded_model.load_weights(<span class="string">"model.h5"</span>)</span><br><span class="line">print(<span class="string">"Loaded model from disk"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate loaded model on test data</span></span><br><span class="line">loaded_model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'rmsprop'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">score = loaded_model.evaluate(X, Y, verbose=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">"%s: %.2f%%"</span> % (loaded_model.metrics_names[<span class="number">1</span>], score[<span class="number">1</span>]*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;生成模型的关键步骤&quot;&gt;&lt;a href=&quot;#生成模型的关键步骤&quot; class=&quot;headerlink&quot; title=&quot;生成模型的关键步骤&quot;&gt;&lt;/a&gt;生成模型的关键步骤&lt;/h2&gt;&lt;h3 id=&quot;model-add&quot;&gt;&lt;a href=&quot;#model-add&quot; class</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Keras中RNNLayer的输入输出总结</title>
    <link href="https://wuruoting.club/2021/04/07/2021-04-07-keras-LSTM/"/>
    <id>https://wuruoting.club/2021/04/07/2021-04-07-keras-LSTM/</id>
    <published>2021-04-07T14:00:24.000Z</published>
    <updated>2021-04-08T05:30:33.041Z</updated>
    
    <content type="html"><![CDATA[<p>网上关于 Keras 的 RNNLayer 中的输入写的很不清楚，整理如下：</p><h2 id="LSTM-的输入"><a href="#LSTM-的输入" class="headerlink" title="LSTM 的输入"></a>LSTM 的输入</h2><h3 id="tf-keras-layers-LSTM-参数"><a href="#tf-keras-layers-LSTM-参数" class="headerlink" title="tf.keras.layers.LSTM()参数"></a><code>tf.keras.layers.LSTM()</code>参数</h3><p><a href="https://keras.io/api/layers/recurrent_layers/lstm/" target="_blank" rel="noopener">文档</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.LSTM(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'sigmoid'</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>, recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>, kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>,</span><br><span class="line">    return_sequences=<span class="literal">False</span>, return_state=<span class="literal">False</span>, go_backwards=<span class="literal">False</span>, stateful=<span class="literal">False</span>,</span><br><span class="line">    time_major=<span class="literal">False</span>, unroll=<span class="literal">False</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="input-dim、input-length、input-shape-的关系"><a href="#input-dim、input-length、input-shape-的关系" class="headerlink" title="input_dim、input_length、input_shape 的关系"></a>input_dim、input_length、input_shape 的关系</h3><p>LSTM 的输入是一个三维的张量（numpy narray), 三维张量的 shape 是[samples, time steps, features]，也就是[样本数量，时间步长（序列数量），特征长度]。LSTM layer 的参数需要确定其中的两个，在 model.fit 时，就能够对 trainX 进行训练。因此 input_dim 表示单个样本的特征长度，可以用 trainX.shape[2]赋值； input_length 表示的就是时间步长，序列长度，可以用 trainX.shape[1]进行赋值。</p><p>另外一种写法是 input_shape，其实就是这两个量的结合：input_shape = (input_length, input_dim)</p><p>因此以下的两种写法是等价的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(LSTM(units=<span class="number">256</span>, return_sequences=<span class="literal">True</span>,</span><br><span class="line">            input_dim=trainX.shape[<span class="number">2</span>], input_length=trainX.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(LSTM(units=<span class="number">256</span>, return_sequences=<span class="literal">True</span>,</span><br><span class="line">            input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))</span><br></pre></td></tr></table></figure><p>但比较奇怪的是这样设置最终的结果第一维会是 None。如果设置<code>input_size=trainX.size</code>的话，会出现以下错误：<br><code>ValueError: Input 0 of layer lstm is incompatible with the layer: expected ndim=3, found ndim=4.</code></p><h3 id="batch-size"><a href="#batch-size" class="headerlink" title="batch_size"></a>batch_size</h3><p>在 keras LSTM 的官方文档中，对 input 的定义是：<br><code>[batch, timesteps, feature]</code>,也就是说第一个参数指的是 batch 的大小，如果没有就默认为 None。<br>但是如果使用 batch_input_shape=(trainX.shape[0])就可以正常运行，并且最终得到训练的每一个样本的 <code>[timesteps,feature]</code>张量，如果按照只赋两个值，就会出现最终输出的是<code>[None,timesteps, feature]</code>，这点比较奇怪，也是我的疑问。</p><p>batch size 限制了在可以执行权重更新之前向网络显示的样本数。拟合模型时使用的 batch size 控制一次必须进行多少预测。</p><h2 id="GRU-的输入"><a href="#GRU-的输入" class="headerlink" title="GRU 的输入"></a>GRU 的输入</h2><h3 id="tf-keras-layers-GRU-参数"><a href="#tf-keras-layers-GRU-参数" class="headerlink" title="tf.keras.layers.GRU()参数"></a><code>tf.keras.layers.GRU()</code>参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.GRU(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'sigmoid'</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, return_sequences=<span class="literal">False</span>, return_state=<span class="literal">False</span>,</span><br><span class="line">    go_backwards=<span class="literal">False</span>, stateful=<span class="literal">False</span>, unroll=<span class="literal">False</span>, time_major=<span class="literal">False</span>,</span><br><span class="line">    reset_after=<span class="literal">True</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;网上关于 Keras 的 RNNLayer 中的输入写的很不清楚，整理如下：&lt;/p&gt;
&lt;h2 id=&quot;LSTM-的输入&quot;&gt;&lt;a href=&quot;#LSTM-的输入&quot; class=&quot;headerlink&quot; title=&quot;LSTM 的输入&quot;&gt;&lt;/a&gt;LSTM 的输入&lt;/h2&gt;&lt;h3</summary>
      
    
    
    
    
    <category term="Keras" scheme="https://wuruoting.club/tags/Keras/"/>
    
    <category term="RNN" scheme="https://wuruoting.club/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>gitbook+Typora打造舒适的笔记环境</title>
    <link href="https://wuruoting.club/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/"/>
    <id>https://wuruoting.club/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/</id>
    <published>2020-06-22T08:53:38.000Z</published>
    <updated>2021-04-07T11:51:16.764Z</updated>
    
    <content type="html"><![CDATA[<p>GitBook 是一个基于 Node.js 的命令行工具，可使用它来制作精美的电子书。gitbook简洁而且高效，能够用一种结构化的方式组织文章或者笔记，所以不管是学习的输入还是撰写文章的输出，gitbook都不失为一个很好的工具。</p><p>网上关于如何安装gitbook的文章有很多，此处不进行总结了。</p><a id="more"></a><h1 id="为什么用Typora？"><a href="#为什么用Typora？" class="headerlink" title="为什么用Typora？"></a>为什么用Typora？</h1><p>Typora可以支持实时预览，比起印象笔记等分屏的markdown写作工具,Typora这种所见即所得的极简给做笔记或者写作带来的体验感是非常强的。Typora的大部分语言都是传统markdown，使用Typora在官网下载对应版本即可 。</p><p>emoji的使用方法，这个我之前不知道，是无意中触发的：</p><p>只要用<code>:emoji-name:</code>的形式就可以插入emoji，通常一个冒号后面加字母就会自动提示emoji了。</p><p>:accept::clinking_glasses::v::ok::zap:</p><h1 id="gitbook-常用命令"><a href="#gitbook-常用命令" class="headerlink" title="gitbook 常用命令"></a>gitbook 常用命令</h1><h2 id="1-gitbook-init"><a href="#1-gitbook-init" class="headerlink" title="1.gitbook init"></a>1.gitbook init</h2><p>这个命令会在指定文件夹创建README.md和SUMMARY.md。</p><h2 id="2-gitbook-build"><a href="#2-gitbook-build" class="headerlink" title="2.gitbook build"></a>2.gitbook build</h2><p>运行该命令后会在书籍的文件夹中生成一个 <code>_book</code> 文件夹, 里面的内容即为生成的 html 文件,可以将这个文件发布自己到github的仓库中，可以作为项目的文档或者其他笔记等，使用<code>nameofUser.github.io/nameofRepository</code>域名就可以访问到在线笔记。</p><p>注意如果是一个有其他文件的仓库的话，需要在git中创建<code>docs</code>分支，然后将<code>_book</code>的内容传入该仓库的该分支中才能够访问。</p><h2 id="3-gitbook-serve"><a href="#3-gitbook-serve" class="headerlink" title="3.gitbook serve"></a>3.gitbook serve</h2><p>这一命令能够让我们在浏览器预览gitbook，通常能够在<code>http://localhost:4000</code> 预览。</p><h1 id="常用插件"><a href="#常用插件" class="headerlink" title="常用插件"></a>常用插件</h1><p>gitbook支持很多插件，能够更方便地帮助你使用gitbook。插件安装时需要在gitbook所在根目录下新建book.json， 并按照下面的配置进行修改或创建，最后使用<code>gitbook install</code>命令将对应的node_modules下载。</p><h2 id="显示文章目录：toc"><a href="#显示文章目录：toc" class="headerlink" title="显示文章目录：toc"></a>显示文章目录：toc</h2><p>一般来说如果想要显示文章目录的话，在Typora中可以在文章最开始加入<code>[toc]</code>，Typora就能够自动生成对应目录，但这个目录无法在gitbook中显示，这个插件让文档能够插入目录，在浏览器显示时也能够看见目录。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"plugins"</span> : [</span><br><span class="line">        <span class="string">"toc"</span>,</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"pluginsConfig"</span>: &#123;</span><br><span class="line">        <span class="attr">"toc"</span>: &#123;</span><br><span class="line">            <span class="attr">"addClass"</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">"className"</span>: <span class="string">"toc"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要目录时须在文章开始添加<code>&lt;!-- toc --&gt;</code>，这样才会显示目录。</p><h2 id="总目录折叠：expandable-chapters"><a href="#总目录折叠：expandable-chapters" class="headerlink" title="总目录折叠：expandable-chapters"></a>总目录折叠：expandable-chapters</h2><p>这个插件使目录具有折叠功能。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"plugins"</span> : [</span><br><span class="line">        <span class="string">"expandable-chapters"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>！这里将不断继续更新 ！</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;GitBook 是一个基于 Node.js 的命令行工具，可使用它来制作精美的电子书。gitbook简洁而且高效，能够用一种结构化的方式组织文章或者笔记，所以不管是学习的输入还是撰写文章的输出，gitbook都不失为一个很好的工具。&lt;/p&gt;
&lt;p&gt;网上关于如何安装gitbook的文章有很多，此处不进行总结了。&lt;/p&gt;</summary>
    
    
    
    
    <category term="gitbook" scheme="https://wuruoting.club/tags/gitbook/"/>
    
    <category term="小技巧" scheme="https://wuruoting.club/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>文本数据的聚类分析综述</title>
    <link href="https://wuruoting.club/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/"/>
    <id>https://wuruoting.club/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/</id>
    <published>2020-06-10T08:25:51.000Z</published>
    <updated>2020-06-14T16:33:32.909Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>聚类分析是一种无监督学习方法，在模式识别中，对于给定的数据样本，类别标号已知的情况下，分类问题通过训练，使得能够对未知类别的样本进行分类。而现实世界中，相当多的数据是没有已知类别的，它们的类别缺失或者需要大量的人工标注才能获取类别。为了发现数据的内在知识、检测并分析异常点和从数据中提取模式，聚类分析是非常重要的。</p><p>聚类分析依据相似性，将给定数据样本划分成若干个类别，相似性越高的两个物体划分为同一类，最终会将数据形成若干个簇，簇与簇可根据它们的形状、大小和密度等有所区别。</p><p>生活中的多个方面聚类都能够辅助模式识别和数据挖掘。在产品市场上，聚类可以基于用户的购买对商品进行聚类，使得市场营销人员能够利用这些知识开发有针对性地计划；在城市规划上，聚类可以将相似性高的区域进行划分，为土地建设提供选址方案等。</p><p>随着全球信息化的不断发展，大量文本数据隐含着潜在的信息和知识。文本数据是一种非常常见的非结构化数据，针对文本数据的聚类应用领域也很广泛。在信息检索方向，文本聚类可对搜索引擎进行聚类，提升用户获取信息的精确度；在信息推荐方向，聚类还可以提取出热点主题或发现事件、自动归档文本并帮助完善文本可视化。</p><p>实现文本聚类主要由三个步骤组成：1.文档的表示（提取文档特征并对特征降维处理）；2.文本聚类算法的选择和应用；3.评估文本聚类算法的有效性。三个步骤将在接下来的4章中进行详细的探讨。</p><h1 id="二、文本数据的特征提取"><a href="#二、文本数据的特征提取" class="headerlink" title="二、文本数据的特征提取"></a>二、文本数据的特征提取</h1><p>计算机难以直接对字符串文本进行处理，需要将实际的文字转化成数值型数据。对文本本身来说，它具有一些显式的特征，如字数、词频、停止词数量、单词平均长度等。为了实现文本的聚类，上述的特征需要进行处理和调整，按照某种完整的模型对文档进行数值化或向量化。</p><p>当前的主要的文档模型可被分为五个类别：布尔模型、向量空间模型、概率模型、统计语言模型和分布表示模型。</p><h2 id="（一）布尔模型"><a href="#（一）布尔模型" class="headerlink" title="（一）布尔模型"></a>（一）布尔模型</h2><p>布尔模型具有简洁的形式，容易理解。它的基础是集合论和布尔代数。我们考虑单词在文档中出现或缺失时，一个文档能够用二进制向量表示。</p><h2 id="（二）向量空间模型"><a href="#（二）向量空间模型" class="headerlink" title="（二）向量空间模型"></a>（二）向量空间模型</h2><p>向量空间模型是将文档表达为向量空间的一个矢量或点，向量空间的维数是词的数量。在向量空间的文档向量的长度是由出现的词和词的权重共同决定的[1]。在向量空间中，单词的顺序并不被考虑，这种方法也称为词袋表示方法（Bag of Words）。它是一种简单、经典的表示方法，但它对出现在文本中的词无法判定其重要性的差异，导致准确率不高。</p><p>1983年，Salton等提出了扩展布尔模型[2]，它结合了布尔模型和向量空间模型，并表现出检索性能的提升。</p><p>1986年，TF-IDF被提出[3]，这种表示改进了词袋表示法，每个单词的词频都由逆文档频率（IDF）规范化。在单词集合中，出现频率更高的项权重更低，降低了常用词在文档中的重要性，保证后续文档聚类的结果更受文档出现频率低的词的影响。</p><h2 id="（三）概率模型"><a href="#（三）概率模型" class="headerlink" title="（三）概率模型"></a>（三）概率模型</h2><p>概率模型中，文档<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002.png" alt="img">)与查询<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004.png" alt="img">)的相似度有如下关系：<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)表示相关文档集，<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image008.png" alt="img">)表示<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">的补集。</p><p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001825039.png" alt="image-20200615001825039"></p><p>对文档而言，根据独立性假设，文档的各个词相互独立，用<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image012.png" alt="img">表示词可得到：</p><p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001859217.png" alt="image-20200615001859217"></p><p>其中词权重<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image016.png" alt="img">。</p><p>用<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018.png" alt="img">)表示相关文档数，<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image020.png" alt="img">)表示包含索引词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的文档数，相关文档中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image024.png" alt="img">, 不相关文档中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001927832.png" alt="image-20200615001927832">),<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image028.png" alt="img">)表示包含索引词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">的文档数。</p><p>则可推出：</p><p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001955999.png" alt="image-20200615001955999"></p><p>概率模型的优点在于，文档可以按照相关概率递减顺序来计算秩；但概率模型需要把文档分为相关和不相关的两个集合，未考虑到单词的频率，没有权重系数[4]。 </p><h2 id="（四）-统计语言模型"><a href="#（四）-统计语言模型" class="headerlink" title="（四） 统计语言模型"></a>（四） 统计语言模型</h2><p>统计语言模型(Statistics Language Models)是基于统计学和概率论对语言进行建模的，主要思想是语言是字母表上的概率分布，该分布表示一种可能性：即任何一个字母序列成为该语言的一个句子。这一分布就是语言的统计语言模型。目前较流行的统计语言模型是n元模型（N-gram），表示一个词的出现与否和其前面的n-1个词有关。</p><p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591777871572.png" alt="img"></p><h2 id="（五）分布表示模型"><a href="#（五）分布表示模型" class="headerlink" title="（五）分布表示模型"></a>（五）分布表示模型</h2><p>分布式表示模型不仅考虑将单词符号化，还考虑将语义信息融入到词表示中。 1954 年，Harris提出了分布假说（ distributional hypothesis）上下文相似的词，其语义也相似[5]，这一假说为语义信息的融入提供了理论基础。</p><p>分布式表示根据任务、算法的区别，可被分为基于矩阵的分布表示、基于聚类的分布表示和基于神经网络的分布表示。在基于聚类的分布表示中，较典型的算法为布朗聚类方法(Brown clustering)，在第四章会具体介绍该算法。</p><h1 id="三、样本的相似性度量"><a href="#三、样本的相似性度量" class="headerlink" title="三、样本的相似性度量"></a>三、样本的相似性度量</h1><p>文本聚类根据不同的粒度可以分为文档、段落、语句或者单词的聚类。样本在不同的粒度下代表的事物也有所区别，如文档聚类时，每一个样本表示一个文档。对文档进行聚类时，我们需要获知文档样本与样本之间的相似度，需要相似性的度量标准。</p><p>相似性度量可使用空间两点的欧式距离、向量内积、余弦相似度、Jaccard相似度等。</p><p>相似度的度量会在一定程度上影响算法的效果，目前也有大量的研究针对聚类的相似性度量，如2009年，Luo[6]等人应用了邻居和链接的概念，将全局信息引入到两个文档的相似性度量上，提出了新的相似性度量方式：使用余弦和链接函数组合等，总而言之，相似性度量并不存在最优的方法，需要和聚类算法结合。</p><h1 id="四、文本聚类方法"><a href="#四、文本聚类方法" class="headerlink" title="四、文本聚类方法"></a>四、文本聚类方法</h1><p>传统的聚类分析算法不仅可以用在文本数据上，其他数据也是通用的。针对文本表示的不同形式，使用的聚类算法也有所区别，文本聚类主要可以分为三类方法：划分聚类方法、层次聚类方法和基于标准参数化模型的方法。</p><h2 id="（一）划分聚类方法"><a href="#（一）划分聚类方法" class="headerlink" title="（一）划分聚类方法"></a>（一）划分聚类方法</h2><p>划分方法符合我们对聚类的直观感受，将多个样本点组织成多个簇，通常簇的个数会在聚类前被给定，融合了相关领域的主观知识。</p><p>划分方法最初指定类别的初始数目，并不断迭代分配样本点，最终收敛时确定所有簇。划分方法运用在文本领域的主要有K-means和K-medoids两种聚类算法。</p><h3 id="1-K-means聚类算法"><a href="#1-K-means聚类算法" class="headerlink" title="1. K-means聚类算法"></a>1. K-means聚类算法</h3><p>K-means算法最早是从不同的科学领域中提出来的，包括1956年的Steinhaus[7], 和1957年的Lloyd[8]，至今已经提出了近60年，但它仍然是目前应用于聚类的算法之一。</p><p>K-means通过判断根据平方误差法计算出的目标函数是否达到最优解，而逐步对聚类结果进行优化。在运行前需要指定簇的类别、初始的簇的中心点，在每次迭代中，将每个点分配给中心最近的聚类。中心是群中所有点的平均值，平均点的坐标是簇中所有点上每个维度的算术平均值。</p><p>原始的K-means的缺点主要有以下几点：首先，它只考虑了样本点之间的距离，通常结果均为球状簇。若从样本点的密度考虑，以DBSCAN算法为代表的基于密度的方法能够发现任意形状的簇。其次，K值、初始化分方向等均是需要用户给定的，容易陷入局部最优。</p><h3 id="2-K-medoids聚类算法"><a href="#2-K-medoids聚类算法" class="headerlink" title="2.K-medoids聚类算法"></a>2.K-medoids聚类算法</h3><p>K-medoids聚类算法使用类中的某个点来代表簇，最早提出的K-mediods算法之一PAM(Partitioning Around Medoids) [9]的基本思想就是最初选取k个代表对象作为初始的中心点，依据当前cluster中所有其他点到该中心点的距离之和最小的准则函数，不断迭代找到更好的中心点。</p><p>该算法在一定程度上削弱了异常值的影响，但缺点是计算较为复杂，耗费的计算机时间比K-means多。它能处理任意类型的属性，但对异常数据不敏感。</p><h2 id="（二）-层次聚类方法"><a href="#（二）-层次聚类方法" class="headerlink" title="（二） 层次聚类方法"></a>（二） 层次聚类方法</h2><p>按照层次的聚类方法源于对数据需要组成层次结构的需求，数据需要进行层次结构上的汇总和特征化，因此层次划分方法被引入。层次划分方法可分为凝聚和分裂两种策略。</p><p>凝聚策略是将每个样本点在聚类最初都形成一个簇，随着迭代的进行，会将所有簇合并，直到终止条件为止。分类策略与凝聚策略正好相反，它将所有的样本点都看成同一个簇，相当于层次结构的根，将簇不断划分为更小的簇，直到划分的每一个簇都达到凝聚的条件。</p><p>以文档聚类为例，凝聚层次聚类方法可以被分为三类[10]：单连接算法（Single Linkage Clustering）、平均连接算法（Group-Average Linkage Clustering）、全连接算法（Complete Linkage Clustering）。</p><p>单连接算法的基本思想是两个簇的距离度量是从两个簇中抽取的每一对样本的最小距离<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591777984132.png" alt="img">,一旦最近的两个簇的距离超过某个任意给定的阈值，则算法结束。平均连接的基本算法是两个簇的距离度量是所有样本对的距离的平均值，全连接算法的距离度量则是两个簇所有样本对的最坏情况。</p><p>在针对文本数据的聚类中流行的层次聚类算法包括：综合的层次聚类方法BIRCH[11]，其优点在于能够通过单词扫描获取一个较好的聚类效果，但它只适用于数值型数据；基于质心和代表对象方法的CURE聚类方法[12]从每个类中抽取固定数量、分布较好的点作为代表点，并乘收缩收缩因子，减小噪音对聚类的影响；适用于分类属性层次的聚类算法ROCK[13],和使用动态模型的层次聚类算法Chameleon[14]。</p><p>1992年提出的布朗聚类方法[15]是一种针对词汇聚类的算法，它借鉴了层次聚类的凝聚策略，它的输入时一个语料库，语料库是一个词序列，输出是一个二叉树，二叉树的叶子节点是词，中间节点是对应的类别。它的评价函数是对于<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004-1591777984132.png" alt="img">)个连续的词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006-1591777984133.png" alt="img">)序列能否组成依据话的概率的对数的归一化结果，评价函数为:$Quality(C)=\frac{1}{n}logP(w_1,w_2…w_n)$。该函数描述了某个词上下文单词对当前聚类中单词的出现的预测程度。</p><p>Gil-García[16]等在2006年提出了一个基于图的凝聚层次聚类的通用框架，这一框架指定簇间相似度度量、β-相似度图的子图和覆盖例程，可以得到不同的层次的凝聚型的聚类算法；在2010年[17]，作者又提出了针对文档聚类的动态层次算法，该算法在获取和其他传统分层算法相似的聚类质量的前提下，层次结构更小、更利于浏览，可用于创建文档分类法和分层主题检测等模式识别问题。</p><p>层次聚类的鲁棒性较强，因为它通常需要比较所有的文档，因此复杂度达到<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image010-1591777984134.png" alt="img">。为了提升层次聚类方法的效率，多种改进方法被提出。如2018年，Zhang等人[18]提出了一个分区合并方案（PMHC）用于快速分层群集，它将数据对象分成适当的组并将它们合并到组中以节省计算成本。</p><h2 id="（三）基于标准参数化模型的方法"><a href="#（三）基于标准参数化模型的方法" class="headerlink" title="（三）基于标准参数化模型的方法"></a>（三）基于标准参数化模型的方法</h2><p>给定文档<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image012-1591777984134.png" alt="img">)，获取该文档属于不同簇的概率向量q，也是文档聚类的任务之一。考虑第二章中用统计语言模型表示文档的方式，可假定文档的生成过程是先以一定概率<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image014-1591777984134.png" alt="img">)选择簇<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image016-1591777984135.png" alt="img">),然后再按照词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018-1591777984135.png" alt="img">)的概率分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image020-1591777984135.png" alt="img">)选择词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018.png" alt="img">生成文档d,观测的所有文档在混合模型中被生成的概率为：</p><p>  <img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image024-1591777984136.png" alt="img"></p><p>其中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image014-1591777984134.png" alt="img">为“聚簇参数”，可通过期望最大化算法学习。该方法会陷入局部最优导致收敛速度较慢。</p><p>基于EM算法进行聚类的研究主要是基于EM算法对聚类方法的改进和提升，如2005年，Rigutini[19]等人将EM算法与基于信息增益的特征选择技术相结合，该算法只需要少量文档初始化聚类，并且能够正确地提取隐藏在大量未标记集合中的规则。2011年，Kim[20]等人基于EM算法，提出了一种文本文档的主题聚类算法，使用EM方法确保文档被分配给正确的主题，从而收敛到局部最优解，其结果具有较好的性能和可解释性。</p><p>EM算法衍生出了主题建模，它是一种对文档进行聚类并提取主题的无监督学习方法，可用来识别大规模文档集或语料库中潜藏的主题信息，广泛应用在文本分类、文本聚类、摘要抽取、情感分析等领域。</p><p>主题建模起源于潜在语义分析（LSA）[21]，该方法通过奇异值分解，将高维文档向量近似地映射到一个低维潜在地语义空间上，以达到降低文档维数和消除词语存在的同义、多义等问题。在LSA基础上，Hofmann引入了概率统计的思想，提出了概率潜在语义分析模型[22]。然而pLSA模型的参数容易与特定的文档相关，有时会出现过拟合现象，因此，Blei等人在2003年提出了LDA概率主题模型[23]，把模型的参数也看作随机变量，引入控制参数的参数，实现进一步的概率化。LDA本质上是一种无监督无指导的机器学习模型，将高维文本单词空间表示为低维主题空间，忽略了和文本相关的类别信息。</p><h2 id="（四）其他聚类学习方法"><a href="#（四）其他聚类学习方法" class="headerlink" title="（四）其他聚类学习方法"></a>（四）其他聚类学习方法</h2><p>除了上述三点主要的聚类算法之外，针对文本数据的部分其他聚类算法将在本节进行简短的阐述。</p><p>模糊聚类需要根据研究对象本身的属性来构造模糊矩阵，并根据隶属度来构造模糊矩阵，最终确定聚类关系。它可允许一个文档属于不同的局促，使得聚类结果更稳定[24]。</p><p>半监督聚类是一种更新的研究算法，半监督聚类的核心思想是把半监督学习的思想结合到聚类中，通过少量的标签数据和先验知识提高聚类性能，得到性能更优的结果。在文本聚类中，使用半监督获取少量标签的聚类算法也有部分研究。</p><p>Zhang W 等提出了基于频繁项集和相似度计算的最大获取的文本聚类方法[25]。</p><h1 id="五、聚类结果的评价"><a href="#五、聚类结果的评价" class="headerlink" title="五、聚类结果的评价"></a>五、聚类结果的评价</h1><p>  聚类结果并没有没有适用于所有算法的统一的评价指标，聚类算法结果的好坏取决于聚类算法的使用的相似性度量和相应的聚类算法。首先好的聚类的簇需要满足两个特点：簇内高内聚，簇间低耦合。其次，好的聚类能够发现隐含的模式，簇的形状没有较大限制；最后从用户的角度来说，能够产生一个满足用户的聚类结果，结果具有可解释性、可理解性。</p><h2 id="（一）分类评价指标"><a href="#（一）分类评价指标" class="headerlink" title="（一）分类评价指标"></a>（一）分类评价指标</h2><p>  通常，聚类任务可以使用分类任务的数据集（包含分类标签），衡量聚类的质量可以使用分类任务的评价指标。</p><h3 id="1-召回率和准确率"><a href="#1-召回率和准确率" class="headerlink" title="1.召回率和准确率"></a>1.召回率和准确率</h3><p>对于信息检索的结果，其计算包括了两个指标：召回率（Recall Rate）和准确率（Precision Rate）。召回率表示检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率；准确率是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；F 值为两者的调和平均值。</p><h3 id="2-宏平均和微平均"><a href="#2-宏平均和微平均" class="headerlink" title="2.宏平均和微平均"></a>2.宏平均和微平均</h3><p>宏平均（Macro-averaging），是先对每一个类统计指标值，然后在对所有类求算术平均值。微平均（Micro-averaging**），是对数据集中的每个实例不分类别进行统计建立全局混淆矩阵，然后计算相应指标[26]。</p><h2 id="（二）交叉检验方法"><a href="#（二）交叉检验方法" class="headerlink" title="（二）交叉检验方法"></a>（二）交叉检验方法</h2><p>将用于聚类的数据集划分为m个部分，随机使用m-1个部分建立聚类模型，并用剩下的1个部分检验聚类的质量。这一部分可以计算与他们最近形心的距离平方和作为度量，重复m次后，总体质量度量由质量度量的平均值计算出来，对不同的k，可以比较总体质量度量，最终选取最佳拟合数据的簇数[27]。</p><h2 id="（三）聚类质量的测定"><a href="#（三）聚类质量的测定" class="headerlink" title="（三）聚类质量的测定"></a>（三）聚类质量的测定</h2><p>当有专家构建的基准时，可将聚类模型和基准进行比较，比较时聚类质量度量Q如满足以下4项基本标准：簇的同质性、簇的完全性、碎布袋、小簇保持性，那么可以使用Q进行比较和评估。</p><p>当基准不存在时，可以采用轮廓系数对距离进行内部评估。</p><p>假设数据集D有<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591778129766.png" alt="img">)个样本被分为<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004-1591778129766.png" alt="img">)个类别，则对于任意一个样本<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006-1591778129767.png" alt="img">),计算<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)与<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)所在簇中其他对象的平均距离<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image008-1591778129767.png" alt="img">),<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)与其他簇的最小平均距离为<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image010-1591778129768.png" alt="img">。轮廓系数的定义为：</p><p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615002122028.png" alt="image-20200615002122028"></p><p>  当轮廓系数为越接近1时，包含<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">的簇是紧凑的，当轮廓系数值为负时，这种情况是糟糕的，应该避免。</p><h1 id="六、聚类的局限性和挑战"><a href="#六、聚类的局限性和挑战" class="headerlink" title="六、聚类的局限性和挑战"></a>六、聚类的局限性和挑战</h1><p>不同的文本数据有不同的特性，目前文本数据聚类的局限性也给文本聚类这一领域带来了新的挑战。</p><p>目前文本数据仍存在数据稀疏等问题，文档的词汇可能很多，但这些词汇是相互关联的，数据中主成分的数量远小于特征空间的特征数量。因此上述的所有聚类方法并不能解决所有文本的聚类问题。</p><p>近年来社交网络媒体和在线聊天应用创造了大量的文本数据，特别是短文本，短文本表示维数大，如何探索出更有效率、更节省空间的数据表示形式、如何将表示形式与聚类算法更好地结合在一起，是未来仍值得研究的课题。</p><p>文本数据也越来越多地出现在异构应用程序中，有效地将基于文本的算法应用于异构多媒体场景是非常关键的。P2P分布式文档聚类算法解决了其中的一些难题[28]，但对于开发结合优化技术的新型混合算法的研究仍有很大的需求。近年来的研究热点也集中在高维数据的处理上，不断提高处理速度和规模。</p><p>【后记-如果你还能看到这里】<br>这是模式识别课程的最终提交论文（我靠着这个论文得了98分），找了几十篇论文掐头去尾粗略的看了，还是有很多不懂的地方，但至少对于这个方向有了一个框架上的概念。写综述真的很锻炼人哇…</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Salton, G. Some experiments in the generation of word and document associations [A].Proceedings of the December 4–6, 1962, fall joint computer conference[C].1962.234–250. </p><p>[2] Salton, G.&amp; E. A. Fox.&amp; H. Wu. Extended Boolean information retrieval[J]. Communications of the ACM, 1983,26(11):1022–1036. </p><p>[3]Salton, G.&amp;M.J.McGill. Introduction to modern information retrieval[M].New York.The McGraw-Hill Companies,1986.</p><p>[4]McCullagh, P. What is a statistical model?[J]. Annals of Statistics,2002,30:1225–1310. </p><p>[5]Harris, Z. Distributional structure[J]. Word,1954,10(23):146-162.</p><p>[6]Luo, C., Li, Y., &amp; Chung, S. M. Text document clustering based on neighbors[J]. Data &amp; Knowledge Engineering,2009,68(11):1271–1288.</p><p>[7]Steinhaus, H. Sur la division des corp materiels en parties[J]. Bull. Acad. Polon. Sci,1956, IV (C1.III):801–804.</p><p>[8]Lloyd, S. Least squares quantization in PCM[J].IEEE Trans Inform Theory.1982,28:129–137. </p><p>[9]Kaufman,L.&amp;,P.J.Rousseeuw.,Clustering by means of Medoids[J].Statistical Data Analysis Based on the L1–Norm and Related Methods,1987: 405–416.</p><p>[10]Aggarwal, C. C.&amp;C.Zhai.A Survey of Text Clustering Algorithms[J]. Mining Text Data,2012: 77–128.</p><p>[11]Charikar,M.&amp;C.Chekuri. Incremental clustering and dynamic information retrieval[J]. SIAM J Comput, 2004,33(6):1417-1440.</p><p>[12]Guha,S.&amp;R.Rastogi.CURE: an efficient clustering algorithm for large databases[J]. Inf Syst,2003,26(1):35-58.</p><p>[13]Dutta,M.&amp;AK.Mahanta.QROCK: a quick version of the ROCK algorithm for clustering of categorical data[J]. Pattern Recognit Letter, 2005,26(15):2364-2373.</p><p>[14]Karypi,G.&amp;EH.Han.Chameleon: a hierarchical clustering algorithm using dynamic modeling. Computer,1999,32:68-75.</p><p>[15]Brown,P,F&amp;V.J.Della Pietra.Class-Based n-gram Models of Natural Language[J].Computational Linguistics,1992,18:467-480.</p><p>[16]Gil-García,J.&amp;M. Badía-Contelles&amp;A.Pons-Porrata. Extended Star Clustering Algorithm[J]. Lecture Notes on Computer Sciences,2003,2905:480-487.</p><p>[17]Gil-García,R.&amp;A.Pons-Porrata.Dynamic hierarchical algorithms for document clustering[J].Pattern Recognition Letters,2010,31(6):469-477.</p><p>[18]Zhang, Y.&amp; Cheung, Y. A fast hierarchical clustering approach based on partition and merging scheme[A]. 2018 Tenth International Conference on Advanced Computational Intelligence (ICACI).[C].Xiamen,2018.846-851.</p><p>[19]Kim, S.&amp; Wilbur, W. Thematic clustering of text documents using an EM-based approach[J]. Journal of Biomedical Semantics, 2012,3(Suppl 3), S6.</p><p>[20]Rigutini,L&amp;U.Adegli Studi di Siena.A semi-supervised document clustering algorithm based on EM[A].IEEE/WIC/ACM International Conference on Web Intelligence[C], Compiègne (France): Proceedings of the IEEE/ACM/WI International Conference on Web Intelligence,2005.200-206.</p><p>[21]Deerwester,S&amp;S.Dumais.Indexing by latent semantic analysis[J].Journal of the American Society for Informatlon Science,1990,41(6):391-407.</p><p>[22]Hofmann,T.Probabilistic latent semantic analysis[A].Proc.of the Conference on Uncertainty in Artificial Intelligence[C].1999:289—296.</p><p>[23]Blei,D&amp;A.Ng A.Latent Dirichlet Allocation[J].Journal of Machine Learning Research,2003,3:993—1022．</p><p>[24]C. Borgelt and A. Nurnberger.Fast Fuzzy Clustering of Web Page Collections[A].Proc. of PKDD Workshop on Statistical Approaches for WebMining（SAWM)[C],Pisa(Italy) 2004.</p><p>[25]Zhang,W.&amp;T.Yoshida.Text Clustering Using Frequent Itemsets[J]. Knowledge-Based Systems,2010,23(5):379-388.</p><p>[26]Yang Y. An evaluation of statistical approaches to text categorization[J]. Information retrieval, 1999, 1(1-2): 69-90.</p><p>[27]Han,J&amp;M.Kamber.数据挖掘：概念与技术(原书第3版)[M].北京：机械工业出版社.2012.</p><p>[28]Judith, J.E.&amp;J.Jayakumari.Distributed document clustering algorithms: a recent survey[J].Int. J. Enterprise Network Management,2015,Vol. 6, No. 3:207–221.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、引言&quot;&gt;&lt;a href=&quot;#一、引言&quot; class=&quot;headerlink&quot; title=&quot;一、引言&quot;&gt;&lt;/a&gt;一、引言&lt;/h1&gt;&lt;p&gt;聚类分析是一种无监督学习方法，在模式识别中，对于给定的数据样本，类别标号已知的情况下，分类问题通过训练，使得能够对未知类别的</summary>
      
    
    
    
    
    <category term="文本挖掘" scheme="https://wuruoting.club/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"/>
    
    <category term="聚类分析" scheme="https://wuruoting.club/tags/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【编译原理复习专题5】中间代码生成</title>
    <link href="https://wuruoting.club/2020/05/23/%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"/>
    <id>https://wuruoting.club/2020/05/23/%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/</id>
    <published>2020-05-23T09:27:48.000Z</published>
    <updated>2020-06-14T15:45:18.837Z</updated>
    
    <content type="html"><![CDATA[<p>中间代码生成就是把经过语法分析和语义分析的源程序中间表示翻译为中间代码展示，中间表示可能有多个种类，如语法树、DAG、后缀式、三地址代码等。</p><p>如果中间代码独立于机器的话，那么各便于编译系统的建立和移植，并且便于进行独立于机器的代码优化工作。</p><h1 id="三地址代码"><a href="#三地址代码" class="headerlink" title="三地址代码"></a>三地址代码</h1><p>三地址代码包含一个运算和三个地址，两个地址用于存放运算对象，一个用于存放运算结果。</p><p>具体实现：四元式、三元式、间接三元式。</p><h2 id="四元式"><a href="#四元式" class="headerlink" title="四元式"></a>四元式</h2><p>op、arg1、arg2、result</p><h2 id="三元式"><a href="#三元式" class="headerlink" title="三元式"></a>三元式</h2><p>op、arg1、arg2 使用运算x op y 的位置来表示计算的结果</p><h2 id="间接三元式"><a href="#间接三元式" class="headerlink" title="间接三元式"></a>间接三元式</h2><h1 id="类型和声明"><a href="#类型和声明" class="headerlink" title="类型和声明"></a>类型和声明</h1><p>类型表达式是用于表示类型的结构的，如基本类型int、char、float，</p><p>类型表达式名也是类型表达式。</p><p>类型构造算子:作用于类型表达式可以构造新的类型表达式。</p><p><strong>数组构造符array</strong></p><table><thead><tr><th align="center">类型</th><th align="center">类型表达式</th></tr></thead><tbody><tr><td align="center">int[3]</td><td align="center">array(3,int)</td></tr><tr><td align="center">int[2][3]</td><td align="center">array(2,array(3,int))</td></tr></tbody></table><p><strong>指针构造符pointer</strong></p><p><strong>笛卡尔乘积构造符x</strong></p><p><strong>函数构造符-&gt;</strong></p><p><strong>记录构造符record</strong></p><h2 id="类型检查-type-checking"><a href="#类型检查-type-checking" class="headerlink" title="类型检查 type checking"></a>类型检查 type checking</h2><p>保证参与的运算分量和运算符预期的类型相匹配。</p><p><strong>如果两个类型表达式相等，那么返回某种类型，否则出错</strong></p><h3 id="类型等价"><a href="#类型等价" class="headerlink" title="类型等价"></a>类型等价</h3><blockquote><p>两种类型之间结构等价当且仅当下面某个条件为真： </p><p>1.是相同的类型</p><p>2.是相同的类型构造算子应用于结构等价的类型而构造得到的。</p><p>3.一个类型是另一个类型表达式的名字</p></blockquote><p><strong>类型检查有两种形式：类型综合和类型推导。</strong></p><p>类型综合是根据子表达式的类型构造出表达式的类型，<strong>要求名字先声明再使用</strong>。表达式$E1+E2$的类型是根据$E1$和$E2$的类型定义的。</p><p>类型推导是根据一个语言结构的使用来确定结构的类型，就类似如果使用了某个类型才能用的函数的话，那么可以指出使用该函数的变量就是对应的类型。</p><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>浮点数和整型相加，编译器内部需要进行转换。</p><p>不同的语言有不同的类型转换，主要转换有两种：拓宽转换（保持信息）、窄化转换（丢失信息）。</p><h2 id="类型翻译"><a href="#类型翻译" class="headerlink" title="类型翻译"></a>类型翻译</h2><h2 id="类型的声明"><a href="#类型的声明" class="headerlink" title="类型的声明"></a>类型的声明</h2><p>语义分析在遇到声明语句时，主要做两件事情：1.收集标识符的类型等属性信息；2.为每一个名字分配一个相对地址。</p><h3 id="声明的SDT"><a href="#声明的SDT" class="headerlink" title="声明的SDT"></a>声明的SDT</h3><h2 id="表达式和赋值语句的翻译"><a href="#表达式和赋值语句的翻译" class="headerlink" title="表达式和赋值语句的翻译"></a>表达式和赋值语句的翻译</h2><h3 id="为赋值语句生成三地址码的SDD"><a href="#为赋值语句生成三地址码的SDD" class="headerlink" title="为赋值语句生成三地址码的SDD"></a>为赋值语句生成三地址码的SDD</h3><p>gen 一个函数，生成括号内代表信息的三地址码</p><table><thead><tr><th>Production</th><th>Semantic Rules</th></tr></thead><tbody><tr><td>$S\rightarrow id=E$</td><td>$S.code=E.code</td></tr><tr><td>$E\rightarrow E_1+E_2$</td><td>$E.addr=new Temp()$, $E.code=E1.code</td></tr><tr><td>$E\rightarrow -E_1$</td><td>$E.addr=new Temp()$ ,$E.code=E_1.code</td></tr><tr><td>$E\rightarrow (E_1)$</td><td>$E.addr=E1.addr$,$E.code=E_1.code$</td></tr><tr><td>$E\rightarrow id$</td><td>$E.addr=top.get(id.lexeme)$, $E.code=’’$</td></tr></tbody></table><p>将$a=b+-c;$ 编译成三地址码：</p><p>$S\Rightarrow id=E_0;$</p><p>$\Rightarrow id=E_1+E_2;$</p><p>$\Rightarrow id=E_1+-E_3;$ </p><p>$\Rightarrow id=E_1+-id;$</p><p>$\Rightarrow id=id+-id;$</p><table><thead><tr><th>产生式</th><th>属性变化</th></tr></thead><tbody><tr><td>$E_1\rightarrow id$</td><td>$E_1.addr=addr(b)$, $E_1.code=’’$</td></tr><tr><td>$E3\rightarrow id$</td><td>$E_3.addr=addr(c)$, $E_3.code=’’$</td></tr><tr><td>$E_2\rightarrow -E_3$</td><td>$E_2.addr=t1$ ,$E_2.code=E_3.code</td></tr><tr><td>$E_0\rightarrow E_1+E_2$</td><td>$E_0.addr=t2$,$E_0.code=E_1.code</td></tr><tr><td>$S\rightarrow id=E_0$</td><td>$S.code=E_0.code</td></tr></tbody></table><p>刚好三行就是赋值语句的三地址码。</p><h3 id="布尔表达式的翻译"><a href="#布尔表达式的翻译" class="headerlink" title="布尔表达式的翻译"></a>布尔表达式的翻译</h3><h4 id="短路代码"><a href="#短路代码" class="headerlink" title="短路代码"></a>短路代码</h4><p>跳转代码中&amp;&amp; || ！都被翻译成跳转指令。</p><p>语句：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(x&lt;<span class="number">100</span>||x&gt;<span class="number">200</span> &amp;&amp; x!=y)</span><br><span class="line">x=<span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>三地址代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if x&lt;100 goto L2</span><br><span class="line">goto L3</span><br><span class="line">L3: if x&gt;200 goto L4</span><br><span class="line">goto L1</span><br><span class="line">L4: if x!&#x3D;y goto L2</span><br><span class="line">goto L1</span><br><span class="line">L2:x&#x3D;0</span><br><span class="line">L1:</span><br></pre></td></tr></table></figure><p>其实运算符并不在代码中，布尔表达式的值是通过代码序列中的位置来表示的。</p><h3 id="控制流语句"><a href="#控制流语句" class="headerlink" title="控制流语句"></a>控制流语句</h3><p>控制流语句：(S表示语句，B表示布尔表达式)</p><p>1.$P\rightarrow S$</p><p>2.$S\rightarrow assign$</p><p>3.$S\rightarrow if(B) S1$</p><p>4.$S\rightarrow if(B) \quad S1 \quad else \quad S2$</p><p>5.$S\rightarrow while(B)\quad S1$</p><p>6.$S\rightarrow S1 \quad S2$</p><p>SDD</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>$P\rightarrow S$</td><td>$S.next=newlable()$</td></tr><tr><td>$S\rightarrow assign$</td><td>$S.code=assign.code$</td></tr><tr><td>$S\rightarrow if(B) S1$</td><td>$B.true=newlabel()$,$B.false=S_1.next=S.next$, $S.code=B.code</td></tr><tr><td>$S\rightarrow if(B) \quad S1 \quad else \quad S2$</td><td>$B.true=newlabel()$,$B.false=newlabel()$,$S_1.next=S_2.next=S.next$,$S.code=B.code</td></tr><tr><td>$S\rightarrow while(B)\quad S1$</td><td></td></tr></tbody></table><p><strong>(1) $B\rightarrow E1 \quad rel \quad R2$ (假设形如$a&lt;b$)</strong></p><p>$B.true: if \quad a&lt;b\quad goto \quad B.true$ (j&lt;,a,b,B.true)</p><p>$B.FALSE: goto B.false$     (j,,,B.false)</p><p>(2) <strong>B是常量</strong>, 就直接翻译为跳转指令。</p><p>(3) 不需要为$B\rightarrow!B$产生新的代码，只需要将真假出口交换就可以了。(继承属性)。</p><p>(4) 对$B\rightarrow B1||B2$,</p><p>如果B1为真则B为真，B1.true从B.true继承而来，如果B1为假，则对B2求值，B1.false就可以设置为B2的代码的第一条指令的标号。B2的真假出口标号可直接从B继承获得。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;中间代码生成就是把经过语法分析和语义分析的源程序中间表示翻译为中间代码展示，中间表示可能有多个种类，如语法树、DAG、后缀式、三地址代码等。&lt;/p&gt;
&lt;p&gt;如果中间代码独立于机器的话，那么各便于编译系统的建立和移植，并且便于进行独立于机器的代码优化工作。&lt;/p&gt;
&lt;h1 i</summary>
      
    
    
    
    
    <category term="编译原理" scheme="https://wuruoting.club/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【编译原理复习专题4】语法制导翻译</title>
    <link href="https://wuruoting.club/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/"/>
    <id>https://wuruoting.club/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/</id>
    <published>2020-05-22T02:27:00.000Z</published>
    <updated>2020-06-14T15:45:00.324Z</updated>
    
    <content type="html"><![CDATA[<p>语法制导翻译，边做语法分析，边做语义分析。它使用CFG引导对语言的翻译，是一种面向文法的翻译技术。</p><h1 id="语义信息"><a href="#语义信息" class="headerlink" title="语义信息"></a>语义信息</h1><p><strong>如何表示语义信息？</strong></p><p>将语言结构的语义以属性(attribute)的形式赋予代表此结构的文法符号。</p><p><strong>如何计算语义属性？</strong></p><p>属性的计算以语义规则(semantic rules)的形式赋予由文法符号组成的产生式。在语法分析推导或归约的每一步骤中，通过语义规则实现对属性的计算，以达到对语义的处理。</p><p>换句话说就是：为每一个产生式配上语义规则并且在适当的时候执行这些规则。</p><h1 id="SDD-语法制导定义"><a href="#SDD-语法制导定义" class="headerlink" title="SDD 语法制导定义"></a>SDD 语法制导定义</h1><p>SDD是一个上下文无关文法和属性及规则的结合。属性和文法符号相关联，而规则和产生式相关联，有时也称为属性文法。<br>如果𝑿是一个符号，而𝒂是𝑿的一个属性，那么用𝑿.𝒂来表示在某个标号为𝑿的分析树节点上的属性值。属性可以有很多类型，比如变量的数据类型、表达式的值、变量的地址、数字的有效位数等等。</p><h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p>属性分为综合属性和继承属性。</p><p><strong>综合属性</strong>只能由当前结点或者结点的子节点的属性值来计算。通常，产生式左侧的属性都来自右侧的话，那么左侧的属性就是综合属性。</p><p><strong>继承属性</strong>是由当前结点的父节点或兄弟节点或本身的属性值来定义的。（只要有父节点或兄弟结点定义就是继承属性了）</p><blockquote><p>终结符可以有综合属性，就是词法分析的词法值。终结符没有继承属性。</p></blockquote><p>属性文法写成表格形式，相同的非终结符需要用下标区分。</p><h2 id="S属性的SDD"><a href="#S属性的SDD" class="headerlink" title="S属性的SDD"></a>S属性的SDD</h2><p>只包含综合属性的SDD称为S属性的SDD。它可以按照任何自底向上的顺序进行求值。</p><p>L属性SDD的特例。</p><h2 id="L属性的SDD"><a href="#L属性的SDD" class="headerlink" title="L属性的SDD"></a>L属性的SDD</h2><p>要么是综合属性，要么是继承属性，且满足以下i条件：</p><p>对于产生式$A\rightarrow X_1 X_2 …X_n$,$X_i$的继承属性仅能依赖于：</p><ul><li><p>A的继承属性（如果是综合属性可能会有环路）</p></li><li><p>产生式$X_i$左侧的属性。（继承属性只能右侧的继承左侧的，规定了依赖图的边只能从左往右)</p></li></ul><h2 id="SDD的求值"><a href="#SDD的求值" class="headerlink" title="SDD的求值"></a>SDD的求值</h2><p>如果是综合属性，就可以按照任何自底向上的顺序进行求值，如果是同时具有继承属性和综合属性的话，首先要看有没有出现环状的依赖关系，最好不要出现循环的情况。</p><p>1.绘制依赖图dependency graph</p><p>2.求DAG的依赖图的拓扑排序（如果图存在环，就不存在拓扑排序）</p><p>拓扑排序不是唯一的，平行关系可以交换。</p><h1 id="SDT-语法制导的翻译方案"><a href="#SDT-语法制导的翻译方案" class="headerlink" title="SDT 语法制导的翻译方案"></a>SDT 语法制导的翻译方案</h1><p>SDT是在产生式中嵌入了程序片段的一个上下文无关文法。这些片段称为语义动作，它们可以出现在产生式的任何位置。默认用{}括起来。</p><blockquote><p>SDD时语言翻译的高层次规格说明，隐藏了很多具体实现细节，使用户不必显式地说明翻译发生的顺序。</p><p>SDT是SDD的一种补充，是SDD的具体实施方案，显式地指明了语义规则的计算顺序，以便说明某些实现细节。</p></blockquote><p>语法制导翻译可以用于抽象语法树的构建，</p><h2 id="如何用SDT实现两类重要的SDD"><a href="#如何用SDT实现两类重要的SDD" class="headerlink" title="如何用SDT实现两类重要的SDD"></a>如何用SDT实现两类重要的SDD</h2><p>产生式右侧的动作在它左边的所有文法符号后被匹配后立即执行。</p><p>将内嵌语义动作替换成一个新的非终结符，可以执行相应的语义动作。</p><h3 id="S属性的SDD-1"><a href="#S属性的SDD-1" class="headerlink" title="S属性的SDD"></a>S属性的SDD</h3><p><strong>后缀翻译方案：</strong></p><p>S属性的SDD可以构造出SDT: <strong>每个动作都放在产生式的结尾。</strong></p><p>所有属性都是综合属性。</p><h3 id="产生式内部带有语义动作的SDT"><a href="#产生式内部带有语义动作的SDT" class="headerlink" title="产生式内部带有语义动作的SDT"></a>产生式内部带有语义动作的SDT</h3><p>$B\rightarrow X{a}Y$</p><p>自底向上，X出现在分析栈栈顶时，立即执行动作a。</p><p>自顶向下，在展开Y的本次出现或者在输入中检测Y之前执行动作a。</p><h3 id="L属性的SDD-1"><a href="#L属性的SDD-1" class="headerlink" title="L属性的SDD"></a>L属性的SDD</h3><p>将计算某个非终结符号A的<strong>继承属性</strong>的动作插入到产生式<strong>右部中紧靠在A的本次出现之前的位置上</strong>。</p><p>将计算一个产生式左部符号的<strong>综合属性</strong>的动作放置在这个产生式右部的<strong>最右端</strong> <strong>。</strong></p><p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200226341.png" alt="image-20200523200226341"></p><p>如果基本文法可以用LL分析，那么可以用递归下降、在LL预测分析过程中翻译(属性值存放在语法分析栈中)或者用LR分析。</p><h3 id="在递归下降分析中加入语义翻译"><a href="#在递归下降分析中加入语义翻译" class="headerlink" title="在递归下降分析中加入语义翻译"></a>在递归下降分析中加入语义翻译</h3><p>函数A的参数是非终结符A的继承属性<br>函数A的返回值是非终结符A的综合属性</p><p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200609909.png" alt="image-20200523200609909"></p><p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200643560.png" alt="image-20200523200643560"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;语法制导翻译，边做语法分析，边做语义分析。它使用CFG引导对语言的翻译，是一种面向文法的翻译技术。&lt;/p&gt;
&lt;h1 id=&quot;语义信息&quot;&gt;&lt;a href=&quot;#语义信息&quot; class=&quot;headerlink&quot; title=&quot;语义信息&quot;&gt;&lt;/a&gt;语义信息&lt;/h1&gt;&lt;p&gt;&lt;stro</summary>
      
    
    
    
    
    <category term="编译原理" scheme="https://wuruoting.club/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【编译原理复习专题3】语法分析的例子整理</title>
    <link href="https://wuruoting.club/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/"/>
    <id>https://wuruoting.club/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/</id>
    <published>2020-05-21T12:58:37.000Z</published>
    <updated>2020-06-14T15:44:54.984Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SLR-1"><a href="#SLR-1" class="headerlink" title="SLR(1)"></a>SLR(1)</h2><p>考虑文法：</p><p>$E\rightarrow E+T|T$</p><p>$T\rightarrow T*F|F$</p><p>$F\rightarrow (E) |id$</p><p>1.扩展文法：</p><p>$E’\rightarrow E$<br>$E\rightarrow E+T|T$<br>$T\rightarrow T*F|F$<br>$F\rightarrow (E) |id$</p><p>2.LR(0)项：</p><p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200522080711106.png" alt="LR(0)项"></p><p>3.绘制LR(0)自动机：</p><p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200521205727392.png" alt="LR(0)自动机"></p><p>4.由状态1、2、9可发现，这个语法有移进归约冲突，因此不是LR(0)文法，</p><p>而在状态1中，Follow(E’)={$},+不在E’的Follow集里面的，因此无歧义，在状态2和9中，Follow(E)={+,(,$},*不在E的Follow集里，也无歧义，该文法是SLR(1)文法。</p><p>5.构建SLR(1)分析表。</p><p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200522095458808.png" alt="image-20200522095458808"></p><p>6.串(id+id)*id的分析过程:</p><table><thead><tr><th></th><th>stack</th><th>input</th><th>action</th></tr></thead><tbody><tr><td>1</td><td>$0</td><td>(id+id)*id$</td><td>S4</td></tr><tr><td>2</td><td>$0(4</td><td>id+id)*id$</td><td>S5</td></tr><tr><td>3</td><td>$0(4id5</td><td>+id)*id$</td><td>$r(F\rightarrow id)$</td></tr><tr><td>4</td><td>$0(4F3</td><td>+id)*id$</td><td>$r(T\rightarrow F)$</td></tr><tr><td>5</td><td>$0(4T2</td><td>+id)*id$</td><td>$r(E\rightarrow T)$</td></tr><tr><td>6</td><td>$0(4E8</td><td>+id)*id$</td><td>S6</td></tr><tr><td>7</td><td>$0(4E8+6</td><td>id)*id$</td><td>S5</td></tr><tr><td>8</td><td>$0(4E8+6id5</td><td>)*id$</td><td>$r(F\rightarrow id)$</td></tr><tr><td>9</td><td>$0(4E8+6F3</td><td>)*id$</td><td>$r(T\rightarrow F)$</td></tr><tr><td>10</td><td>$0(4E8+6T9</td><td>)*id$</td><td>$r(E\rightarrow E+T)$</td></tr><tr><td>11</td><td>$0(4E8</td><td>)*id$</td><td>S11</td></tr><tr><td>12</td><td>$0(4E8)11</td><td>*id$</td><td>$r(F\rightarrow (E))$</td></tr><tr><td>13</td><td>$0F3</td><td>*id$</td><td>$r(T\rightarrow F)$</td></tr><tr><td>14</td><td>$0T2</td><td>*id$</td><td>S7</td></tr><tr><td>15</td><td>$0T2*7</td><td>id$</td><td>S5</td></tr><tr><td>16</td><td>$0T2*7id5</td><td>$</td><td>$r(F\rightarrow id)$</td></tr><tr><td>17</td><td>$0T2*7F10</td><td>$</td><td>$r(T\rightarrow  T*F)$</td></tr><tr><td>18</td><td>$0T2</td><td>$</td><td>$r(E\rightarrow T)$</td></tr><tr><td>19</td><td>$0E1</td><td>$</td><td>accept</td></tr></tbody></table><p>因此该串被接受。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;SLR-1&quot;&gt;&lt;a href=&quot;#SLR-1&quot; class=&quot;headerlink&quot; title=&quot;SLR(1)&quot;&gt;&lt;/a&gt;SLR(1)&lt;/h2&gt;&lt;p&gt;考虑文法：&lt;/p&gt;
&lt;p&gt;$E\rightarrow E+T|T$&lt;/p&gt;
&lt;p&gt;$T\rightarrow T</summary>
      
    
    
    
    
    <category term="编译原理" scheme="https://wuruoting.club/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【编译原理复习专题2】关于语法分析</title>
    <link href="https://wuruoting.club/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"/>
    <id>https://wuruoting.club/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/</id>
    <published>2020-05-21T02:07:43.000Z</published>
    <updated>2020-06-14T15:44:35.422Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这将是一个非常口语化的总结，因为这就是我口述的总结。</p></blockquote><p>语法分析过程主要包括两种方法：自底向上的语法分析和自顶向下的语法分析。其中，“底”指的就是原始串，而“顶”指的是开始符号。分析的目的就是确定某一个确定的字符串是否属于文法描述的语言。</p><p>而这些分析方法，最终都是要让串形成对应的语法分析树，因此它们将一个判定问题，转化成了生成语法分析树的过程。</p><h1 id="First集和Follow集"><a href="#First集和Follow集" class="headerlink" title="First集和Follow集"></a>First集和Follow集</h1><p>First集和Follow集应该是对于任意的文法都是能够确定的。</p><p>文法中的任意文法符号串都是有First集的，First集相当于这个文法符号串能推出的串中最左侧的终结符的集合。First集可以包含$\epsilon$。</p><blockquote><p>求First集的规则：</p><ol><li><p>把所有的终结符语法规则列出来（我感觉First集求的时候不能有或？还是也可以）</p></li><li><p>如果X是终结符或者$\epsilon$,$First(X)={X}$</p><p>如果X是非终结符，对每个产生式$X-&gt;X_1X_2…X_n$,$First(X_1)$是$First(X)$的子集。</p><p>如果有$X_1X_2…X_i\Rightarrow\epsilon(i&lt;n)$,那么$First(X_{i+1})$是$First(X)$的子集。</p></li></ol></blockquote><p>Follow集能够让一个非终结符消失（推出空），就是说Follow是确定当某一个非终结符后面出现了哪些终结符的时候，我们需要用推出空这个产生式。</p><blockquote><p>求Follow集的规则：</p><p>1.先将$放入Follow(S)中，S为开始字符。(构建LL(1)分析表的时候，如果有$S\Rightarrow\epsilon$,那么就可以写在[S,$]里，表示如果接受的是一个空串，就可以用这个产生式)</p><p>2.如果存在产生式$A\rightarrow\alpha B\beta$,那么求解Follow(B)的时候，要将$First(\beta)$中除了$\epsilon$所有的元素都加入Follow(B)。$\beta$可包含终结符或非终结符。</p><p>3.产生式右侧被推导出之后，左侧的Follow集就是右侧最右（需要考虑右侧是否为空，若为空就不断考虑向左移动的符号）的非终结符的Follow集的子集。</p><p>【如果存在产生式$A\rightarrow\alpha B\beta$,且$\beta$可空（或者说B的First集包含$\epsilon$)，那么$Follow(B)\Leftarrow Follow(A)$】</p></blockquote><p>因为我们确定某个非终结符的Follow集，都是通过它在右侧才能确定的，因此我们不需要考虑那些右侧全是终结符的产生式。</p><p>LL(1)分析表做的是这件事：横轴是预测的下一个字符，然后当前的栈顶的非终结符已知，那么要通过哪一个产生式能够最终推出预测的下一个字符。所以我们需要通过计算First集和Follow集来确定LL(1)分析表。</p><h1 id="自顶向下的语法分析"><a href="#自顶向下的语法分析" class="headerlink" title="自顶向下的语法分析"></a>自顶向下的语法分析</h1><p>从开始符号最终到实际的字符串，<strong>自顶向下</strong>中主要分为<strong>回溯分析程序</strong>和<strong>预测分析程序</strong>。我们主要学了两种预测分析方法：<strong>递归下降和LL(1)</strong>。</p><p><strong>为何叫“预测分析”，</strong>我们可以这么理解：首先，自顶向下分析方法的基础就是将字符串看成输入串，就是说从开始到结束，我们可以认为是逐步读取这个串的，因此字符之间有了先后被读取的，那么我们构建语法分析树也就是一个先根次序创建树的过程，我们也可以说<strong>自顶向下分析就是要找到对应串的最左推导</strong>。因此预测分析首先是要求给定的文法中没有左因子、左递归，文法不能是二义性的，其次预测分析需要看文法的下一个字符，也就是<strong>下一个输出符号</strong>，所以我们称之为“预测”。</p><h2 id="回溯分析程序"><a href="#回溯分析程序" class="headerlink" title="回溯分析程序"></a>回溯分析程序</h2><h2 id="预测分析程序"><a href="#预测分析程序" class="headerlink" title="预测分析程序"></a>预测分析程序</h2><h3 id="递归下降"><a href="#递归下降" class="headerlink" title="递归下降"></a>递归下降</h3><p>改写为$EBNF$(消除左递归、去除左因子)</p><h3 id="LL-1-分析算法"><a href="#LL-1-分析算法" class="headerlink" title="LL(1)分析算法"></a>LL(1)分析算法</h3><p>第一个L表示从左向右扫描输入，第二个L表示最左推导，1表示每一步中只需要向前看一个输入符号来决定语法分析动作。</p><h4 id="预测分析表的构建"><a href="#预测分析表的构建" class="headerlink" title="预测分析表的构建"></a>预测分析表的构建</h4><blockquote><p>$LL(1)$构建预测分析表的步骤：</p><ol><li>$First(\alpha)$中的每个记号$s$，都将$A\rightarrow\alpha$添加至$M[A,s]$中。</li><li>$\alpha$可空的话，对$Follow(A)$中的每一个元素$k$，将$A\rightarrow\alpha$添加到$M[A,k]$中。</li></ol><p>如果$M[A,\alpha]$没有产生式的话，就将其设置为$error$。</p></blockquote><h4 id="LL-1-文法"><a href="#LL-1-文法" class="headerlink" title="LL(1)文法"></a>LL(1)文法</h4><p>一个文法若满足以下条件，则该文法就是LL(1)文法：</p><p>在每个产生式$A\rightarrow{\alpha}_1 |{\alpha}_2⋯|{\alpha}_n$中，对于所有的i和j:$1≤i, j≤n, i≠j$，$First(α_i )∩First(α_j )$为空。（若不为空，假设有一个相同元素$k$,那么在$M[A,k]$就会加入两个产生式：$A\rightarrow{\alpha}_i$和$A\rightarrow{\alpha}_j$)</p><p>若对于非终结符A可空，那么$First(A)∩Follow(A)$为空。(若有相同元素k，根据分析表也会发现$M[A,k]$有两个产生式)</p><p><strong>如果一个文法G，由它构造的LL(1)分析表中的每个子项最多只含有一个产生式，那么它就是LL(1)文法。</strong></p><p>在LL(1)分析表中有两项产生式的文法不一定是二义性的文法，可能是有左递归的。</p><blockquote><p>一个不是$LL(1)$的文法同样可以用$LL(1)$方法。</p></blockquote><p>LL(1）方法对应的是非递归的预测分析器，显示维护栈结构，应该和计算理论里的下推自动机类似。下推自动机所定义的语言恰好就是上下文无关语言。</p><h1 id="自底向上的语法分析"><a href="#自底向上的语法分析" class="headerlink" title="自底向上的语法分析"></a>自底向上的语法分析</h1><p>归约其实就是推导的反向操作。如果反向构造一个推导过程，那么就会是最右推导的。推导的方法是从记号串开始，使用产生式进行归约，期望得到开始符号，如果能够得到开始符号，那么这个字符串就是文法可以识别的语句。</p><p>两个动作：移进 shift和规约 reduce。</p><p>自底向下就是从输入串到开始符号的归约，归约的方向是从左到右，可以认为是最左归约，逆向的过程就是最右推导。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="短语、直接短语和句柄"><a href="#短语、直接短语和句柄" class="headerlink" title="短语、直接短语和句柄"></a>短语、直接短语和句柄</h3><p>短语就是在一个句型中对应的分析树，里以非终结符为根的子树的所有叶子节点构成的排列就是对于该非终结符的短语，如果子树只有两层，那么就是直接短语。最左侧的非终结符的子树对应的短语就是句柄。</p><p>句柄的定义：如果$S\Rightarrow_{lm}^{*}\alpha A\omega \Rightarrow_{lm} \alpha \beta \omega$，A是输入串中最右的非终结符，则$\beta$称为一个句柄。</p><p>句柄可以理解为一个归约点，可以允许解析器通过进一步的归约操作回到开始符号的位置。而实际上我们做的归约就是最左归约。</p><p>对于下列文法：</p><p>$E\rightarrow E+T|T$<br>$T\rightarrow T*F|F$<br>$F\rightarrow (E) |id$</p><p>对于输入串$id*id$，从左到右相当于一个最左归约的过程。从左至右：</p><table><thead><tr><th>产生式</th><th>句柄</th><th>最右句型</th></tr></thead><tbody><tr><td>$F\rightarrow id$</td><td>$id$</td><td>id*id</td></tr><tr><td>$T\rightarrow F$</td><td>$F$</td><td>F*id</td></tr><tr><td>$F\rightarrow id $</td><td>$id$</td><td>T*id</td></tr><tr><td>$T\rightarrow T*F$</td><td>$T*F$</td><td>T*F</td></tr><tr><td>$E\rightarrow T$</td><td>$T$</td><td>T</td></tr></tbody></table><p><img src="/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image-20200521195029382.png" alt="image-20200521195029382"></p><h3 id="可行前缀"><a href="#可行前缀" class="headerlink" title="可行前缀"></a>可行前缀</h3><h2 id="LR-0-分析算法"><a href="#LR-0-分析算法" class="headerlink" title="LR(0)分析算法"></a>LR(0)分析算法</h2><p><strong>LR(0)文法中L指的是从左到右扫描输入串，R代表了最右推导，0表示进行分析动作的决策只考虑栈顶状态，不需要看输入串。（没有lookahead)</strong></p><p><strong>1.扩展文法。</strong></p><p>在决定状态间的转移前，我们必须先加入一条扩展文法：$S\rightarrow E$其中$S$是新的起始符号（start symbol）而<em>E</em>是原先的起始符号。这一做法是为了保证分析器能有一个唯一的起始状态。</p><p><strong>2.列LR(0)项。</strong>(点号的左侧是已经读入的，点号的剩余是还没有读入的)</p><p><strong>3.起始状态是所有点在最左侧的LR(0)项组成的封闭集,构建LR(0)自动机</strong></p><p><strong>4.构建LR(0)分析表。</strong></p><p><strong>5.进行分析。</strong></p><p>如果X是终结符，只要有移进项先移进。</p><h4 id="LR-0-文法"><a href="#LR-0-文法" class="headerlink" title="LR(0)文法"></a>LR(0)文法</h4><p>无歧义需要没有归约归约冲突或移进归约冲突。</p><h2 id="SLR-1-分析算法"><a href="#SLR-1-分析算法" class="headerlink" title="SLR(1)分析算法"></a>SLR(1)分析算法</h2><p>如果当前栈顶状态可以支持终结符移进，并且<strong>下一个记号也就是该终结符</strong>，才会移进。如果当前栈顶状态包含了归约项$A\rightarrow\gamma.$，且<strong>下一个记号在$Follow（A)$</strong>时，才会使用$A\rightarrow\gamma$归约，如果不在$Follow(A)$也不会做归约。$GOTO$项与LR(0)类似。</p><blockquote><p>歧义的产生：</p><p>1)有归约项和移进项，且移进项$A\rightarrow \alpha . X \beta$的下一个字符$X$在$Follow（B）$中,当然如果下一个记号不是$X$那么就没有歧义了。</p><p>2)有两个不同的归约项$A\rightarrow\beta.$，$B\rightarrow\gamma.$，且下一个记号即在A的Follow集也在B的Follow集，或者两个Follow集都没有$X$,此时要报错。</p></blockquote><p>当确认没有歧义的时候，归约项$r(A\rightarrow \gamma)$就会被填入A的Follow集对应的Input下。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这将是一个非常口语化的总结，因为这就是我口述的总结。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;语法分析过程主要包括两种方法：自底向上的语法分析和自顶向下的语法分析。其中，“底”指的就是原始串，而“顶”指的是开始符号。分析的目的就是确定某一个确定的</summary>
      
    
    
    
    
    <category term="编译原理" scheme="https://wuruoting.club/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【编译原理复习专题1】上下文无关文法和正则表达式</title>
    <link href="https://wuruoting.club/2020/05/21/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>https://wuruoting.club/2020/05/21/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</id>
    <published>2020-05-21T01:35:48.000Z</published>
    <updated>2020-06-14T16:30:45.896Z</updated>
    
    <content type="html"><![CDATA[<p>扫描器是词法分析器，它接收输入的源程序，对源程序进行词法分析并识别出一个个单词符号，输出单词符号。</p><h1 id="上下文无关语言"><a href="#上下文无关语言" class="headerlink" title="上下文无关语言"></a>上下文无关语言</h1><p>表示上下文无关文法规则的形式被称为BNF，其扩展表示就是EBNF。</p><p>在BNF中，重复是使用递归表示的，重复实际分两种：嵌套重复和并列重复，并列重复对应到程序是可以用循环来实现的。</p><h2 id="EBNF"><a href="#EBNF" class="headerlink" title="EBNF"></a>EBNF</h2><p><strong>重复表示{…}</strong></p><blockquote><p>下面两种重复的递归形式表达的就是并列重复：</p><p>$A\rightarrow A \alpha|\beta$</p><p>$A\rightarrow \alpha A |\beta$</p><p>其中第一条中要求$\beta$ 不能以A开头， 而第二条中要求$\beta$不能以A结尾。对应的正则表达式为：$\beta \alpha^<em>$和$\alpha^</em>\beta$<br>EBNF中使用{…}来表示这种重复：<br>$A\rightarrow \beta {\alpha}$</p><p>$A\rightarrow{\alpha} \beta$</p></blockquote><p><strong>可选表示[…]</strong> 有点类似消除左因子。</p><blockquote><p>语句序列：<br>$stmt-sequence \rightarrow stmt; stmt-sequence | stmt$<br>可以表示为：<br>$stmt-sequence \rightarrow  stmt [ ; stmt-sequence ]$<br>$stmt-sequence \rightarrow  stmt { ; stmt }  $       </p></blockquote><h2 id="消除左递归"><a href="#消除左递归" class="headerlink" title="消除左递归"></a>消除左递归</h2><h3 id="直接简单左递归"><a href="#直接简单左递归" class="headerlink" title="直接简单左递归"></a>直接简单左递归</h3><p>$A\rightarrow A \alpha |\beta$</p><p>改写文法为：</p><p>$A\rightarrow \beta A’$</p><p>$A’\rightarrow \alpha A’ |\epsilon$</p><h3 id="间接左递归"><a href="#间接左递归" class="headerlink" title="间接左递归"></a>间接左递归</h3><p>会出现$A\Rightarrow^*A$的左递归。</p><p>处理方法：</p><p>将文法的所有非终结符按任意一种顺序排序，得到$A_1,A_2…A_n$</p><p>对每个$A_i$，如果存在一个编号比它小的非终结符，编号大的非终结符可以含有推出编号小的非终结符的句型，而且编号小的非终结符还能够推出一个句型，那么就可以进行代入操作。<br>如果有直接左递归，那么直接消除即可。</p><blockquote><p>$S\rightarrow Qc|c$</p><p>$Q\rightarrow Rb|b$</p><p>$R\rightarrow Sa|a$</p><p>1) 对S、Q、R编号1、2、3</p><p>2）i=1，无法代入，i=2，无法代入</p><p>i=3, 代入有 $R\rightarrow Qca|ca|a$,可再次代入：$R\rightarrow Rbca|bca|ca|a$</p><p>3)化简直接左递归：</p><p>$R\rightarrow bcaR’|caR’|aR’$</p><p>$R\rightarrow bcaR’|\epsilon$</p></blockquote><h2 id="消除左公因子"><a href="#消除左公因子" class="headerlink" title="消除左公因子"></a><strong>消除左公因子</strong></h2><p>对每个非终结符A，找出它的两个或多个选项之间的最长公共前缀$\alpha$,如果$\alpha$不为空，即存在一个非平凡的公共前缀，那么将所有A的产生式$A\rightarrow \alpha\beta_1|\alpha\beta_2|…\alpha\beta_n|\gamma$,</p><p>替换为：</p><p>$A\rightarrow \alpha A’|\gamma$</p><p>$A’\rightarrow \beta_1|\beta_2|…|\beta_n$</p><h2 id="递归构造上下文无关文法"><a href="#递归构造上下文无关文法" class="headerlink" title="递归构造上下文无关文法"></a>递归构造上下文无关文法</h2><p>左递归：左侧非终结符出现在右侧第一个位置。<br>$A\rightarrow A a | a$<br>右递归：左侧非终结符出现在右侧最后一个位置<br>$A \rightarrow a A | a$</p><blockquote><p>表示$\alpha\beta^*\gamma$一样的语言：</p><p>1）$A\rightarrow B\gamma$ ,$B\rightarrow B\beta|\alpha$</p><p>2) $A\rightarrow \alpha B$ ,$B\rightarrow \beta B|\gamma$</p><p>3)$A\rightarrow\alpha B\gamma$,$B\rightarrow\beta B| \epsilon$</p></blockquote><hr><p>所有的正则语言都能被上下文无关文法表示。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;扫描器是词法分析器，它接收输入的源程序，对源程序进行词法分析并识别出一个个单词符号，输出单词符号。&lt;/p&gt;
&lt;h1 id=&quot;上下文无关语言&quot;&gt;&lt;a href=&quot;#上下文无关语言&quot; class=&quot;headerlink&quot; title=&quot;上下文无关语言&quot;&gt;&lt;/a&gt;上下文无关语言&lt;</summary>
      
    
    
    
    
    <category term="编译原理" scheme="https://wuruoting.club/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>一个解决word页码错乱的小方法</title>
    <link href="https://wuruoting.club/2020/05/20/%E4%B8%80%E4%B8%AA%E8%A7%A3%E5%86%B3word%E9%A1%B5%E7%A0%81%E9%94%99%E4%B9%B1%E7%9A%84%E5%B0%8F%E6%96%B9%E6%B3%95/"/>
    <id>https://wuruoting.club/2020/05/20/%E4%B8%80%E4%B8%AA%E8%A7%A3%E5%86%B3word%E9%A1%B5%E7%A0%81%E9%94%99%E4%B9%B1%E7%9A%84%E5%B0%8F%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-20T08:11:28.000Z</published>
    <updated>2020-06-14T16:31:18.836Z</updated>
    
    <content type="html"><![CDATA[<p>说实话，我常常因为word多此一举的方便用户而感到困扰。</p><p>比如拿到了一个页码错乱的文档模板，然后强迫症的我页码绝对不能错一个。</p><p>那么如果出现了这样恐怖的情况:文档页码在某一页开始一直往下都相同的话，其实是因为word看见的文档并不和你看见的一样，如果一个节没有结束的话，那么word就默认这一页还没有结束，可以理解为word看见的文档按照节来说实际上是一个不知道多长的羊皮卷。</p><p>通常如果出现页码相同的情况，可以双击页码并注意看导航栏里是否勾选了链接到前一节。我们看字面意思就能猜到，链接到前一节就指的是前后两个页面(不一定是你看到的页面，而是word认为的页面，总之）它们被绑定在一起了，修改一个另一个也会被更改。如果你发现勾选了这项的话，把它取消。我们不需要自作多情的链接。</p><p>但是还有一种情况是你发现链接到前一节没有被勾选，但页码也还是从某一页往下相同，那么就是因为word把”节“理解成了”页“，对于未完成的节，它是不会变换页码的。所以，你要做的就是告诉word这一页已经结束了。</p><p>那么具体的方法如下：</p><blockquote><p>1.光标移动到相同页面中的第一张的最末尾，点击布局-&gt; 分隔符，选择下一页，就会在该页插入分节符（下一页）</p><p>2.选中第二页的页码，就会发现此时会显示勾选了链接到前一节，取消它</p><p>3.正确地命名页码</p><p>4.如此往复直到问题解决</p></blockquote><p>不知道这个方法是不是正确，总之页码错乱问题是能够解决了，但是随之而来的是新的问题，自动目录并不能识别到对应的页码，还好自动页码可以手动改页码。</p><p>结尾也不知道要说我是该去学习一下Word呢，还是高喊”Latex真香“, 那就这样吧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;说实话，我常常因为word多此一举的方便用户而感到困扰。&lt;/p&gt;
&lt;p&gt;比如拿到了一个页码错乱的文档模板，然后强迫症的我页码绝对不能错一个。&lt;/p&gt;
&lt;p&gt;那么如果出现了这样恐怖的情况:文档页码在某一页开始一直往下都相同的话，其实是因为word看见的文档并不和你看见的一样，</summary>
      
    
    
    
    
    <category term="小技巧" scheme="https://wuruoting.club/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
    <category term="word" scheme="https://wuruoting.club/tags/word/"/>
    
  </entry>
  
  <entry>
    <title>【综述总结2】More Data,More Relations,More Context and More Openness:A Review and Outlook for Relation Extraction</title>
    <link href="https://wuruoting.club/2020/05/02/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93-2/"/>
    <id>https://wuruoting.club/2020/05/02/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93-2/</id>
    <published>2020-05-02T00:15:09.000Z</published>
    <updated>2020-05-02T00:21:06.422Z</updated>
    
    <content type="html"><![CDATA[<h2 id="行文结构"><a href="#行文结构" class="headerlink" title="行文结构"></a>行文结构</h2><p>先关注于现有的工作，按照模型分类，其次探讨了关系提取的更多方向，主要是从数据量、学习表现、场景、领域四个方面，恰好和题目呼应；最后提出了其他的挑战。</p><h3 id="Section-1-Introduction"><a href="#Section-1-Introduction" class="headerlink" title="Section 1 Introduction"></a>Section 1 Introduction</h3><p>RE: relation extraction</p><h3 id="Section-2-背景和现有的工作"><a href="#Section-2-背景和现有的工作" class="headerlink" title="Section 2 背景和现有的工作"></a>Section 2 背景和现有的工作</h3><h4 id="2-1-模式提取模型"><a href="#2-1-模式提取模型" class="headerlink" title="2.1 模式提取模型"></a>2.1 模式提取模型</h4><h4 id="2-2-统计关系提取模型"><a href="#2-2-统计关系提取模型" class="headerlink" title="2.2 统计关系提取模型"></a>2.2 统计关系提取模型</h4><h4 id="2-3-神经网络关系提取模型"><a href="#2-3-神经网络关系提取模型" class="headerlink" title="2.3 神经网络关系提取模型"></a>2.3 神经网络关系提取模型</h4><h3 id="Section-3-RE的更多方向"><a href="#Section-3-RE的更多方向" class="headerlink" title="Section 3 RE的更多方向"></a>Section 3 RE的更多方向</h3><h4 id="3-1-使用更多数据"><a href="#3-1-使用更多数据" class="headerlink" title="3.1 使用更多数据"></a>3.1 使用更多数据</h4><h4 id="3-2-学习表现更有效"><a href="#3-2-学习表现更有效" class="headerlink" title="3.2  学习表现更有效"></a>3.2  学习表现更有效</h4><h4 id="3-3-在更复杂的场景中实现"><a href="#3-3-在更复杂的场景中实现" class="headerlink" title="3.3 在更复杂的场景中实现"></a>3.3 在更复杂的场景中实现</h4><h4 id="3-4-面向更开放的领域"><a href="#3-4-面向更开放的领域" class="headerlink" title="3.4 面向更开放的领域"></a>3.4 面向更开放的领域</h4><h3 id="Section-4-其他挑战"><a href="#Section-4-其他挑战" class="headerlink" title="Section  4 其他挑战"></a>Section  4 其他挑战</h3><h4 id="4-1-从文本或实体名中学习"><a href="#4-1-从文本或实体名中学习" class="headerlink" title="4.1 从文本或实体名中学习"></a>4.1 从文本或实体名中学习</h4><h4 id="4-2关系提取数据集"><a href="#4-2关系提取数据集" class="headerlink" title="4.2关系提取数据集"></a>4.2关系提取数据集</h4>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;行文结构&quot;&gt;&lt;a href=&quot;#行文结构&quot; class=&quot;headerlink&quot; title=&quot;行文结构&quot;&gt;&lt;/a&gt;行文结构&lt;/h2&gt;&lt;p&gt;先关注于现有的工作，按照模型分类，其次探讨了关系提取的更多方向，主要是从数据量、学习表现、场景、领域四个方面，恰好和题目呼应</summary>
      
    
    
    
    
    <category term="NLP" scheme="https://wuruoting.club/tags/NLP/"/>
    
    <category term="综述" scheme="https://wuruoting.club/tags/%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>【综述总结1】Analysis Methods in Neural Language Processing:A Survey</title>
    <link href="https://wuruoting.club/2020/04/30/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93/"/>
    <id>https://wuruoting.club/2020/04/30/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93/</id>
    <published>2020-04-29T16:00:00.000Z</published>
    <updated>2020-05-02T00:19:08.047Z</updated>
    
    <content type="html"><![CDATA[<h2 id="行文结构"><a href="#行文结构" class="headerlink" title="行文结构"></a>行文结构</h2><p>论文进行综述时很善于从多个维度对工作进行分类，比如使用的方法、语言现象等。（作者也输出了一张表格、通过不同的维度归纳了相关的工作）。整体来说是按照不同角度下的方法进行综述，比如有一章专门写了自然语言处理中的可视化方法和衡量的难度性。同时最后将所有本文的结论写在了结语。</p><h3 id="Section-1-Introduction"><a href="#Section-1-Introduction" class="headerlink" title="Section 1 Introduction"></a>Section 1 Introduction</h3><p>对全文脉络进行梳理</p><h3 id="Section-2-什么样的语言信息会被神经网络使用？"><a href="#Section-2-什么样的语言信息会被神经网络使用？" class="headerlink" title="Section 2 什么样的语言信息会被神经网络使用？"></a>Section 2 什么样的语言信息会被神经网络使用？</h3><p>阐述从三个方面回答这一问题（和小标题对应）：</p><ul><li>which method are used  使用什么方法</li><li>what kind of linguistic information is sought 什么信息</li><li>which objects in the neural network are being investigated  什么被观测</li></ul><h4 id="2-2-Linguistic-Phenomena"><a href="#2-2-Linguistic-Phenomena" class="headerlink" title="2.2 Linguistic Phenomena"></a>2.2 Linguistic Phenomena</h4><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>sentence length</td><td>句子长度</td><td></td></tr><tr><td>word position</td><td>单词位置</td><td></td></tr><tr><td>word presence</td><td>文字出现</td><td></td></tr><tr><td>simple word order</td><td>简单词序</td><td></td></tr><tr><td>morphological information</td><td>形态信息</td><td></td></tr><tr><td>syntactic information</td><td>句法信息</td><td></td></tr><tr><td>semantic information</td><td>语义信息</td><td></td></tr></tbody></table><p><a href="https://boknilev.github.io/nlp-analysis-methods/table2.html">other phenomena</a></p><h3 id="Section-3-可视化方法和衡量可视化工作的难度性"><a href="#Section-3-可视化方法和衡量可视化工作的难度性" class="headerlink" title="Section 3 可视化方法和衡量可视化工作的难度性"></a>Section 3 可视化方法和衡量可视化工作的难度性</h3><h3 id="Section-4-用于细粒度评估的挑战集的编译"><a href="#Section-4-用于细粒度评估的挑战集的编译" class="headerlink" title="Section 4 用于细粒度评估的挑战集的编译"></a>Section 4 用于细粒度评估的挑战集的编译</h3><p>datasets used for evaluating neural network models that diverge from the common average case evaluatio</p><blockquote><p>分类数据集的依据：</p><ul><li>the task they seek to evaluate</li><li>the linguistic phenomena they aim to study</li><li>the language(s) they target</li><li>their size</li><li>their method of construction</li><li>how performance is evaluated</li></ul></blockquote><h3 id="Section-5-对抗性例子的产生和使用、神经网络的弱点"><a href="#Section-5-对抗性例子的产生和使用、神经网络的弱点" class="headerlink" title="Section 5 对抗性例子的产生和使用、神经网络的弱点"></a>Section 5 对抗性例子的产生和使用、神经网络的弱点</h3><h3 id="Section-6-解释模型预测的工作"><a href="#Section-6-解释模型预测的工作" class="headerlink" title="Section 6 解释模型预测的工作"></a>Section 6 解释模型预测的工作</h3><h3 id="Section-7-其他不归于上述主题的方法"><a href="#Section-7-其他不归于上述主题的方法" class="headerlink" title="Section 7 其他不归于上述主题的方法"></a>Section 7 其他不归于上述主题的方法</h3><h2 id="引用他人工作的句式"><a href="#引用他人工作的句式" class="headerlink" title="引用他人工作的句式"></a>引用他人工作的句式</h2><ul><li><p>see somebody for example</p></li><li><p>They found … suggesting that </p></li><li><p>In contrast,</p></li><li><p>Somebody <strong>made some headway on</strong> this question.</p></li><li><p>Somebody noted several key properties…</p></li><li><p>conducted behavioral experiments</p></li></ul><h2 id="其他句式"><a href="#其他句式" class="headerlink" title="其他句式"></a>其他句式</h2><ul><li><p>enable them to draw conclusions about…</p></li><li><p>synthesize a holistic picture from this diverse body of work</p></li><li><p>Another theme that emerges in several  studies is…</p></li><li><p>Much recent work has focused on …</p></li><li><p>… have gained renewed popularity in the NLP community.</p></li><li><p>Most of the relevant analysis work is concerned with…</p></li><li><p>Method … may shed new light on some of these questions.</p></li><li><p>A long tradition in work on (domain) is to …</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;行文结构&quot;&gt;&lt;a href=&quot;#行文结构&quot; class=&quot;headerlink&quot; title=&quot;行文结构&quot;&gt;&lt;/a&gt;行文结构&lt;/h2&gt;&lt;p&gt;论文进行综述时很善于从多个维度对工作进行分类，比如使用的方法、语言现象等。（作者也输出了一张表格、通过不同的维度归纳了相关的</summary>
      
    
    
    
    
    <category term="NLP" scheme="https://wuruoting.club/tags/NLP/"/>
    
    <category term="综述" scheme="https://wuruoting.club/tags/%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>D3笔记</title>
    <link href="https://wuruoting.club/2020/04/03/D3%E7%AC%94%E8%AE%B0/"/>
    <id>https://wuruoting.club/2020/04/03/D3%E7%AC%94%E8%AE%B0/</id>
    <published>2020-04-03T03:38:29.000Z</published>
    <updated>2020-04-05T09:53:00.526Z</updated>
    
    <content type="html"><![CDATA[<p>loading data onto the page</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">waitSeconds=<span class="function"><span class="params">numSeconds</span>=&gt;</span><span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="params">resolve</span>=&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">const</span> message=<span class="string">`<span class="subst">$&#123;numSeconds&#125;</span> seconds have passed!`</span>;</span><br><span class="line">    setTimeout(<span class="function"><span class="params">()</span>=&gt;</span>resolve(message),numSeconds*<span class="number">1000</span>);</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">waitSeconds(<span class="number">2</span>).then(<span class="function"><span class="params">message</span>=&gt;</span><span class="built_in">console</span>.log(message));</span><br></pre></td></tr></table></figure><blockquote><p>结果：等待两秒后显示 2 seconds have passed!</p></blockquote><h2 id="ECMAScript-6-Features"><a href="#ECMAScript-6-Features" class="headerlink" title="ECMAScript 6 Features"></a>ECMAScript 6 Features</h2><h2 id="HTML-CSS-SVG"><a href="#HTML-CSS-SVG" class="headerlink" title="HTML CSS SVG"></a>HTML CSS SVG</h2><p>Scalable Vector Graph</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>&#123;select,arc&#125; <span class="keyword">from</span> <span class="string">'d3'</span></span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> width=+svg.attr(<span class="string">'width'</span>) <span class="comment">//string转换为float</span></span><br><span class="line"><span class="keyword">const</span> width=<span class="built_in">parseFloat</span>(svg.attr(<span class="string">'width'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> circle=svg.append(<span class="string">'circle'</span>)</span><br><span class="line">.attr(<span class="string">'fill'</span>,<span class="string">'yellow'</span>) </span><br><span class="line">.attr(<span class="string">'stroke'</span>,<span class="string">'black'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> g=svg.append(<span class="string">'g'</span>)</span><br><span class="line">.attr(<span class="string">'transform'</span>,<span class="string">'translate($&#123;width/2&#125;,$&#123;height/2&#125;)'</span>);</span><br><span class="line"><span class="keyword">const</span> mouth=svg.append(<span class="string">'path'</span>)</span><br><span class="line">.attr(<span class="string">'d'</span>,acr()(&#123;</span><br><span class="line">        innerRadius:<span class="number">80</span>,</span><br><span class="line">        outerRadius:<span class="number">100</span>,</span><br><span class="line">        startAngle:<span class="built_in">Math</span>.PI/<span class="number">2</span>,</span><br><span class="line">        endAngle:<span class="built_in">Math</span>,PI*<span class="number">3</span>/<span class="number">2</span></span><br><span class="line">    &#125;));</span><br></pre></td></tr></table></figure><h2 id="d3"><a href="#d3" class="headerlink" title="d3"></a>d3</h2><p>csv comma seperated value</p><h3 id="customizing-axis"><a href="#customizing-axis" class="headerlink" title="customizing  axis"></a>customizing  axis</h3><p>d3.format() 函数</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;loading data onto the page&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;sp</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>hexo的坑和新博客</title>
    <link href="https://wuruoting.club/2020/03/31/hexo%E7%9A%84%E5%9D%91%E5%92%8C%E6%96%B0%E5%8D%9A%E5%AE%A2/"/>
    <id>https://wuruoting.club/2020/03/31/hexo%E7%9A%84%E5%9D%91%E5%92%8C%E6%96%B0%E5%8D%9A%E5%AE%A2/</id>
    <published>2020-03-31T01:45:41.955Z</published>
    <updated>2020-05-01T08:58:11.845Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><h3 id="给一篇文章加多个tags"><a href="#给一篇文章加多个tags" class="headerlink" title="给一篇文章加多个tags"></a>给一篇文章加多个tags</h3><p>tags:[‘a’,’b’]</p><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;hexo&quot;&gt;&lt;a href=&quot;#hexo&quot; class=&quot;headerlink&quot; title=&quot;hexo&quot;&gt;&lt;/a&gt;hexo&lt;/h2&gt;&lt;h3 id=&quot;给一篇文章加多个tags&quot;&gt;&lt;a href=&quot;#给一篇文章加多个tags&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
    <category term="博客" scheme="https://wuruoting.club/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>文档主题建模</title>
    <link href="https://wuruoting.club/2019/11/26/%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/"/>
    <id>https://wuruoting.club/2019/11/26/%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/</id>
    <published>2019-11-26T12:00:00.000Z</published>
    <updated>2020-04-01T01:50:24.958Z</updated>
    
    <content type="html"><![CDATA[<p>对于一篇文章来说，分析它的主题能够达到理解文本的效果。主题建模就是通过在文档集合里面学习、识别和提取主题的过程。对于一篇文章 或者说一个文档来说，它包含着多个主题，而如何去区分不同的主题，是通过主题下面包含的多个单词来进行分析，我们能够将文档转化为一个数值向量，每一个维度对应一个主题。</p><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ul><li><strong>分类文档</strong> （比如说不同领域的新闻：科技、金融、体育新闻。通过对新闻的主题建模，能够将文本按照主题来归类）</li><li><strong>检索</strong>（当用户输入关键字的时候，就能够确认检索的文本的主题，从而在数据库进行匹配，最终返回相符的文本）</li></ul><h2 id="文本模型的可交换性"><a href="#文本模型的可交换性" class="headerlink" title="文本模型的可交换性"></a>文本模型的可交换性</h2><p>目前，大多数文本模型都基于“bag-of-words”的假设，即</p><ul><li>1.一篇文档内N个词之间的顺序可以随意互换，不影响建模过程</li><li>2.一个语料库内M个文档可以随意互换顺序，哪个文档在前哪个文档在后都无所谓。这两个性质合称为文本模型的可交换性</li></ul><h2 id="四种流行的用于主题建模的算法"><a href="#四种流行的用于主题建模的算法" class="headerlink" title="四种流行的用于主题建模的算法"></a>四种流行的用于主题建模的算法</h2><h3 id="1-LSA-Latent-semantic-analysis"><a href="#1-LSA-Latent-semantic-analysis" class="headerlink" title="1.LSA(Latent semantic analysis)"></a>1.LSA(Latent semantic analysis)</h3><p>LSA的核心思想就是将我们所拥有的文档-术语矩阵分解成相互独立的文档-主题矩阵和主题-术语矩阵。词和文档是用向量来表示的，通过向量之间的关系，来判断词与词之间 或者文档与文档之间的关系。</p><h3 id="2-pLSA"><a href="#2-pLSA" class="headerlink" title="2.pLSA"></a>2.pLSA</h3><p>pLSA，即概率潜在语义分析，采取概率方法替代 SVD 以解决问题。其核心思想是找到一个潜在主题的概率模型，该模型可以生成我们在文档-术语矩阵中观察到的数据。</p><h3 id="3-LDA"><a href="#3-LDA" class="headerlink" title="3.LDA"></a>3.LDA</h3><p>将狄利克雷视为「分布的分布」。本质上，它回答了这样一个问题：「给定某种分布，我看到的实际概率分布可能是什么样子？」</p><p>一篇文档，可以看成是一组有序的词的序列。从统计学角度来看，文档的生成可以看成是上帝抛掷骰子生成的结果，每一次抛掷骰子都生成一个词汇，抛掷N词生成一篇文档。在统计文本建模中，我们希望猜测出上帝是如何玩这个游戏的，这会涉及到两个最核心的问题：上帝都有什么样的骰子；上帝是如何抛掷这些骰子的；第一个问题就是表示模型中都有哪些参数，骰子的每一个面的概率都对应于模型中的参数；第二个问题就表示游戏规则是什么，上帝可能有各种不同类型的骰子，上帝可以按照一定的规则抛掷这些骰子从而产生词序列。</p><h3 id="4-lda2vec"><a href="#4-lda2vec" class="headerlink" title="4.lda2vec"></a>4.lda2vec</h3><p>社交媒体如微博、脸书上也会有大量值得研究的文本，这些文本规模大、更新速度更快而且语义信息不丰富、噪声高。传统的pLSA和LDA模型泛化能力弱、主题词可解释性差、分类准确性低。</p><p>文档向量表示随着word2vec模型的提出和深度学习的发展,近年来出现了很多相关研究成果。以LDA为代表的主题模型认为文档的生成是不同主题混合的结果;神经网络模型习惯于将文档表示为稠密向量。如果结合前者覆盖范围广和后者维度低的特点生成新的模型,可以做到快速检测,同对隐含语义的解释也会更好。lda2vec模型就是基于这一思想提出的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;对于一篇文章来说，分析它的主题能够达到理解文本的效果。主题建模就是通过在文档集合里面学习、识别和提取主题的过程。对于一篇文章 或者说一个文档来说，它包含着多个主题，而如何去区分不同的主题，是通过主题下面包含的多个单词来进行分析，我们能够将文档转化为一个数值向量，每一个维度对</summary>
      
    
    
    
    
    <category term="文本挖掘" scheme="https://wuruoting.club/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"/>
    
    <category term="主题建模" scheme="https://wuruoting.club/tags/%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/"/>
    
  </entry>
  
  <entry>
    <title>一份不完全的数据可视化入门指南</title>
    <link href="https://wuruoting.club/2019/10/13/%E4%B8%80%E4%BB%BD%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"/>
    <id>https://wuruoting.club/2019/10/13/%E4%B8%80%E4%BB%BD%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</id>
    <published>2019-10-13T07:00:00.000Z</published>
    <updated>2020-11-06T14:49:56.392Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-如何快速上手数据可视化？"><a href="#1-如何快速上手数据可视化？" class="headerlink" title="1. 如何快速上手数据可视化？"></a>1. 如何快速上手数据可视化？</h2><p>1.【FreeCodeCamp】<a href="https://www.freecodecamp.cn/home">https://www.freecodecamp.cn/home</a> (学习Html/Css/JavaScript)</p><p>2.【Echarts.js】<a href="https://www.echartsjs.com/zh/index.html">https://www.echartsjs.com/zh/index.html</a></p><p>3.【D3】<a href="https://d3js.org/">https://d3js.org/</a></p><p>4.【更多的工具总结】 <a href="https://zhuanlan.zhihu.com/p/24089938">https://zhuanlan.zhihu.com/p/24089938</a></p><h2 id="2-有哪些值得借鉴的优秀的数据可视化设计作品？"><a href="#2-有哪些值得借鉴的优秀的数据可视化设计作品？" class="headerlink" title="2.有哪些值得借鉴的优秀的数据可视化设计作品？"></a>2.有哪些值得借鉴的优秀的数据可视化设计作品？</h2><p>【使用Tableau Public 制作的优秀作品】<a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">https://public.tableau.com/</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">zh-cn</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">/gallery/?</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">tab=</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">viz-of-the-day&amp;type</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">=</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">viz</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day">-of-the-day</a></p><p>【使用Echarts制作的优秀作品】 <a href="https://gallery.echartsjs.com/explore.html">https</a><a href="https://gallery.echartsjs.com/explore.html">://</a><a href="https://gallery.echartsjs.com/explore.html">gallery.echartsjs.com/explore.html#sort=rank<del>timeframe=all</del>author=all</a></p><p>【信息之美获奖作品】<a href="https://www.informationisbeautifulawards.com/">https://www.informationisbeautifulawards.com/</a></p><p>【数据可视化领域的五大趋势】<a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc">https://baijiahao.baidu.com/</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc">s?id</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc">=1614710364563883354&amp;wfr=</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc">spider&amp;for</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc">=pc</a></p><p>【一位自由数据可视化设计师（ Nadieh Bremer ）的作品集】<a href="https://www.visualcinnamon.com/portfolio/">https://www.visualcinnamon.com/portfolio/</a></p><h2 id="3-数据可视化的学术研究发展情况？"><a href="#3-数据可视化的学术研究发展情况？" class="headerlink" title="3.数据可视化的学术研究发展情况？"></a>3.数据可视化的学术研究发展情况？</h2><h3 id="CCF-A类会议-刊物"><a href="#CCF-A类会议-刊物" class="headerlink" title="CCF A类会议/刊物"></a>CCF A类会议/刊物</h3><p>【IEEE Visualization Conference (IEEE VIS)】<a href="http://dblp.uni-trier.de/db/conf/visualization/index.html">http://dblp.uni-trier.de/db/conf/visualization/index.html</a></p><p>【IEEE Transactions on Visualization and Computer Graphics(TVCG)】 <a href="http://dblp.uni-trier.de/db/journals/tvcg/">http://dblp.uni-trier.de/db/journals/tvcg/</a></p><p>【ACM Knowledge Discovery and Data Mining （SIGKDD）】<a href="http://dblp.uni-trier.de/db/conf/kdd/">http://dblp.uni-trier.de/db/conf/kdd/</a></p><h3 id="国内的实验室-学者"><a href="#国内的实验室-学者" class="headerlink" title="国内的实验室/学者"></a><strong>国内的实验室/学者</strong></h3><p>【北京大学，袁晓如】 <a href="http://vis.pku.edu.cn/wiki/">http://vis.pku.edu.cn/wiki/</a></p><p>【浙江大学，陈为】 <a href="http://www.cad.zju.edu.cn/home/vagblog/">http://www.cad.zju.edu.cn/home/vagblog/</a></p><p>【同济大学，曹楠】<a href="http://www.nancao.org/">http://www.nancao.org/</a></p><p>【清华大学，刘世霞】 <a href="http://www.shixialiu.com/">http://www.shixialiu.com/</a></p><p>【四川大学，朱敏】 <a href="http://scuvis.org/">http://scuvis.org/</a></p><h2 id="4-有哪些书籍可以进行学习？"><a href="#4-有哪些书籍可以进行学习？" class="headerlink" title="4.有哪些书籍可以进行学习？"></a>4.有哪些书籍可以进行学习？</h2><p>《Knowledge Is Beautiful》<a href="https://book.douban.com/subject/11650561/">https://book.douban.com/subject/11650561/</a></p><p>《数据可视化》 <a href="https://book.douban.com/subject/25760272/">https://book.douban.com/subject/25760272/</a></p><p>《数据可视化(40位数据设计师访谈录)》 <a href="https://book.douban.com/subject/27049704/">https://book.douban.com/subject/27049704/</a></p><h2 id="5-相关的比赛？"><a href="#5-相关的比赛？" class="headerlink" title="5.相关的比赛？"></a>5.相关的比赛？</h2><p>【China Vis 挑战赛】 <a href="http://www.chinavis.org/2019/challenge.html">http://www.chinavis.org/2019/challenge.html</a></p><p>【Kaggle】 <a href="http://kaggle.com/">http://kaggle.com/</a></p><p>【天池大数据比赛】<a href="https://tianchi.aliyun.com/competition/gameList/activeList">https://tianchi.aliyun.com/competition/gameList/activeList</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-如何快速上手数据可视化？&quot;&gt;&lt;a href=&quot;#1-如何快速上手数据可视化？&quot; class=&quot;headerlink&quot; title=&quot;1. 如何快速上手数据可视化？&quot;&gt;&lt;/a&gt;1. 如何快速上手数据可视化？&lt;/h2&gt;&lt;p&gt;1.【FreeCodeCamp】&lt;a h</summary>
      
    
    
    
    
    <category term="数据可视化" scheme="https://wuruoting.club/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>git总结</title>
    <link href="https://wuruoting.club/2019/10/11/git%E6%80%BB%E7%BB%93/"/>
    <id>https://wuruoting.club/2019/10/11/git%E6%80%BB%E7%BB%93/</id>
    <published>2019-10-10T16:00:00.000Z</published>
    <updated>2020-05-17T01:10:31.807Z</updated>
    
    <content type="html"><![CDATA[<p>最近不知为什么git desktop崩了，遂重新使用命令行，总结一下git的相关命令。</p><h2 id="本地库管理"><a href="#本地库管理" class="headerlink" title="本地库管理"></a>本地库管理</h2><ol><li><p>切换到工作目录</p></li><li><p>将文件xxx（也可以添加文件夹）添加到仓库<br><code>git add xxx</code></p></li><li><p>将文件提交到仓库<br><code>git commit -m &quot;关于此次commit的描述&quot;</code></p></li><li><p>查看当前状态<br><code>git status</code></p></li><li><p>查看修改内容<br> <code>git diff</code></p></li><li><p>查看更新日志</p><p><code>git log</code></p></li></ol><h2 id="新建远程库"><a href="#新建远程库" class="headerlink" title="新建远程库"></a>新建远程库</h2><ol><li>在github上创建仓库</li><li>切换到工作目录并与本地的库关联<br><code>git remote add origin git@github.com:michaelliao/learngit.git</code></li><li>把本地库的内容推到远程库上（之后可以不用写-u)<br><code>git push -u origin master</code></li></ol><h2 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h2><p>当使用github协同工作，使用分支可以使工作更加整洁。</p><h3 id="切分支开发"><a href="#切分支开发" class="headerlink" title="切分支开发"></a>切分支开发</h3><p>git的分支可以看作指向当前结点的指针，HEAD指针始终指向文件的最新的地方。</p><p>分支的创建：<code>git branch branch1</code></p><p>分支的切换：<code>git checkout branch1</code></p><p>分支切换意味着，如果在该分支上产生的所有改动add或commit都将是在该分支下。</p><h3 id="分支的合并"><a href="#分支的合并" class="headerlink" title="分支的合并"></a>分支的合并</h3><h4 id="一、本地多个不同分支的合并"><a href="#一、本地多个不同分支的合并" class="headerlink" title="一、本地多个不同分支的合并"></a>一、本地多个不同分支的合并</h4><p>本地有多个分支时，在branch1分支下，使用<code>git merge branch2</code>就会将branch2合并到branch1分支。</p><h4 id="二、远程分支和本地分支的合并"><a href="#二、远程分支和本地分支的合并" class="headerlink" title="二、远程分支和本地分支的合并"></a>二、远程分支和本地分支的合并</h4><p><code>git pull</code>拉取远程分之后直接与本地分支进行合并，其作用相当于<code>git fetch</code>和<code>git merge</code></p><p>但是远程和本地合并时较长涉及到一致性的问题。</p><p><strong>1.如果本地分支已有未提交的修改，此时又需要pull，可使用如下命令：</strong></p><p>1）用<code>git add</code>将需要隐藏的文件保存在暂存区</p><p>2）隐藏本地分支工作：<code>git stash save &quot;message&quot;</code>  </p><p>3）执行<code>git pull</code>命令，将远程分支下拉下来，此时不会出现冲突情况</p><p>4）使用<code>git stash list</code>可查看有哪些stash。使用<code>git stash show stash@{num}</code>可以看到第num-1个stash了存储了那些内容,默认是0号存储。</p><p>5） 若要恢复原来的文件，可使用<code>git stash pop</code>命令恢复。该命令会将缓存堆栈中的对应stash删除，并将对应修改应用到当前的工作目录下,默认为第一个stash。</p><p>6）若隐藏的文件可丢弃，则可使用<code>git stash drop stash@{$num}</code>丢弃该文件的内容。</p><p>注意，使用<code>git stash</code>后，暂存区的所有文件都会被隐藏，意味着如果再次进行<code>git add</code> 暂存区是不会有东西的，使用<code>git commit</code>也是无法提交更新的，只有恢复后才能解除文件的隐藏。 </p><h4 id="三、某个分支的diverged"><a href="#三、某个分支的diverged" class="headerlink" title="三、某个分支的diverged"></a>三、某个分支的diverged</h4><p>当出现了<code>Your branch and origin/master have diverged,and have...different commits each respectively</code></p><p>此时可使用<code>git rebase origin/master</code>将分叉的分支重新合并。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近不知为什么git desktop崩了，遂重新使用命令行，总结一下git的相关命令。&lt;/p&gt;
&lt;h2 id=&quot;本地库管理&quot;&gt;&lt;a href=&quot;#本地库管理&quot; class=&quot;headerlink&quot; title=&quot;本地库管理&quot;&gt;&lt;/a&gt;本地库管理&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;</summary>
      
    
    
    
    
    <category term="git" scheme="https://wuruoting.club/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>关于人工智能，最近想谈的一些东西</title>
    <link href="https://wuruoting.club/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/"/>
    <id>https://wuruoting.club/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/</id>
    <published>2019-09-21T16:00:00.000Z</published>
    <updated>2020-06-14T16:30:37.330Z</updated>
    
    <content type="html"><![CDATA[<p>最近终于把郝景芳《人之彼岸》书后面的小科普看完并且做完了思维导图，把这个拖了太久的事情结束是因为人工智能导论课的一次作业：“人工智能是否会超越人的智力？”，下面是正文：</p><p>人工智能是否会超越人的智力？我的答案是有可能，不过目前还有很多挑战。<br>首先，这一问题将比较限定在了人的智力，更准确地说，就是人认识、理解事物并且运用知识、经验等解决问题的能力。此处不探讨人工智能是否会拥有人的情感、人的意识或是人的欲望，仅仅从“解决问题的能力”这一层面来探讨人工智能的“智力有没有可能超越人类。<br>人工智能的研究和发展目的之一，就是因为人工智能可以借由计算机来模拟人的思考和行动，让计算机能够辅助甚至代替人类完成一系列复杂的工作。因此，目前的人工智能，可以说在某些特定的领域，已经超越了人的智力。就拿AlphaGo获胜的棋局来说，可以说在围棋这一领域，人工智能已经超越了人的智力。<br>除了围棋，在语言翻译、语音识别、图像检测等诸多方面，人工智能都可以说是超越了人的智力。但承认人工智能在单个领域上的卓越性，并不等于我们认同人工智能完全超越了人的智力。<br>且不说人工智能还没有应用完任何一个微小的分支领域，即使存在那么一个时间结点，人工智能在任何一个可以应用的小分支下都能够比人类完成得更高效、更好，在那时，人工智能也只是将在这些领域中的“经验”进行叠加。如果没有综合将多个领域的结果产生出创造性的洞见，那么人工智能也仅仅只是一个有强大思考和计算能力的机器罢了，它无法拥有人类的智力。<br>人的思考过程并不只是多个领域结果的简单叠加，我们的智力不是单一的分辨图像，翻译句子或是解数学题，我们的智力高明在我们能够以我们的一切认识作为输入，输出一个非常复杂的结果。换句话说，我们能够综合地考虑问题，触类旁通，从多个角度去思考问题，而不是割裂地分解每个子问题，得到每一个答案。<br>我们能够基于我们的常识，即使只知道一个线索，通过想象、推测出整个事件。我们能够根据我们的世界观，和一系列我们意识到或者没有意识到的规则，对某件事情进行决策。我们的智力在于“综合”，而这种综合，目前还没有人工智能能够做到。如果人工智能想要拥有超越人类的智力，那么它们至少需要大量的数据集，能够将整个世界的规则、机制全部都输入来训练。<br> 上述提到的“综合的能力”，可以认为是一种需要靠智商的思考，但除此之外，人类的智力还运用在生活的方方面面，甚至在我们没有意识的情况下，就已经被使用到了。 通常，这种智力也被称为“快思考”，它们被本能驱动，但同样是由大脑的相互配合而完成的，也因此人产生了感知、情绪、情感等。而这种类型的智力，人工智能超越人类的难度要更大。<br>另外，人还具有创造力（这是否算是一种智力）。在审美和艺术上，就算我们让人工智能学习绘画、写诗、写文章，那并不是真正的创造力，只是在既定的输入下精准的模仿。人类创作的艺术品通常都会被人的经历、性格、周遭发生的事情所影响，而人工智能因为常识体系没有构建，没有自己的世界观，也没有自己的意识、情感，它们的艺术作品仍然是缺乏灵魂的。如果想要让人工智能具有这一类型的智力，那么绕不开的还是得先实现“综合”能力，注入意识，将人工智能铸造得几乎和一个人类没有什么区别才有可能实现这种类型的创作。<br>不过，如果以上所说，未来的人工智能都完美地实现了，那时人工智能会因为其强大的计算性和极高的效率而能够轻易地掌握人类所拥有的能力，在和人类的竞赛中成为永远的胜者，甚至发现了人类从未发现的规律和捷径，那时人工智能才算是真正超越了人类。<br>当然，如果它们不存在感情、不存在个人意志，也无法超越人类，也不会对人类有什么威胁。而反过来想，作为人类的我们其实是一个比目前的人工智能神奇和有智慧千百倍的生物。我们有思想、有感情、具有创造力，虽然我们也没有那么理性，在但我觉得那也是作为人的骄傲，是我们的生气之所在。<br> 当然我的观点也借鉴了郝景芳的那两篇科普文章，如果想了解可以先看看思维导图，或者直接找原文来看。</p><p><img src="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/%E7%A6%BB%E8%B6%85%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%88%B0%E6%9D%A5%E8%BF%98%E6%9C%89%E5%A4%9A%E8%BF%9C.png" alt="离超级人工智能到来还有多远"></p><p><img src="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3%E5%BA%94%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%EF%BC%9F.png" alt="人工智能时代应如何学习？"></p><p>从大一开始，我的周围很多人都在学人工智能，不过彼时它还没有很吸引我。我对人工智能最初的印象是高中的时候，因为AlphaGo写过一篇关于人工智能的议论文，那时我也是第一次知道“深度学习”。（哎想想当时的我也根本不知道那些看起来无足轻重的词汇会在未来的日子支配我的时间）上了大学以后写过一些人工智能的短篇小说和小段落，不过也都是没有理论支撑的软科幻罢了。<br>等到上学期选了机器学习的课，才稍微开始入了门，这学期也选了深度学习引论和人工智能导论两个选修。虽然我没读过几篇论文，网络也没跑过，但是我隐隐地感觉这是更加激动人心的事情。幸好我现在确实可以像一句话说的那样“做组里来无影去无踪的本科生”，真正的参与一点点事情，更多的是看到新的东西。<br>如果真的做不出什么成绩也无所谓，我只希望回忆起来的时候，我会觉得幸好那时学会了那么有意思的东西。那就已经够好了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近终于把郝景芳《人之彼岸》书后面的小科普看完并且做完了思维导图，把这个拖了太久的事情结束是因为人工智能导论课的一次作业：“人工智能是否会超越人的智力？”，下面是正文：&lt;/p&gt;
&lt;p&gt;人工智能是否会超越人的智力？我的答案是有可能，不过目前还有很多挑战。&lt;br&gt;首先，这一问题</summary>
      
    
    
    
    
    <category term="人工智能" scheme="https://wuruoting.club/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="杂谈" scheme="https://wuruoting.club/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>2019川大新生数据可视化（python wordcloud + echarts）</title>
    <link href="https://wuruoting.club/2019/09/09/2019%E5%B7%9D%E5%A4%A7%E6%96%B0%E7%94%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%88python-wordcloud-echarts%EF%BC%89/"/>
    <id>https://wuruoting.club/2019/09/09/2019%E5%B7%9D%E5%A4%A7%E6%96%B0%E7%94%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%88python-wordcloud-echarts%EF%BC%89/</id>
    <published>2019-09-09T04:00:28.000Z</published>
    <updated>2020-06-14T16:30:29.129Z</updated>
    
    <content type="html"><![CDATA[<p>8月底和同学一起为川大新生制作了一个新生数据可视化的<a href="https://mp.weixin.qq.com/s?__biz=MzA5Mzc2MDYxMw==&mid=2650063145&idx=1&sn=3516ccd3dcac87558debbd942c3ead1d&chksm=88589c23bf2f1535b19bc75f306d37682868670959df835e8e5c67bbc4adaeec278465b3c6f8&mpshare=1&scene=24&srcid=&sharer_sharetime=1567422683641&sharer_shareid=a49052cb76c97bd4594f8f49e94ec7ca#rd">推送</a>。这篇推送中插入的图片，主要使用了python的wordcloud制作词云，用echarts中的一些图表。这篇博客主要会记录一下我制作的部分。</p><h1 id="一、wordcloud制作姓名词云"><a href="#一、wordcloud制作姓名词云" class="headerlink" title="一、wordcloud制作姓名词云"></a>一、wordcloud制作姓名词云</h1><h2 id="1-Anaconda下安装wordcloud模块"><a href="#1-Anaconda下安装wordcloud模块" class="headerlink" title="1.Anaconda下安装wordcloud模块"></a>1.Anaconda下安装wordcloud模块</h2><p>如果没有安装wordcloud，可以在<a href="https://pypi.org/project/wordcloud/#files">官网</a>下载whl文件。下载好文件后，使用Anconda命令行，切到whl所在的文件目录，输入命令行：<code>pip install wordcloud-1.5.0-cp36-cp36m-win_amd64.whl</code>，然后安装成功后就可导入该模块了。<br><img src="https://img-blog.csdnimg.cn/20190908103647749.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="安装成功wordcloud"></p><h2 id="2-导入模块"><a href="#2-导入模块" class="headerlink" title="2.导入模块"></a>2.导入模块</h2><p>要制作词云，主要需导入wordcloud,matplotlib这两个模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="comment">#导入wordcloud模块和matplotlib模块</span></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud,ImageColorGenerator,STOPWORDS</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> chardet</span><br></pre></td></tr></table></figure><h2 id="3-处理数据"><a href="#3-处理数据" class="headerlink" title="3. 处理数据"></a>3. 处理数据</h2><p>由于当时得到的excel表格中，学生包括新疆、西藏等民族，姓名不是普通的姓+名的结构，给姓名的处理带来了一定困难。因此没有统计他们的姓氏。当时不了解python也可以处理excel，于是是将姓名按行存入一个txt文件，再通过python进行处理。</p><h3 id="1）-处理名字"><a href="#1）-处理名字" class="headerlink" title="1） 处理名字"></a>1） 处理名字</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取原始的姓名txt文件</span></span><br><span class="line">fileObj = open(<span class="string">'name4.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8-sig'</span>)</span><br><span class="line">ming=[]</span><br><span class="line"><span class="comment">#按行读取,姓名是三个字的同学的姓删除</span></span><br><span class="line">line=fileObj.readline()</span><br><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">if</span> (len(line)&lt;=<span class="number">4</span> <span class="keyword">and</span> len(line)&gt;<span class="number">0</span>):</span><br><span class="line">        line=line.replace(line[<span class="number">0</span>],<span class="string">""</span>)</span><br><span class="line">    ming.append(line)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">m=<span class="string">""</span>.join(ming)</span><br><span class="line">print(ming)</span><br><span class="line">fileObj2 = open(<span class="string">'ming.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">fileObj2.write(m)</span><br><span class="line">fileObj2.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 姓名全部以单字形式排列，并存入新的文档</span></span><br><span class="line">name=open(<span class="string">'ming.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line">name=name.replace(<span class="string">'·'</span>,<span class="string">''</span>)</span><br><span class="line">name=name.replace(<span class="string">'\n'</span>,<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">result=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> name:</span><br><span class="line">    result.append(i)</span><br><span class="line">    result.append(<span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line">s = <span class="string">""</span>.join(result) <span class="comment">#列表转字符串</span></span><br><span class="line"></span><br><span class="line">save = open(<span class="string">'name7.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">save.write(s)</span><br><span class="line">save.close()</span><br></pre></td></tr></table></figure><p>得到处理的结果：<br><img src="https://img-blog.csdnimg.cn/2019090919322293.png" alt="名处理结果"></p><h3 id="2）处理姓氏"><a href="#2）处理姓氏" class="headerlink" title="2）处理姓氏"></a>2）处理姓氏</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 姓</span></span><br><span class="line"></span><br><span class="line">fileObj = open(<span class="string">'name4.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8-sig'</span>)</span><br><span class="line">surname=[]</span><br><span class="line">line=fileObj.readline()</span><br><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">if</span> (len(line)&lt;=<span class="number">4</span> <span class="keyword">and</span> len(line)&gt;<span class="number">0</span>):</span><br><span class="line">        surname.append(line[<span class="number">0</span>])</span><br><span class="line">        surname.append(<span class="string">" "</span>)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">sur=<span class="string">""</span>.join(surname)</span><br><span class="line">print(surname)</span><br><span class="line">fileObj2 = open(<span class="string">'surname.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">fileObj2.write(sur)</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure><p>得到处理的结果：<br><img src="https://img-blog.csdnimg.cn/20190909193128546.png" alt="姓处理结果"></p><h2 id="4-生成词云"><a href="#4-生成词云" class="headerlink" title="4.生成词云"></a>4.生成词云</h2><p>处理完名和姓的结果后，就可以使用wordcloud函数来绘制词云。当时遇到了一个问题就是词云只能生成两个字及以上的词云，对于单个字会认为这不是一个词。解决办法是修改参数中的regexp（正则表达式）有<code>regexp=r&quot;\w[\w&#39;]*&quot;</code>，这样wordcloud就会将单字也认为是词，从而生成字云。<br>除此之外还使用到了以下几个参数：</p><blockquote><p>mask：设置为pic是为了让生成的词云具有图片的形状。#FFFFFF是不会显示字的，因此如果画面背景不是纯白也会显示字。<br>prefer_horizontal： 这个属性是让竖直的字的出现概率为1，因此词云的所有字都是竖直排列的，可读性会更强。<br>background_color=None和mode=’RGBA’ ：这两个一起设置，能够让图片的背景是透明的。（这里主要是需要和美工交接，让她帮忙上一个底色）<br>stopwords：停止词，因为处理数据是先生成了姓，因此当时考虑将姓作为停止词（也就是不会出现在词云上），但鉴于有些姓同样会出现在名字中，会影响准确性，因此并没有这样做。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读入处理过的姓名文件</span></span><br><span class="line">text2= open(<span class="string">'name7.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"><span class="comment">#读入背景图片</span></span><br><span class="line">pic = imread(<span class="string">'panda16.png'</span>)</span><br><span class="line"><span class="comment">#生成词云</span></span><br><span class="line">cloud = WordCloud(mask=pic,prefer_horizontal=<span class="number">1</span>,<span class="comment">#width=800,height=800,</span></span><br><span class="line">                  font_path=<span class="string">'C:\\Windows\\Fonts\\Nk728iWCZ.TTF'</span>,</span><br><span class="line">                  background_color=<span class="literal">None</span>,scale=<span class="number">5</span>,regexp=<span class="string">r"\w[\w']*"</span>,</span><br><span class="line">                  max_font_size = <span class="number">100</span>,mode=<span class="string">'RGBA'</span>) <span class="comment">#,stopwords=stop)</span></span><br><span class="line">cloud.generate(text2)</span><br><span class="line">image_colors = ImageColorGenerator(pic)</span><br><span class="line">cloud.recolor(color_func=image_colors)</span><br><span class="line"><span class="comment">#显示词云图片</span></span><br><span class="line">plt.imshow(cloud)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#保存图片</span></span><br><span class="line">cloud.to_file(<span class="string">'test26.png'</span>)</span><br></pre></td></tr></table></figure><p>最后生成的词云如下：<br><img src="https://img-blog.csdnimg.cn/20190909195400163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="姓氏"><br><img src="https://img-blog.csdnimg.cn/20190909195440150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="名字"></p><h1 id="二、用Python处理数据"><a href="#二、用Python处理数据" class="headerlink" title="二、用Python处理数据"></a>二、用Python处理数据</h1><p>除了用python处理词云之外，python还用于处理一些数据，比如将数据从excel格式调成json格式(便于echarts使用）。当然，当时我python处理excel文件还不太熟，因此整个处理数据（包括年龄、星座等制作后面的表格时使用到的数据）的步骤可以归纳为以下的几点：<br>1.在excel中用数据透视表进行统计，然后将得到的结果以txt文本保存。<br>2.在notepad进行简单的查找替换，将文件编码设置为utf-8。<br>3.转化为json数组时通过python读取txt文件，然后对其进行相应的处理，得到符合要求的json数组。<br>（当然后续知道可以直接在excel中转json，不过写数据处理的代码也算是让我更熟悉了python)</p><p>这里放部分的代码：</p><h3 id="1-处理日期"><a href="#1-处理日期" class="headerlink" title="1) 处理日期"></a>1) 处理日期</h3><p>因为生日的日期有多种格式（斜杠、全数值、横杠），为了让他们格式相同，所以进行了处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    <span class="keyword">if</span>(line.find(<span class="string">'/'</span>)&gt;=<span class="number">0</span>):</span><br><span class="line">        print(line)</span><br><span class="line">        line=line.replace(<span class="string">'/'</span>,<span class="string">'-'</span>)</span><br><span class="line">        fileObj2.write(line)   </span><br><span class="line">    <span class="keyword">elif</span>(line.find(<span class="string">'-'</span>)&lt;<span class="number">0</span>):</span><br><span class="line">        line_list=[]</span><br><span class="line">        line_list=list(line)</span><br><span class="line">        line_list.insert(<span class="number">4</span>,<span class="string">'-'</span>)</span><br><span class="line">        print(line_list)</span><br><span class="line">        line_list.insert(<span class="number">7</span>,<span class="string">'-'</span>)</span><br><span class="line">        print(line_list)</span><br><span class="line">        newline=<span class="string">""</span>.join(line_list)</span><br><span class="line">        print(newline)</span><br><span class="line">        fileObj2.write(newline) </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fileObj2.write(line)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure><h3 id="2）其他数据转换成json数组"><a href="#2）其他数据转换成json数组" class="headerlink" title="2）其他数据转换成json数组"></a>2）其他数据转换成json数组</h3><p>这是用来生成桑基图中的links中的数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> line:   </span><br><span class="line">    index=line.find(<span class="string">'\n'</span>)</span><br><span class="line">    blank=line.find(<span class="string">' '</span>)</span><br><span class="line">    line_list = list(line)</span><br><span class="line">    line_list.insert(index+<span class="number">1</span>,<span class="string">"&#125;,"</span>)</span><br><span class="line">    line_list.insert(<span class="number">0</span>,<span class="string">"&#123; 'name':'"</span>)</span><br><span class="line">    line_list.insert(blank+<span class="number">2</span>,<span class="string">"',\n"</span>)</span><br><span class="line">    line_list.insert(blank+<span class="number">3</span>,<span class="string">"value:"</span>)</span><br><span class="line">    </span><br><span class="line">    print(line_list)</span><br><span class="line">    <span class="comment">#转回字符串</span></span><br><span class="line">    newline=<span class="string">''</span>.join(line_list)</span><br><span class="line">    print(newline)</span><br><span class="line">    fileObj2.write(newline) </span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure><h1 id="三、echarts制作其他图表"><a href="#三、echarts制作其他图表" class="headerlink" title="三、echarts制作其他图表"></a>三、echarts制作其他图表</h1><h2 id="1-矩形树图-Treemap-制作专业人数分布图"><a href="#1-矩形树图-Treemap-制作专业人数分布图" class="headerlink" title="1.矩形树图(Treemap)制作专业人数分布图"></a>1.矩形树图(Treemap)制作专业人数分布图</h2><p>在这张图中，主要通过矩形的大小来映射专业的人数多少。图片的尺寸考虑到看推送的清晰度问题，因此设置得较长。<br><img src="https://img-blog.csdnimg.cn/20190908105527724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="矩形树图"><br>在做的时候，遇到的问题主要是字体不能够换行以及调整字体大小的问题。<br>解决办法是用：series-&gt;upperLable-&gt;normal加入<code>formatter: &#39;{b}&#39;,</code>，然后通过data中的name进行换行处理（由于矩形树图的特殊性，为了让排版更好看，手动对每一个需要换行的name进行了换行）。</p><p>series-&gt;levels中的两个元素分别表示的是学院层和学院下的专业层的不同设置。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> myChart = echarts.init(<span class="built_in">document</span>.getElementById(<span class="string">'treemap'</span>));</span><br><span class="line">option = &#123;</span><br><span class="line">    series: [&#123;</span><br><span class="line">        type: <span class="string">'treemap'</span>,</span><br><span class="line">        data: [</span><br><span class="line">            &#123;</span><br><span class="line">                name: <span class="string">'材料科学与工程学院'</span>,          </span><br><span class="line">                value: xxx,</span><br><span class="line">                children: [&#123;</span><br><span class="line">                    name: <span class="string">'材料类'</span>, </span><br><span class="line">                    value: xx,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line">                    name: <span class="string">'生物医学工程'</span>,        </span><br><span class="line">                    value: xx</span><br><span class="line">                &#125;]</span><br><span class="line">                <span class="comment">//每一个学院下的专业</span></span><br><span class="line">            &#125;,</span><br><span class="line">        ],</span><br><span class="line">        upperLabel:&#123;</span><br><span class="line">            normal:&#123;</span><br><span class="line">                ellipsis:<span class="literal">false</span>,</span><br><span class="line">                color: <span class="string">'#555'</span>,</span><br><span class="line">                show:<span class="literal">true</span>,</span><br><span class="line">                fontSize:<span class="number">10</span>,</span><br><span class="line">                fontWeight:<span class="string">'bold'</span>,</span><br><span class="line">                formatter: <span class="string">'&#123;b&#125;'</span>,</span><br><span class="line">                backgroundColor:<span class="string">'#e6eae3'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        levels:[</span><br><span class="line">            &#123;</span><br><span class="line">                color:[<span class="string">'#5bbdc8'</span>,<span class="string">'#83ccd2'</span>,<span class="string">'#7ebea5'</span>,<span class="string">'#ffefa1'</span>],</span><br><span class="line">                itemStyle: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        borderColor:<span class="string">'#e6eae3'</span>,</span><br><span class="line">                        borderWidth: <span class="number">6</span>,</span><br><span class="line">                        gapWidth: <span class="number">5</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                itemStyle: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        borderColor:<span class="string">'#e6eae3'</span>,</span><br><span class="line">                        borderWidth: <span class="number">4</span>,</span><br><span class="line">                        gapWidth: <span class="number">1</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        ],</span><br><span class="line">        label:&#123;</span><br><span class="line">            position:<span class="string">'insideLeft'</span>,</span><br><span class="line">            ellipsis:<span class="literal">false</span>,</span><br><span class="line">            color: <span class="string">'#555'</span>,</span><br><span class="line">            fontWeight:<span class="string">'bold'</span>,</span><br><span class="line">            fontSize:<span class="number">13</span>,</span><br><span class="line">            formatter:<span class="string">'&#123;b&#125;'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;]</span><br><span class="line">&#125;;</span><br><span class="line">myChart.setOption(option);</span><br></pre></td></tr></table></figure><h2 id="2-桑基图-Sankey-制作年龄流动图"><a href="#2-桑基图-Sankey-制作年龄流动图" class="headerlink" title="2.桑基图(Sankey)制作年龄流动图"></a>2.桑基图(Sankey)制作年龄流动图</h2><p><img src="https://img-blog.csdnimg.cn/20190909191646223.gif" alt="桑基图"></p><p>从桑基图中，能够看到不同年龄占男女生总人数的比例，以及占学院总人数的比例。<br>在制作桑基图时，主要遇到的问题是：年龄最小/大的人数过少，表现在echarts的图表中就会发现根本无法选中和显示出来，为了解决这个问题，将series-&gt;data-&gt;itemStyle-&gt;borderWidth中的数值改大（即增大边框宽度），这样就能够正常显示和交互了。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">option = &#123;</span><br><span class="line">    series: &#123;</span><br><span class="line">        type: <span class="string">'sankey'</span>,</span><br><span class="line">        layout: <span class="string">'none'</span>,</span><br><span class="line">        layoutIterations: <span class="number">0</span>,</span><br><span class="line">        nodeWidth: <span class="number">30</span>,</span><br><span class="line">        nodeGap: <span class="number">10</span>,</span><br><span class="line">        height: <span class="number">300</span>,</span><br><span class="line">        focusNodeAdjacency: <span class="string">'allEdges'</span>,</span><br><span class="line">        orient: <span class="string">'vertical'</span>,</span><br><span class="line">        label: &#123;</span><br><span class="line">            show: <span class="literal">true</span>,</span><br><span class="line">            position: <span class="string">'bottom'</span>,</span><br><span class="line">            <span class="comment">//[-10,60],</span></span><br><span class="line">            formatter: <span class="function"><span class="keyword">function</span>(<span class="params">val</span>) </span>&#123;</span><br><span class="line">                <span class="comment">//x轴的文字改为竖版显示</span></span><br><span class="line">                <span class="keyword">var</span> str = val.name.split(<span class="string">""</span>);</span><br><span class="line">                <span class="keyword">return</span> str.join(<span class="string">"\n"</span>);</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        data: [&#123;</span><br><span class="line">            name: <span class="string">'14岁'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#e95295'</span>,</span><br><span class="line">                borderWidth: <span class="number">6</span>,</span><br><span class="line">                borderColor: <span class="string">'#e95295'</span>,</span><br><span class="line">                opacity: <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">//其余每一个年龄除了color的设置之外，其他都是相同的</span></span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'材料科学与工程学院'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">                borderWidth: <span class="number">0</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">//其他所有学院的格式都如上所示</span></span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'男'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'女'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;],</span><br><span class="line">        </span><br><span class="line">        links: [&#123;</span><br><span class="line">            source: <span class="string">'男'</span>,</span><br><span class="line">            target: <span class="string">'15岁'</span>,</span><br><span class="line">            value: <span class="number">7</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">/*...</span></span><br><span class="line"><span class="comment">        男和女两种性别和到每一个年龄的所有link</span></span><br><span class="line"><span class="comment">        此处不公开数据*/</span></span><br><span class="line">        &#123;</span><br><span class="line">            source: <span class="string">'15岁'</span>,</span><br><span class="line">            target: <span class="string">'材料科学与工程学院'</span>,</span><br><span class="line">            value: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">          <span class="comment">/*...</span></span><br><span class="line"><span class="comment">          每一个年龄流动到每一个学院的所有link</span></span><br><span class="line"><span class="comment">        此处不公开数据*/</span></span><br><span class="line">        ],</span><br><span class="line">        lineStyle: &#123;</span><br><span class="line">            normal: &#123;</span><br><span class="line">                color: <span class="string">'source'</span>,</span><br><span class="line">                curveness: <span class="number">0.75</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 使用刚指定的配置项和数据显示图表。</span></span><br><span class="line">myChart.setOption(option);</span><br></pre></td></tr></table></figure><h2 id="3-柱状图制作男女比例图"><a href="#3-柱状图制作男女比例图" class="headerlink" title="3.柱状图制作男女比例图"></a>3.柱状图制作男女比例图</h2><p><img src="https://img-blog.csdnimg.cn/20190908105606347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="男女比例图"><br>柱状图制作的比较顺利。右侧的数值可以通过设置两个y轴来解决。另外，圆角的柱状图可以在series-&gt;itemStyle-&gt;barBorderRadius中设置圆角的半径。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> myChart = echarts.init(<span class="built_in">document</span>.getElementById(<span class="string">'gendermap'</span>));</span><br><span class="line"></span><br><span class="line">option = &#123;</span><br><span class="line">    backgroundColor: <span class="string">'#fff'</span>,</span><br><span class="line">    tooltip: &#123;</span><br><span class="line">        trigger: <span class="string">'axis'</span>,</span><br><span class="line">        axisPointer: &#123;<span class="comment">// 坐标轴指示器，坐标轴触发有效</span></span><br><span class="line">            type: <span class="string">'shadow'</span>        </span><br><span class="line">            <span class="comment">// 默认为直线，可选为：'line'或'shadow'</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    legend: &#123;</span><br><span class="line">        data: [<span class="string">'男生'</span>, <span class="string">'女生'</span>],</span><br><span class="line">    &#125;,</span><br><span class="line">    grid: &#123;</span><br><span class="line">        left: <span class="string">'3%'</span>,</span><br><span class="line">        right: <span class="string">'4%'</span>,</span><br><span class="line">        bottom: <span class="string">'3%'</span>,</span><br><span class="line">        containLabel: <span class="literal">true</span></span><br><span class="line">    &#125;,</span><br><span class="line">    yAxis: [</span><br><span class="line">        &#123;</span><br><span class="line">            type: <span class="string">'category'</span>,</span><br><span class="line">            data: [<span class="string">'外国语学院'</span>,</span><br><span class="line">                <span class="string">'文学与新闻学院'</span>,</span><br><span class="line">                ...],</span><br><span class="line">                <span class="comment">/*这里存储的是图中左侧显示的每一个学院</span></span><br><span class="line"><span class="comment">                为了减少篇幅就不写完了*/</span></span><br><span class="line">            splitLine: &#123;</span><br><span class="line">                show: <span class="literal">true</span>,</span><br><span class="line">                ineStyle:&#123;<span class="attr">type</span>:<span class="string">'dashed'</span>&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">            axisLine: &#123;</span><br><span class="line">                lineStyle: &#123;</span><br><span class="line">                    color: <span class="string">'#000'</span>,</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            axisLabel: &#123;</span><br><span class="line">                color: <span class="string">'#000'</span>,</span><br><span class="line">                fontSize:<span class="number">15</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            type: <span class="string">'category'</span>,</span><br><span class="line">            data: [<span class="string">'0.24:1'</span>,...],</span><br><span class="line">            <span class="comment">/*这里存储的是图中右边显示的所有的比例（用字符串存储）</span></span><br><span class="line"><span class="comment">            为了减少篇幅就不写完了*/</span></span><br><span class="line">            text:<span class="string">'男女比'</span>,</span><br><span class="line">            splitLine: &#123;</span><br><span class="line">                show: <span class="literal">false</span></span><br><span class="line">            &#125;,</span><br><span class="line">            axisLine: &#123;</span><br><span class="line">                lineStyle: &#123;</span><br><span class="line">                    color: <span class="string">'#000'</span>,</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            axisLabel: &#123;</span><br><span class="line">                color: <span class="string">'#000'</span>,</span><br><span class="line">                fontSize:<span class="number">15</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    ],</span><br><span class="line">    xAxis: [</span><br><span class="line">        &#123;</span><br><span class="line">            show: <span class="literal">false</span>,</span><br><span class="line">            type: <span class="string">'value'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    series : [</span><br><span class="line">        &#123;</span><br><span class="line">            name:<span class="string">'女生'</span>,</span><br><span class="line">            type:<span class="string">'bar'</span>,</span><br><span class="line">            stack: <span class="string">'总量'</span>,</span><br><span class="line">            data:[],</span><br><span class="line">            <span class="comment">/*这里的data包括每一个学院的女生的数量</span></span><br><span class="line"><span class="comment">            此处就不公开该数据了*/</span></span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                barBorderRadius: <span class="number">20</span>,</span><br><span class="line">                <span class="comment">//设置柱形的圆角，可以设置该半径</span></span><br><span class="line">                color: <span class="keyword">new</span> echarts.graphic.LinearGradient(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, [&#123;</span><br><span class="line">                    offset: <span class="number">0.4</span>,</span><br><span class="line">                    color: <span class="string">"#ffefa1"</span></span><br><span class="line">                &#125;,</span><br><span class="line"></span><br><span class="line">                ])</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            name:<span class="string">'男生'</span>,</span><br><span class="line">            type:<span class="string">'bar'</span>,</span><br><span class="line">            stack: <span class="string">'总量'</span>,</span><br><span class="line">            data:[],</span><br><span class="line">            <span class="comment">/*这里的data包括每一个学院的男生的数量</span></span><br><span class="line"><span class="comment">            需要将数量取成负数</span></span><br><span class="line"><span class="comment">            这样能够让男女数量分布在坐标轴的两边（中轴对齐）*/</span></span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                barBorderRadius: <span class="number">20</span>,</span><br><span class="line">                color: <span class="keyword">new</span> echarts.graphic.LinearGradient(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, [&#123;</span><br><span class="line">                    offset: <span class="number">0.4</span>,</span><br><span class="line">                    color: <span class="string">"#5bbdc8"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                ])</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (option &amp;&amp; <span class="keyword">typeof</span> option === <span class="string">"object"</span>) &#123;</span><br><span class="line">    myChart.setOption(option, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="四、设计与配色"><a href="#四、设计与配色" class="headerlink" title="四、设计与配色"></a>四、设计与配色</h1><p>使用了echarts和python，可视化看上去的确没有什么难度，但如果说要做出来能够放在推送上的视觉美观的作品，就不得不考虑设计和配色了。<br>首先是两个姓氏和名字的词云，大川的美工小姐姐基于原图，帮我们画了底色，让整个图案变得更鲜明。<br>其次，最初我们制作的图表的风格不统一，配色也非常混乱。在讨论后我们选择用了蓝色和黄色作为两种主色调。在这个基础上做好的图都要重新换一身衣服。当看到统一的配色的时候，风格自然地就融入在一起了。<br>关于配色当时我们参考了一些网站，包括 <a href="http://www.360doc.com/content/19/0524/11/12235645_837879925.shtml">配色方案</a>，还有其他的一些网上常见的有RGB值的色卡，最后定下来颜色。</p><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>这个可视化推送我们断断续续做了一周左右。因为我python其实不算熟，做词云、数据处理的时候是边学边做，绕了不少弯路，配色那里也是反复修改，每张图都是十几稿，词云生成了差不多三十张（笑哭）。不过总算也将一个相对成熟的可视化作品完成了，3万点击量和很多令人感动的留言真的是让人成就感满满呐。<br>还有一点我很惊讶，我司空见惯，甚至觉得有点难看的echarts，在不是计算机专业的美工看来非常稀奇，希望更多不是计算机的人也能使用这些可视化工具，如果这篇文章能有些帮助的话，那就太好了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;8月底和同学一起为川大新生制作了一个新生数据可视化的&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5Mzc2MDYxMw==&amp;mid=2650063145&amp;idx=1&amp;sn=3516ccd3dcac87558debbd942c3e</summary>
      
    
    
    
    
    <category term="数据可视化" scheme="https://wuruoting.club/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
</feed>
