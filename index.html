<!DOCTYPE html>
<html lang="zh-CN">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<link rel="alternate" href="/atom.xml" title="Ruoting Wu's Blog"><link rel="shortcut icon" type="image/x-icon" href="/cat.jpg?v=2.11.0" />
<link rel="canonical" href="https://codingClaire.github.io/"/>

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" /><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "UAlwruFunxBGx8T5d5R2vDKT-gzGzoHsz",
      appKey: "c0YVFIAlMCeKLx899vBJAnMV"
    });
  </script><script>
  window.config = {"leancloud":{"app_id":"UAlwruFunxBGx8T5d5R2vDKT-gzGzoHsz","app_key":"c0YVFIAlMCeKLx899vBJAnMV"},"toc":true,"fancybox":true,"pjax":"","latex":true};
</script>

    <title>Ruoting Wu's Blog</title>
  <meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Ruoting Wu's Blog" type="application/atom+xml">
</head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Ruoting Wu's Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a><a href="/tags">
        <li class="mobile-menu-item">标签
          </li>
      </a><a href="/about">
        <li class="mobile-menu-item">关于
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Ruoting Wu's Blog</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            标签
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about">
            关于
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><section id="posts" class="posts"><article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/06/29/2021-07-01-attention/">Attention Mechanism总结</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-06-29
        </span><span class="post-visits"
             data-url="/2021/06/29/2021-07-01-attention/"
             data-title="Attention Mechanism总结">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>[toc]</p>
<h2 id="Neural-Machine-Translation-NMT"><a href="#Neural-Machine-Translation-NMT" class="headerlink" title="Neural Machine Translation(NMT)"></a>Neural Machine Translation(NMT)</h2><p>Neural Machine Translation,简称NMT, 是指使用深度学习来完成机器翻译任务。NMT任务是一个端到端的学习任务，输入一个序列直接输出对应的目标序列。NMT可以被分为两个步骤：编码和解码。如图所示：</p>
<div align="center">    
<img src="/2021/06/29/2021-07-01-attention/1.png" width="50%" height="50%">
</div>

<center>图1</center>

<p><strong>-encoder</strong></p>
<p>在encoder阶段，模型输入语句 $x=(x_1,…x_{T_x})$ ，使用RNN计算上下文向量（context vector），其中t时刻的隐含状态计算公式如下：<br>$$<br>h_t=f(x_t,h_{t-1})<br>$$<br>上下文向量：<br>$$<br>c=q({h_1,…h_{T_x}})<br>$$<br>$f$和$q$是两个非线性函数， (<a href="https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" target="_blank" rel="noopener">Sutskever et al.,2014</a>)使用LSTM作为$f$, $q({h_1,…h_T })= h_T$作为$q$。</p>
<p>-<strong>decoder</strong></p>
<p>在decoder阶段，模型逐个预测单词。当预测单词$y_{t^{‘}}$时，给定的上下文向量$c$和所有之前预测的单词${y_1,…y_{t^{‘}-1}}$将会用于预测。decoder生成的目标序列$y=(y_1,…y_{T_y})$，条件概率为：<br>$$<br>p(y)=\prod_{t=1}^{T}p(y_t│{y_1,…y_{t-1}},c)<br>$$</p>
<ul>
<li>如果使用RNN，则条件概率可以被表示为$p(y_t│y_1,…y_{t-1},c)=g(y_{t-1},s_t,c)$</li>
<li>如果使用Attention机制，</li>
</ul>
<h3 id="coditional-probability"><a href="#coditional-probability" class="headerlink" title="coditional probability"></a>coditional probability</h3><h2 id="Seq2seq模型"><a href="#Seq2seq模型" class="headerlink" title="Seq2seq模型"></a>Seq2seq模型</h2><p>Seq2seq模型 (<a href="https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" target="_blank" rel="noopener">Sutskever et al.,2014</a>)是基于encoder-decoder框架下使用LSTM对文本进行翻译。</p>
<h3 id="encoder-decoder框架"><a href="#encoder-decoder框架" class="headerlink" title="encoder-decoder框架"></a>encoder-decoder框架</h3><div align="center">    
<img src="/2021/06/29/2021-07-01-attention/2.png" width="90%" height="90%">
</div>

<center>图2 （图片来源：Sutskever et al.2014）</center>

<p>图2中，模型输入句子“ABC&lt;EOS&gt;”, 输出对应的翻译句子“WXYZ&lt;EOS&gt;”，当decoder输入Z时，模型预测出&lt;EOS&gt;字符（end-of-sentence)，表示预测结束。</p>
<p>encoder-decoder框架是sequence-to-sequence任务中的一个标准的模型，其中包括两个组件：</p>
<p>encoder: 读入原始的序列，生成整个输入序列的representation(即输入语句的embedding，也被称作context vector) 。</p>
<p>decoder: 使用encoder输出的representation，生成目标序列。</p>
<h3 id="Seq2seq的问题"><a href="#Seq2seq的问题" class="headerlink" title="Seq2seq的问题"></a>Seq2seq的问题</h3><p>RNN结构存在着长程梯度消失的问题，随着输入句子长度的增加，结构的效果会有所下降。</p>
<p>seq2seq中，每一步</p>
<h2 id="Attention机制"><a href="#Attention机制" class="headerlink" title="Attention机制"></a>Attention机制</h2><p>Attention(<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau et al.,2015</a>)</p>
<h2 id="Attention-in-NMT"><a href="#Attention-in-NMT" class="headerlink" title="Attention in NMT"></a>Attention in NMT</h2><h3 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h3><p>在encoder部分，使用的是一个双向的RNN（BiRNN），会生成一个前向的隐藏状态序列和后向的隐藏状态序列，将前向和后向对应的状态进行连接（concate）。</p>
<div align="center">    
<img src="/2021/06/29/2021-07-01-attention/3.png" width="50%" height="50%">
</div>

<center>图3 双向RNN原理（图片来源：Yang et al.2020）

<h3 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h3><div align="center">    
<img src="/2021/06/29/2021-07-01-attention/4.png" width="25%" height="25%">
</div>


<p>attention机制</p>
<p>在解码翻译时模拟搜索输入序列</p>
<p>$$<br>p(y_t│y_1,…y_{t-1},x)=g(y_{i-1},s_i,c_i)<br>$$<br>$s_i$是RNN在i时刻的隐藏状态，$s_i=f(s_{i-1},y_{i-1},c_i)$，这里和seq2seq模型的区别是，seq2seq仅会产生一个上下文向量$c$，但通过attention机制会生成多个上下文向量，时间$i$的上下文向量为$c_i$，由隐藏状态的加权和计算得出：<br>$$<br>c_i=\Sigma_{j=1}^{T_x}\alpha_{ij}h_j<br>$$<br>相当于计算所有的annotation(状态）的期望。$\alpha_{ij}$表示i时刻第j个状态的权重，这个权重可以被理解成目标语言生成的$y_i$能够翻译源语言的单词$x_j$的概率，计算公式为：<br>$$<br>α<em>{ij}=\frac{exp⁡(e</em>{ij})}{\Sigma_{k=1}^{T_x}exp⁡(e_{ik})}<br>$$</p>
<p>$e_{ij}=a(s_{i-1},h_j)$</p>
<p>alignment model: )  score表示输入j位置和输出的i位置有多match</p>
<p>注意力机制保证了encoder不需要将所有的原始语句都编码为一个固定长度的向量。</p>
<h3 id="alignment-visualizations"><a href="#alignment-visualizations" class="headerlink" title="alignment visualizations"></a>alignment visualizations</h3><h2 id="Attention-in-Graph"><a href="#Attention-in-Graph" class="headerlink" title="Attention in Graph"></a>Attention in Graph</h2><h2 id="Attention-Family"><a href="#Attention-Family" class="headerlink" title="Attention Family"></a>Attention Family</h2><p>根据attention score计算方式的不同，有如下的attention机制：</p>
<ul>
<li>additive attention</li>
<li>dot-product (multiplicative) attention</li>
<li>scaled Dot-Product Attention</li>
</ul>
<h3 id="query、values和keys"><a href="#query、values和keys" class="headerlink" title="query、values和keys"></a>query、values和keys</h3><p>values/keys: 把编码好的输入的表示看成key-value pairs$(K,V)$  ,长度为N, key和value皆是encoder的隐藏状态。</p>
<p>query：在decoder阶段，之前的输出会被压缩成一个query$(Q)$,长度为M。decoder的输出用于映射这个query和key-value pairs的集合。模型decoder会输出一个word的distribution, query表示最有可能的单词的表示向量。</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>可以把它理解成一个全连接层，权重是由输入的成对关系动态生成的。</p>
<p>输入向量，输出相同数量的向量，相当于一个encoder。</p>
<p><img src="/2021/06/29/2021-07-01-attention/image-20210702092147189.png" alt="demo"></p>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><ul>
<li><p>原论文： Attention is all you need  (2017 NIPS)</p>
<p><img src="/2021/06/29/2021-07-01-attention/image-20210702092323838.png" alt="image-20210702092323838"></p>
</li>
</ul>
<h3 id="Encoder-amp-Decoder"><a href="#Encoder-amp-Decoder" class="headerlink" title="Encoder&amp;Decoder"></a>Encoder&amp;Decoder</h3><p><img src="/2021/06/29/2021-07-01-attention/image-20210702065725298.png" alt="image-20210702065725298"></p>
<h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><ul>
<li><p>层数$N=6$，每层有两个sub-layers，分别是多头自注意力机制和根据位置的全连接前馈网络</p>
</li>
<li><p>两个子层之前使用残差连接[11]和正则化</p>
</li>
<li><p>生成K、V矩阵</p>
</li>
</ul>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><ul>
<li><p>层数$N=6$，在encoder的两个子层之间加入第三层</p>
</li>
<li><p>对encoder的输出使用多头注意力机制</p>
</li>
<li><p>对decoder的第一层多头注意力层进行了修改-&gt;masking multi-head attention 保证第一层注意力机制在预测当前位置的单词时只依赖当前位置之前的单词</p>
</li>
<li><p>生成Q矩阵</p>
</li>
</ul>
<h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><ul>
<li>$d_{model}$是词embedding的维度，论文中取512。</li>
<li>偶数位置：$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$ </li>
<li>奇数位置：$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$ </li>
</ul>
<p>绝对位置向量中蕴含着相对位置的信息，相对位置会在注意力机制中消失。</p>
<h3 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled-Dot-Product Attention"></a>Scaled-Dot-Product Attention</h3><p><img src="/2021/06/29/2021-07-01-attention/image-20210702065823387.png" alt="image-20210702065823387"><br>$$<br>Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V=AV<br>$$<br>${d_k}$是key和value的维度，$QK^T$保持方差为1。</p>
<h3 id="Multi-Head-Self-Attention"><a href="#Multi-Head-Self-Attention" class="headerlink" title="Multi-Head Self-Attention"></a>Multi-Head Self-Attention</h3><p><img src="/2021/06/29/2021-07-01-attention/image-20210702065858923.png" alt="image-20210702065858923"></p>
<p>多个平行的attention层分别获得各自的Q、K、V：<br>$$<br>MultiHead(Q,K,V)=Concat(head_1,…,head_h)W^O\space where\space head_i=Attention(QW_i^Q,KW_i^K,VW_I^V)<br>$$</p>
<h3 id="Transformer中的注意力机制"><a href="#Transformer中的注意力机制" class="headerlink" title="Transformer中的注意力机制"></a>Transformer中的注意力机制</h3><ul>
<li>self-attention in encoder and decoder:  $Q=K=V=X$</li>
<li>masked self-attention:  在transformer的decoder中，masked是保证attention加权计算时忽略当前位置后面的单词，保证信息来源于当前位置以及之前的位置。</li>
<li>cross-attention:  keys和values来源于最后一层的encoder的输入。</li>
</ul>
<h3 id="Positional-wise-Feed-Forward-Network"><a href="#Positional-wise-Feed-Forward-Network" class="headerlink" title="Positional-wise Feed-Forward Network"></a>Positional-wise Feed-Forward Network</h3><p>$$<br>FFN(x)=max(0,xW_1+b_1)W_2+b_2<br>$$</p>
<h3 id="Residual-Connection-and-Normalization"><a href="#Residual-Connection-and-Normalization" class="headerlink" title="Residual Connection and Normalization"></a>Residual Connection and Normalization</h3><p><img src="/2021/06/29/2021-07-01-attention/image-20210702081304496.png" alt="image-20210702081304496"></p>
<p>残差结构：输出的Z和经过位置编码的X对位相加，作为输出。</p>
<p>Layer Normalization：不需要像Batch Normalization一样考虑所有batch，只需要考虑同一个example中的不同feature计算均值和方差，然后对example的向量进行normalization。</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul>
<li>teacher forcing: 使用正确的truth作为input。</li>
</ul>
<h2 id="Transformer-Family"><a href="#Transformer-Family" class="headerlink" title="Transformer Family"></a>Transformer Family</h2><p><img src="/2021/06/29/2021-07-01-attention/image-20210702092543139.png" alt="image-20210702092543139"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. <a href="https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" target="_blank" rel="noopener">“Sequence to sequence learning with neural networks.”</a> <em>Advances in neural information processing systems</em>. 2014.</p>
<p>[2] Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">“Neural machine translation by jointly learning to align and translate.”</a> ICLR. 2015.</p>
<p>[3] Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. <a href="https://nlp.stanford.edu/pubs/emnlp15_attn.pdf" target="_blank" rel="noopener">“Effective Approaches to Attention-based Neural Machine Translation.”</a> EMNLP. 2015.</p>
<p>[4] Yang, Shuoheng, Yuxin Wang, and Xiaowen Chu. <a href="https://arxiv.org/pdf/2002.07526.pdf" target="_blank" rel="noopener">“A survey of deep learning techniques for neural machine translation.”</a> <em>arXiv preprint arXiv:2002.07526</em> (2020).</p>
<ol>
<li><a href="https://arxiv.org/pdf/2106.04554.pdf" target="_blank" rel="noopener">A Survey of Transformers</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention! by Lilian Weng</a></li>
<li><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/self_v7.pdf" target="_blank" rel="noopener">Self-Attention by Li Hungyi</a></li>
<li><a href="https://arxiv.org/abs/2009.06732" target="_blank" rel="noopener">Efficient Transformer A survey</a></li>
</ol>
</center>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/05/23/2021-05-23-anomaly-detection-5/">【异常检测5】基于集成学习的异常检测</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-05-23
        </span><span class="post-visits"
             data-url="/2021/05/23/2021-05-23-anomaly-detection-5/"
             data-title="【异常检测5】基于集成学习的异常检测">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p><a href="https://gitee.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E4%BA%94%E3%80%81%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95.md" target="_blank" rel="noopener">DataWhale组队学习活动</a></p>
</blockquote>
<blockquote>
<p>集成学习主要分为三种方法：</p>
<p>1.Boosting（提升）：主要包括两种方法AdaBoost和Gradient Boost，其中Gradient Boost方法的代表是梯度提升决策树（GDBT)</p>
<p>2.Bagging: 主要方法有随机森林</p>
<p>3.Stacking</p>
</blockquote>
<p>通过集成学习来进行异常检测的方法主要有两种，分别是特征Feature Bagging和孤立森林（Isolation Forest)。</p>
<h2 id="Feature-Bagging"><a href="#Feature-Bagging" class="headerlink" title="Feature Bagging"></a>Feature Bagging</h2><p>Feature Bagging将Bagging的思想应用在特征上。它结合了多个异常检测算法的结果，每个异常检测算法使用的特征都是从原始特征集合中随机选取的特征子集合。每种异常检测的方法会检测出不同的异常点，然后通过异常点分值来对结果进行合并。</p>
<h3 id="基础框架"><a href="#基础框架" class="headerlink" title="基础框架"></a>基础框架</h3><p><img src="/2021/05/23/2021-05-23-anomaly-detection-5/image-20210523133318831.png" alt="image-20210523133318831"></p>
<p>上述为这种方法的基本框架，每个异常检测的算法会选取每所有样本的d/2-d个特征，d表示原始的特征数，输出不同的分数向量$AS_t(j)$，表示第$t$个方法中，数据集中数据$j$是异常点的概率。由于总共有$T$个方法，那么会有$T$个异常分数向量，最后使用COMBINE函数对向量进行合并，最后生成一个$AS_{FINAL}$向量，表示数据点是异常点的最终的概率。</p>
<h3 id="COMBINE方法"><a href="#COMBINE方法" class="headerlink" title="COMBINE方法"></a>COMBINE方法</h3><h4 id="1-Breadth-First-广度优先"><a href="#1-Breadth-First-广度优先" class="headerlink" title="1.Breadth-First 广度优先"></a>1.Breadth-First 广度优先</h4><p><img src="/2021/05/23/2021-05-23-anomaly-detection-5/image-20210523133448116.png" alt="image-20210523133448116"></p>
<h4 id="2-Cumulative-Sum-累积求和"><a href="#2-Cumulative-Sum-累积求和" class="headerlink" title="2.Cumulative Sum 累积求和"></a>2.Cumulative Sum 累积求和</h4><p><img src="/2021/05/23/2021-05-23-anomaly-detection-5/image-20210523133521315.png" alt="image-20210523133521315"></p>
<h3 id="优劣"><a href="#优劣" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p>
<p>feature bagging能够降低方差（bagging方法使用有放回抽样，数据集间会有重复的样本，每个模型之间具有相关关系，设相关系数为$\rho$，模型均值的方差可以被表示为：</p>
<p><img src="/2021/05/23/2021-05-23-anomaly-detection-5/image-20210524003416272.png" alt="image-20210524003416272"></p>
<p>当n增大时，模型整体的方差会趋向于$\rho\sigma^2$，模型方差会降低。</p>
<h2 id="孤立森林（Isolation-Forests）"><a href="#孤立森林（Isolation-Forests）" class="headerlink" title="孤立森林（Isolation Forests）"></a>孤立森林（Isolation Forests）</h2><h3 id="整体思想"><a href="#整体思想" class="headerlink" title="整体思想"></a>整体思想</h3><p>假设我们用一个随机超平面来切割数据空间，切一次可以生成两个子空间。然后我们继续用随机超平面来切割每个子空间并循环，直到每个子空间只有一个数据点为止。直观上来讲，那些具有高密度的簇需要被切很多次才会将其分离，而那些低密度的点很快就被单独分配到一个子空间了。孤立森林认为这些很快被孤立的点就是异常点。</p>
<p>孤立森林使用集成方法得到收敛值，将多种切割的方法进行平均，使得结果更为可靠。</p>
<h3 id="孤立树的生成"><a href="#孤立树的生成" class="headerlink" title="孤立树的生成"></a>孤立树的生成</h3><p>孤立森林是由t棵孤立的树构成，每个树是随机二叉树，对异常点来说，它会很快地被划分到叶子节点，因此叶子节点到根节点的路径越短，数据可能越异常。在这个过程中，不需要知道样本的标签，可以直接通过孤立森林构造树的过程来判断样本是否异常，所以孤立森林的方法是无监督的。树的构造方法如下：</p>
<blockquote>
<p>1)从训练数据中随机选择一个样本子集，放入树的根节点；</p>
<p>2)随机指定一个属性，随机产生一个切割点V，即属性A的最大值和最小值之间的某个数；</p>
<p>3)根据属性A对每个样本分类，把A小于V的样本放在当前节点的左孩子中，大于等于V的样本放在右孩子中，这样就形成了2个子空间；</p>
<p>4) 在孩子节点中递归步骤2和3，不断地构造左孩子和右孩子，直到孩子节点中只有一个数据，或树的高度达到了限定高度。</p>
</blockquote>
<p>孤立森林的不同的分支对应于数据的不同局部子空间区域，较小的路径对应于孤立子空间的低维，因此这也是一种基于子空间的方法。</p>
<h3 id="路径长度计算"><a href="#路径长度计算" class="headerlink" title="路径长度计算"></a>路径长度计算</h3><p><img src="https://gitee.com/datawhalechina/team-learning-data-mining/raw/master/AnomalyDetection/img/image-20210103183909407.png" alt="img"></p>
<h3 id="优劣-1"><a href="#优劣-1" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p>
<ul>
<li>计算成本相比基于距离或基于密度的算法更小。</li>
<li>具有线性的时间复杂度。</li>
<li>在处理大数据集上有优势。</li>
</ul>
<p>劣势：</p>
<ul>
<li>不适用于超高维数据，每次随机选取维度，如果维度过高，则会存在过多噪音。</li>
</ul>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/05/20/2021-05-20-anomaly-detection-4/">【异常检测4】基于相似度的方法</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-05-20
        </span><span class="post-visits"
             data-url="/2021/05/20/2021-05-20-anomaly-detection-4/"
             data-title="【异常检测4】基于相似度的方法">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p><a href="https://gitee.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E5%9B%9B%E3%80%81%E5%9F%BA%E4%BA%8E%E9%82%BB%E8%BF%91%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95.md" target="_blank" rel="noopener">DataWhale组队学习活动</a></p>
</blockquote>
<p>基于相似度的异常检测方法中，主要考虑异常点和正常点的相似度。相似度的度量有两种方式：基于距离的和基于密度的。</p>
<h2 id="基于距离的度量"><a href="#基于距离的度量" class="headerlink" title="基于距离的度量"></a>基于距离的度量</h2><p>基于距离的度量<strong>通过最近邻距离来定义异常值</strong>，当某个点的k邻近距离远大于正常点时，它被定义为异常点。k邻近距离指的是在空间中离该点最近的k个邻居的平均距离。那么通常查找某个点的k邻近距离可以使用循环嵌套的方法。首先循环遍历每个数据，然后进行异常判断，计算当前点与其他点的距离，如果当前节点中有k个数据点与它的距离小于D，那么这个点就是非异常的。这种方法的时间复杂度为$O(N^{2})$，数据量较大时，可以使用修剪方法加快计算。<br>以下是两种修剪的方法：</p>
<h3 id="1-基于单元的方法"><a href="#1-基于单元的方法" class="headerlink" title="1.基于单元的方法"></a>1.基于单元的方法</h3><p>数据空间被划分为单元格，单元格的宽度是阈值D和数据维数的函数。</p>
<h3 id="2-基于索引的方法"><a href="#2-基于索引的方法" class="headerlink" title="2.基于索引的方法"></a>2.基于索引的方法</h3><p>利用多维索引结构(如 $\mathrm{R}$ 树、$k-d$ 树)来搜索每个数据对象 $A$ 在半径 $D$ 范围 内的相邻点。</p>
<h2 id="基于密度的度量"><a href="#基于密度的度量" class="headerlink" title="基于密度的度量"></a>基于密度的度量</h2><p>基于密度的算法主要有局部离群因子(LocalOutlierFactor,LOF)，以及LOCI、CLOF等基于LOF的改进算法。</p>
<h3 id="1-k-距离（k-distance-p-）"><a href="#1-k-距离（k-distance-p-）" class="headerlink" title="1.k-距离（k-distance(p)）"></a>1.k-距离（k-distance(p)）</h3><p>p点的k-距离就是p距离数据集的每一个点的距离中第k近的距离，就是k-距离。</p>
<h3 id="2-k-邻域（k-distance-neighborhood）"><a href="#2-k-邻域（k-distance-neighborhood）" class="headerlink" title="2.k-邻域（k-distance neighborhood）"></a>2.k-邻域（k-distance neighborhood）</h3><p>k-距离引申出k-邻域，k-邻域是一个集合，这个集合包含所有到点p的距离小于等于k-距离的所有点。</p>
<h3 id="3-可达距离（reachability-distance）"><a href="#3-可达距离（reachability-distance）" class="headerlink" title="3.可达距离（reachability distance）"></a>3.可达距离（reachability distance）</h3><p>给定点p关于o的可达距离的计算取决于p是否在o的k-邻域内。如果p在o的k-邻域内，那么可达距离就是o的k-距离，如果不在k-邻域内，那么科大距离就是p和o的实际距离。</p>
<blockquote>
<p>可达距离可以减少距离的计算开销，用一个阈值把需要计算的部分截断了，$k$的值越高，无需计算的邻近点越多，计算开销越小。但是另一方面，$k$的值变高，可能意味着可达距离变远，对集群点和离群点的区分度可能变低。因此，如何选择$k$值，是LOF算法能否达到效率与效果平衡的重要因素。</p>
</blockquote>
<h3 id="4-局部可达密度（local-reachability-density）"><a href="#4-局部可达密度（local-reachability-density）" class="headerlink" title="4.局部可达密度（local reachability density）"></a>4.局部可达密度（local reachability density）</h3><p>给定点p关于o的局部可达密度是p到o的k-邻域内所有点的可达距离平均值的导数。<br>计算时需要避免数据集内所有数据落在同一点上，此时可达距离之和为0，局部密度就是∞。</p>
<h3 id="5-局部异常因子-LOF"><a href="#5-局部异常因子-LOF" class="headerlink" title="5.局部异常因子(LOF)"></a>5.局部异常因子(LOF)</h3><p>局部异常银子是通过每个点的局部可达密度和它们的k个邻点的局部可达密度进行比较，得到LOF。<br>LOF是对象p的邻居点o的局部可达密度的平均值与p的局部可达密度的比值。<br>LOF数值就是离群点分数。</p>
<p>数据的LOF值越高，通常会有更稀疏的邻居，更可能是异常点。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/05/17/2021-05-17-anomaly-detection-3/">【异常检测3】线性模型（线性回归、主成分分析）</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-05-17
        </span><span class="post-visits"
             data-url="/2021/05/17/2021-05-17-anomaly-detection-3/"
             data-title="【异常检测3】线性模型（线性回归、主成分分析）">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p><a href="https://gitee.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E4%B8%89%E3%80%81%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.md" target="_blank" rel="noopener">DataWhale组队学习活动</a></p>
</blockquote>
<h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>回归问题在某种程度上等价于函数的拟合，即选择一条函数曲线，使其能很好地拟合已知数据，并较好地预测未知数据。回归问题的目的是求解数据的相关性。解决回归问题主要可以分为两类，一类是线性回归，通过其他变量预测某一个属性值；另一类是主成分分析，是通过潜在变量来代表数据。</p>
<p>注意回归问题的求解有两个假设：</p>
<p>1.近似线性相关假设。</p>
<p>2.子空间假设。</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="什么是线性回归？"><a href="#什么是线性回归？" class="headerlink" title="什么是线性回归？"></a>什么是线性回归？</h3><p>线性回归通过线性方程组来建模不同维度的向量之间的关系。由于样本数通常远大于数据维度，无法直接求解线性方程组，因此通过优化最小化模型预测值和真实数据的误差。</p>
<p>线性回归一般研究的是自变量对因变量的影响，相当于找到自变量和因变量的关系，可以用于解决回归、分类或预测等问题。线性回归根据自变量的个数可以分为一元线性回归和多元线性回归。一元线性回归指自变量只有一个，研究的是单变量对因变量的影响。多元线性回归则是研究多个自变量对因变量的影响。</p>
<h3 id="线性回归中的异常检测"><a href="#线性回归中的异常检测" class="headerlink" title="线性回归中的异常检测"></a>线性回归中的异常检测</h3><p>在线性回归中的异常值主要指的是在特定模型的基础上偏离预测值的值，而非考虑样本特征（自变量）之间的关系。<strong>在线性方法中，异常检测的目标是找到低维子空间，其中离群点的行为与其他数据点非常不同。</strong>由于异常点会对模型性能产生影响，因此异常检测是为了用于数据降噪，防止异常点对模型产生影响。</p>
<h3 id="有哪些线性回归的方法？"><a href="#有哪些线性回归的方法？" class="headerlink" title="有哪些线性回归的方法？"></a>有哪些线性回归的方法？</h3><h4 id="基于自变量与因变量的线性回归"><a href="#基于自变量与因变量的线性回归" class="headerlink" title="基于自变量与因变量的线性回归"></a>基于自变量与因变量的线性回归</h4><h5 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h5><p>以一个多元线性回归为例，最小二乘法的原理如下：</p>
<p>$X_{1}…X_{d}$为一系列因变量，也就是输入值，变量$Y$为因变量，也就是我们要预测的值，线性回归的方法可以将$Y$表示为：</p>
<p>$$<br>Y=\sum_{i=1}^{d} a_{i} \cdot X_{i}+a_{d+1} \tag{1}<br>$$</p>
<p>其中系数$a_{1}…a_{d+1}$是可以被学习到的参数。假设数据共包含$N$个样本，第$j$个样本包含的数据为$x_{j1}…x_{jd}$和$y_{j}$，带入式如下式所示：</p>
<p>$$<br>y_{j}=\sum_{i=1}^{d} a_{i} \cdot x_{j i}+a_{d+1}+\epsilon_{j} \tag{2}<br>$$<br>这里$\epsilon_{j}$为第$j$个样本的误差。以$Y$ 代表 $N \times 1$ 的因变量矩阵${(y_{1}…y_{N})}^{T}$，即样本中的真实值；以$U$代表$N \times (d+1)$的自变量矩阵，其中第$j$行为$(x_{j1}…x_{jd}, 1)$；以$A$ 代表 $(d+1) \times 1$ 的系数矩阵$(a_{1}…a_{d+1})^{T}$。则模型可表示为：<br>$$<br>f(U, A) = U \cdot A \tag{3}<br>$$</p>
<p>对A求导，可得：<br>$$<br>\frac{\partial L(A)}{\partial A} = \frac{1}{2}\times\frac{\partial{|Y - U \cdot A|}^2}{\partial A}= - {U^T}(Y - U \cdot A) \tag{4}<br>$$<br>令$\frac{\partial L(A)}{\partial A}=0$，得到最优参数为：</p>
<p>定义目标函数为：<br>$$<br>L(A) = \frac{1}{2}{\left| {Y - U \cdot A} \right|^2} \tag{5}<br>$$<br>目标函数是关于$A$的凸函数，其对$A$求偏导为：</p>
<p>$$<br>A=\left(U^{T} \cdot U\right)^{-1} \cdot\left(U^{T} \cdot Y\right) \tag{6}<br>$$</p>
<h5 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h5><p>优化目标是最小化损失函数，深度学习是利用随机梯度下降有限次地迭代模型参数，尽可能降低损失函数的值，相当于求出了<strong>数值解</strong>。但线性回归和平方误差是能够直接求出误差的最小化，因此是求出了<strong>解析解</strong>。</p>
<h4 id="基于异常检测的线性回归"><a href="#基于异常检测的线性回归" class="headerlink" title="基于异常检测的线性回归"></a>基于异常检测的线性回归</h4><p>一组变量 $X_{1}… X_{d}$， 对应的回归平面如下：</p>
<p>$$<br>a_{1} \cdot X_{1}+\ldots+a_{d} \cdot X_{d}+a_{d+1}=0 \tag{7}<br>$$<br>为了后续计算的方便，对参数进行如下约束：<br>$$<br>\sum\limits_{i = 1}^d {a_i^2 = 1} \tag{8}<br>$$<br>以$L_{2}$范数作为目标函数：<br>$$<br>L = {\left| {U \cdot A} \right|_2} \tag{9}<br>$$<br>这种方式是以相似的方式对待所有的变量，通过最小化数据对平面的投影误差来确定最佳回归平面。</p>
<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><h3 id="什么是主成分分析？"><a href="#什么是主成分分析？" class="headerlink" title="什么是主成分分析？"></a>什么是主成分分析？</h3><p>主成分分析能够在上述的方法上通过找到一个比原始维数更低的维度表示的最优超平面，它相当于一种降维的操作。</p>
<h3 id="主成分分析的原理"><a href="#主成分分析的原理" class="headerlink" title="主成分分析的原理"></a>主成分分析的原理</h3><p>对于 $d$ 维，包含 $N$ 个样本的数据，用 $R_{i}$ 表示其中第 $i$ 行为：$[x_{i1}… x_{id}]$。由此可以得到 $d \times d$ 的协方差矩阵$Σ$ （标准的PCA应当计算相关系数矩阵，即对数据进行均值为0方差为1的标准化处理，而协方差矩阵只需要减去均值即可）:</p>
<p>$$<br>Σ = (R - \bar{R})^{T} \cdot (R - \bar{R}) \tag{10}<br>$$<br>协方差矩阵是对称并且半正定的，因此可以进行相似对角化：</p>
<p>$$<br>Σ = P \cdot D \cdot P^{T} \tag{11}<br>$$<br>对角化后，$D$是特征值组成的对角矩阵，$P$ 是标准正交矩阵，每一行为对应的特征向量；这些标准正交向量提供了数据应该投影的轴线方向。</p>
<p>获取特征值和特征向量后，可以将原始的数据转换到新的坐标系中。$Y_{1}…Y_{k}$ 表示新坐标系中的数据，这些数据可以通过原始向量 $R_{i}$ 与包含新轴系的标准正交特征向量矩阵 $P$ 的乘积来实现。<br>$$<br>{Y_i} = {R_i} \cdot P \tag{12}<br>$$<br>通常高维数据的很多特征值接近0，相当于他们对原始数据特征向量的贡献不高，可以被忽略，当然这些较小的特征值也可以被看成异常。具体与异常检测相关的性质如下所示。</p>
<h3 id="异常检测相关性质"><a href="#异常检测相关性质" class="headerlink" title="异常检测相关性质"></a>异常检测相关性质</h3><ol>
<li>最大的前k个特征值的特征向量定义的k维超平面是所有维度为k的超平面中数据点到它的均方距离尽可能小的平面。</li>
<li>如果将数据转换为与正交特征向量对应的轴系，则转换后的数据沿每个特征向量维的方差等于相应的特征值。在这种新表示中，转换后的数据的协方差为0。（？）</li>
<li>由于沿特征值小的特征向量的转换数据的方差很低（没有更好地保持在原空间上的关系），因此沿这些方向的变换数据与平均值的显着偏差可能表示离群值。</li>
</ol>
<h3 id="主成分分析中的异常检测"><a href="#主成分分析中的异常检测" class="headerlink" title="主成分分析中的异常检测"></a>主成分分析中的异常检测</h3><p>对于特征值较小（方差较小）的特征向量 $j$，第 $i$ 条记录的 $y_{ij}$ 与 $y_{kj}$ 的其他值的偏差较大，说明有离群行为。这是因为当$j$固定而$k$变化时，$y_{kj}$ 的值应当变化不大。因此，$y_{ij}$ 值是不常见的。</p>
<p>使用特征值来计算数据点沿每个主分量方向到质心的归一化距离。设$e_{j}$为第$j$个特征向量，$λ_j$为沿该方向的方差(特征值)。数据点$\bar{X}$相对于对数据质心$\bar{\mu}$的总体归一化异常得分可以由下式给出：</p>
<p>$$<br>S \operatorname{core}(\bar{X})=\sum_{j=1}^{d} \frac{|(\bar{X}-\bar{\mu}) \cdot \bar{e_j}|^{2}}{\lambda_j} \tag{13}<br>$$</p>
<blockquote>
<p>注意在使用PCA时，需要对数据进行归一化操作，进行均值为0方差为1的标准化处理。这隐含地导致在主成分分析中使用相关矩阵而不是协方差矩阵。</p>
</blockquote>
<h2 id="回归分析的优劣"><a href="#回归分析的优劣" class="headerlink" title="回归分析的优劣"></a>回归分析的优劣</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1.线性建模提供一种有效的工具来从底层数据中移除异常值或者进行异常检测。</p>
<p>2.主成分分析提供了去除异常值和进行异常检测最有效的方法，因为它对存在少数异常值的数据更有鲁棒性。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1.数据不相关，但在某些区域高度聚集时，这种方法可能不会有效。</p>
<p>2.数据中相关性本质上可能不是全局的，主成分分析发现的全局子空间对异常检测可能是次优的，可能需要将线性模型和临近模型进行结合。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/05/14/2021-05-14-anomaly-detection-2/">【异常检测2】基于统计学的异常检测方法</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-05-14
        </span><span class="post-visits"
             data-url="/2021/05/14/2021-05-14-anomaly-detection-2/"
             data-title="【异常检测2】基于统计学的异常检测方法">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p><a href="https://gitee.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0.md" target="_blank" rel="noopener">DataWhale组队学习活动</a></p>
</blockquote>
<p>基于统计学来进行异常检测的方法就是学习一个拟合数据集的生成模型，认为模型中低概率区域的对象就是识别出的异常点。</p>
<p>异常检测的方法可以分为参数方法和非参数方法。它们最大的区别是，参数方法的假定了先验的统计模型，然后运用概率密度公式来计算分布产生概率，非参数方法没有假定先验的统计模型，相当于是运用输入数据来确定模型，这里的参数不是模型训练的参数，而是指先验分布的参数。</p>
<h2 id="参数方法"><a href="#参数方法" class="headerlink" title="参数方法"></a>参数方法</h2><p>主要思路就是先确定一个分布，然后再通过输入数据学习分布的参数，低概率的点就被识别为异常点。如可以选择正态分布进行求解。</p>
<p>在异常点中分为一元异常点和多元异常点，区别是多元异常点会有多个特征。这时候在维度为1的数据中的分布需要被扩充到更高维度上，如果各个维度，也就是说数据的每一个特征都相互独立，那么就可以直接利用一元异常点的异常检测进行扩充，但是如果特征之间有相关关系且符合多元高斯分布，那么就可以求相应参数。如果实际数据复杂，还可以采用混合的参数分布。</p>
<h2 id="非参数方法"><a href="#非参数方法" class="headerlink" title="非参数方法"></a>非参数方法</h2><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>利用数据构造直方图，异常点如果在直方图中就是正常的，否则是异常的。模型容易受到超参数影响如直方图箱数或箱尺寸。当箱尺寸太小，可能正常对象会被误识别为异常点，当箱尺寸太大，异常节点可能会被判定为正确的，造成错误。</p>
<h3 id="角度"><a href="#角度" class="headerlink" title="角度"></a>角度</h3><p>基于角度的异常节点检测主要的思想在于如果某一个数据点距离其余点越远，那么潜在角度可能越小，该点越有可能是异常点。使用加权的余弦可计算出异常的分数。</p>
<h3 id="HBOS"><a href="#HBOS" class="headerlink" title="HBOS"></a>HBOS</h3><p>该方法全称Histogram-based Outlier Score，是将单变量方法组合，适用于互相独立的特征，然后对每个维度进行区间划分，<strong>区间密度越高，异常评分越低。</strong>计算方法是对每个维度做出数据直方图（静态宽度直方图、动态宽度直方图），用箱子高度表示密度估计，归一化处理计算出HBOS值。</p>
<p>$ H B O S(p)=\sum_{i=0}^{d} \log \left(\frac{1}{\text {hist}_{i}(p)}\right) $$</p>
<p>这一方法的缺点是不能检测局部异常值。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/05/11/2021-05-11-anomaly-detection-1/">【异常检测1】基本概念</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-05-11
        </span><span class="post-visits"
             data-url="/2021/05/11/2021-05-11-anomaly-detection-1/"
             data-title="【异常检测1】基本概念">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p><a href="https://gitee.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0.md" target="_blank" rel="noopener">DataWhale组队学习活动</a></p>
</blockquote>
<h2 id="什么是异常检测"><a href="#什么是异常检测" class="headerlink" title="什么是异常检测?"></a>什么是异常检测?</h2><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><p>在统计学中，离群值（Outliers）是与其他观测值显著不同的数据点，也成为异常点。异常点的出现可能是因为观测的可变性或实验的错误。异常是指在大量的数据中较为稀少的数据点、事件或者行为。异常通常与正常数据不同，通常代表着数据中出现的一些问题，如欺诈行为、网络、文字的错误等。异常也被成为噪音、偏差和异常。异常可以被分为三类：点异常、条件异常和群体异常。</p>
<h3 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h3><p>异常检测是在数据集中找到非正常的数据、条件或群体。找到异常节点面临着一些挑战，如用于异常检测的数据集有样本类别不均衡的问题，还有异常节点是不规则的，不同的异常可能表现上完全不同。</p>
<h2 id="异常检测的方法有哪些？"><a href="#异常检测的方法有哪些？" class="headerlink" title="异常检测的方法有哪些？"></a>异常检测的方法有哪些？</h2><h3 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h3><p>有监督学习方法适用于有标签的数据集，也就是说在训练过程中会知道数据是否是异常的，这就相当于一个分类问题。可以用很多基础的机器学习分类算法进行检测，如SVM，决策树、GBDT、XGBoost等进行分类。但值得注意的是，包含异常的数据集是不均衡的，因此可能会影响性能。可以考虑使用集成学习的方法，如feature bagging。</p>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>无监督学习方法适用于没有标签的训练集，可以对数据集进行聚类。用于聚类的方法可以运用在异常检测的场景中，如DBSCAN算法、KNN算法、LOF(local outlier factor)算法等。但无监督学习聚类的方法，有时候会面临维度灾难，可能相似性的度量在高维数据重失效。</p>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>半监督学习的异常检测指的是在训练集中只有正常的数据集，没有异常的实例参与训练。然后会构造出一个表示正常行为的模型，然后会测试该模型生成的实例的可能性。比较适用于数据的标签不足的时候。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/20/2021-04-20-hdf5-weights/">如何读取HDF5保存的权重</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-20
        </span><span class="post-visits"
             data-url="/2021/04/20/2021-04-20-hdf5-weights/"
             data-title="如何读取HDF5保存的权重">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p><a href="https://keras.io/api/layers/base_layer/#set_weights-method" target="_blank" rel="noopener">https://keras.io/api/layers/base_layer/#set_weights-method</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">f = h5py.File(<span class="string">"encoder_weights_0.hdf5"</span>, <span class="string">"r"</span>)</span><br><span class="line">print(f.filename, <span class="string">":"</span>)</span><br><span class="line">print(f[<span class="string">'dense_1'</span>])</span><br><span class="line">print([key <span class="keyword">for</span> key <span class="keyword">in</span> f.keys()], <span class="string">"\n"</span>)</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> f.keys():</span><br><span class="line">    print(key,f[key])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> f[key].keys():</span><br><span class="line">        print(k,f[key][k])</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> f[key][k].keys():</span><br><span class="line">            print(l, f[key][k][l])</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;HDF5 group "/dense_1" (1 members)&gt;</span><br><span class="line">['dense_1', 'dense_2', 'dense_3', 'input_1']</span><br><span class="line"></span><br><span class="line">dense_1 &lt;HDF5 group "/dense_1" (1 members)&gt;</span><br><span class="line">dense_1 &lt;HDF5 group "/dense_1/dense_1" (2 members)&gt;</span><br><span class="line">bias:0 &lt;HDF5 dataset "bias:0": shape (64,), type "&lt;f4"&gt;</span><br><span class="line">kernel:0 &lt;HDF5 dataset "kernel:0": shape (100, 64), type "&lt;f4"&gt;</span><br><span class="line">dense_2 &lt;HDF5 group "/dense_2" (1 members)&gt;</span><br><span class="line">dense_2 &lt;HDF5 group "/dense_2/dense_2" (2 members)&gt;</span><br><span class="line">bias:0 &lt;HDF5 dataset "bias:0": shape (16,), type "&lt;f4"&gt;</span><br><span class="line">kernel:0 &lt;HDF5 dataset "kernel:0": shape (64, 16), type "&lt;f4"&gt;</span><br><span class="line">dense_3 &lt;HDF5 group "/dense_3" (1 members)&gt;</span><br><span class="line">dense_3 &lt;HDF5 group "/dense_3/dense_3" (2 members)&gt;</span><br><span class="line">bias:0 &lt;HDF5 dataset "bias:0": shape (8,), type "&lt;f4"&gt;</span><br><span class="line">kernel:0 &lt;HDF5 dataset "kernel:0": shape (16, 8), type "&lt;f4"&gt;</span><br><span class="line">input_1 &lt;HDF5 group "/input_1" (0 members)&gt;</span><br></pre></td></tr></table></figure>

<p>a Dense layer returns a list of two values– per-output weights and the bias value.<br>在</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/14/2021-04-14-boosting/">Boosting提升</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-14
        </span><span class="post-visits"
             data-url="/2021/04/14/2021-04-14-boosting/"
             data-title="Boosting提升">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="什么是Boosting"><a href="#什么是Boosting" class="headerlink" title="什么是Boosting"></a>什么是Boosting</h2><p>TODO</p>
<h2 id="Boosting的两种方法"><a href="#Boosting的两种方法" class="headerlink" title="Boosting的两种方法"></a>Boosting的两种方法</h2><h3 id="AdaBoost算法"><a href="#AdaBoost算法" class="headerlink" title="AdaBoost算法"></a>AdaBoost算法</h3><h3 id="Gradient-Boost"><a href="#Gradient-Boost" class="headerlink" title="Gradient Boost"></a>Gradient Boost</h3><h2 id="Gradient-Boost-Decision-Tree-GBDT"><a href="#Gradient-Boost-Decision-Tree-GBDT" class="headerlink" title="Gradient Boost Decision Tree(GBDT)"></a>Gradient Boost Decision Tree(GBDT)</h2><p>在每个树节点中找到最佳分割点非常耗时，而且会消耗内存</p>
<h2 id="Boosting框架"><a href="#Boosting框架" class="headerlink" title="Boosting框架"></a>Boosting框架</h2><h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><ul>
<li><p>基于histogram</p>
</li>
<li><p>leaf-wise</p>
</li>
</ul>
<p><img src="/2021/04/14/2021-04-14-boosting/image-20210414095754315.png" alt="image-20210414095754315"></p>
<p><img src="/2021/04/14/2021-04-14-boosting/image-20210414095812474.png" alt="image-20210414095812474"></p>
<p><img src="/2021/04/14/2021-04-14-boosting/image-20210414095908847.png" alt="image-20210414095908847"></p>
<p>直方图优化：基于分桶，减少内存的使用，正则化不容易overfit</p>
<p>控制max_depth来控制num_leaves</p>
<p>num_leaves=2^max_depth</p>
<p>lightGBM控制num_leaves，而不是树的最大深度，因为lightGBM不会生成满二叉树，因此通过控制num_leaves确保树的深度不过大，防止过拟合。</p>
<h4 id="防止过拟合的方法"><a href="#防止过拟合的方法" class="headerlink" title="防止过拟合的方法"></a>防止过拟合的方法</h4><p><img src="/2021/04/14/2021-04-14-boosting/image-20210414101304982.png" alt="image-20210414101304982"></p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><h5 id="num-leaves"><a href="#num-leaves" class="headerlink" title="num_leaves"></a>num_leaves</h5><p>num_leaves越大，增加了训练集的精确度，但增加了过拟合的几率</p>
<h5 id="num-iterations"><a href="#num-iterations" class="headerlink" title="num_iterations"></a>num_iterations</h5><h2 id="Bagging-和-Boosting的区别"><a href="#Bagging-和-Boosting的区别" class="headerlink" title="Bagging 和 Boosting的区别"></a>Bagging 和 Boosting的区别</h2><p>Bagging：</p>
<ul>
<li>训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的</li>
<li>使用均匀取样，每个样例的权重相等</li>
<li>所有预测函数的权重相等</li>
<li>各个预测函数可以并行生成</li>
</ul>
<p>Boosting：</p>
<ul>
<li>每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化，权值是根据上一轮的分类结果进行调整</li>
<li>根据错误率不断调整样例的权值，错误率越大则权重越大</li>
<li>每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重</li>
<li>各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果</li>
</ul>
<hr>
<p>参考资料：</p>
<p>1.微软亚洲研究院AI头条分享-<a href="https%3A//v.qq.com/x/page/k0362z6lqix.html">Introduction to LightGBM</a>-Taifeng Wang</p>
<p>2.<a href="https://easyaitech.medium.com/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3-bagging-boosting-%E4%BB%A5%E5%8F%8A%E4%BB%96%E4%BB%AC%E7%9A%84-4-%E7%82%B9%E5%8C%BA%E5%88%AB-6e3c72df05b8#:~:text=%E8%80%8C%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A0%B8%E5%BF%83,%E4%BD%9C%E2%80%9C%E5%A5%97%E8%A2%8B%E6%B3%95%E2%80%9D%EF%BC%89" target="_blank" rel="noopener">一文看懂集成学习（详解 bagging、boosting 以及他们的 4 点区别）</a></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/13/2021-04-13-Tensorboard/">TensorBoard相关知识</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-13
        </span><span class="post-visits"
             data-url="/2021/04/13/2021-04-13-Tensorboard/"
             data-title="TensorBoard相关知识">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h3 id="TensorBoard查看结果"><a href="#TensorBoard查看结果" class="headerlink" title="TensorBoard查看结果"></a>TensorBoard查看结果</h3><p><code>tensorboard –logdir /path/to/logs</code></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/09/2021-04-09-GNN-classification/">图神经网络里的监督/半监督和转导/归纳概念解析</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-09
        </span><span class="post-visits"
             data-url="/2021/04/09/2021-04-09-GNN-classification/"
             data-title="图神经网络里的监督/半监督和转导/归纳概念解析">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>监督(supervised)和半监督(semi-supervised)其实是转导（transductive)和归纳(inductive)</p>
<p>对于节点分类来说，如何区分监督学习和半监督学习的关键在于节点在训练过程中被使用的区别，也就是训练集节点是否被用在GNN的消息传递操作中，并且会被用于计算损失。</p>
<p>transductive的测试节点是无标签的，并且不会被使用在损失计算中，但是这些点和相关的边会被用于消息传递中，也就是说图神经网络会生成测试集节点的潜在表示中，但是最后一层的表示不会被用在损失函数的计算中。</p>
<p>indutive的测试节点既不会用在GNN的消息传递过程中，也不会用在损失函数计算中，也就是说，inductive在GNN训练的过程中完全不会被包括。</p>
<p>半监督指的就是GNN会使用transductive的测试节点组成的测试集，也就是说在训练的过程中实际上是能够看到测试的节点的（但不能看到label）。监督指的就是在做归纳式的节点分类时，测试的节点是完全不会被检测到的。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/08/2021-04-08-keras/">Keras的一些基本操作</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-08
        </span><span class="post-visits"
             data-url="/2021/04/08/2021-04-08-keras/"
             data-title="Keras的一些基本操作">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="生成模型的关键步骤"><a href="#生成模型的关键步骤" class="headerlink" title="生成模型的关键步骤"></a>生成模型的关键步骤</h2><h3 id="model-add"><a href="#model-add" class="headerlink" title="model.add()"></a><code>model.add()</code></h3><h3 id="model-summary"><a href="#model-summary" class="headerlink" title="model.summary()"></a><code>model.summary()</code></h3><p><code>model.summary() #打印神经网络结构，统计参数数目</code></p>
<h3 id="model-compile"><a href="#model-compile" class="headerlink" title="model.compile()"></a><code>model.compile()</code></h3><p>在配置训练方法时，告知训练时用的优化器、损失函数和准确率评测标准</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer = 优化器</span><br><span class="line">              loss = 损失函数，</span><br><span class="line">              metrics = [<span class="string">"准确率"</span>])</span><br></pre></td></tr></table></figure>

<h3 id="model-fit"><a href="#model-fit" class="headerlink" title="model.fit()"></a><code>model.fit()</code></h3><p>The history object returned by model.fit() is a simple class with some fields, e.g. a reference to the model, a params dict and, most importantly, a history dict. It stores the values of loss and acc (or any other used metric) at the end of each epoch.</p>
<h2 id="模型的保存"><a href="#模型的保存" class="headerlink" title="模型的保存"></a>模型的保存</h2><h3 id="保存模型参数：model-to-json"><a href="#保存模型参数：model-to-json" class="headerlink" title="保存模型参数：model.to_json()"></a>保存模型参数：<code>model.to_json()</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(model_json)</span><br></pre></td></tr></table></figure>

<h3 id="保存-weights-model-save-weights"><a href="#保存-weights-model-save-weights" class="headerlink" title="保存 weights:model.save_weights()"></a>保存 weights:<code>model.save_weights()</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save_weights(<span class="string">"model.h5"</span>)</span><br></pre></td></tr></table></figure>

<p>.h5 文件</p>
<h3 id="保存某一层的输出：model-layers-index-output"><a href="#保存某一层的输出：model-layers-index-output" class="headerlink" title="保存某一层的输出：model.layers[index].output"></a>保存某一层的输出：<code>model.layers[index].output</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inp = model.input</span><br><span class="line">outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers]</span><br></pre></td></tr></table></figure>

<p>outputs 里的元素的类型是：<br><code>&lt;class &#39;tensorflow.python.framework.ops.Tensor&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># serialize model to JSON</span></span><br><span class="line">model_json = model.to_json()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(model_json)</span><br><span class="line"><span class="comment"># serialize weights to HDF5</span></span><br><span class="line">model.save_weights(<span class="string">"model.h5"</span>)</span><br><span class="line">print(<span class="string">"Saved model to disk"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># later...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load json and create model</span></span><br><span class="line">json_file = open(<span class="string">'model.json'</span>, <span class="string">'r'</span>)</span><br><span class="line">loaded_model_json = json_file.read()</span><br><span class="line">json_file.close()</span><br><span class="line">loaded_model = model_from_json(loaded_model_json)</span><br><span class="line"><span class="comment"># load weights into new model</span></span><br><span class="line">loaded_model.load_weights(<span class="string">"model.h5"</span>)</span><br><span class="line">print(<span class="string">"Loaded model from disk"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate loaded model on test data</span></span><br><span class="line">loaded_model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'rmsprop'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">score = loaded_model.evaluate(X, Y, verbose=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">"%s: %.2f%%"</span> % (loaded_model.metrics_names[<span class="number">1</span>], score[<span class="number">1</span>]*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">weights_0_list = new_model.layers[<span class="number">0</span>].get_weights()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(weights_0_list)):</span><br><span class="line">    print(weights_0_list[i].shape)</span><br></pre></td></tr></table></figure>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2021/04/07/2021-04-07-keras-LSTM/">Keras中RNNLayer的输入输出总结</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2021-04-07
        </span><span class="post-visits"
             data-url="/2021/04/07/2021-04-07-keras-LSTM/"
             data-title="Keras中RNNLayer的输入输出总结">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>网上关于 Keras 的 RNNLayer 中的输入写的很不清楚，整理如下：</p>
<h2 id="LSTM-的输入"><a href="#LSTM-的输入" class="headerlink" title="LSTM 的输入"></a>LSTM 的输入</h2><h3 id="tf-keras-layers-LSTM-参数"><a href="#tf-keras-layers-LSTM-参数" class="headerlink" title="tf.keras.layers.LSTM()参数"></a><code>tf.keras.layers.LSTM()</code>参数</h3><p><a href="https://keras.io/api/layers/recurrent_layers/lstm/" target="_blank" rel="noopener">文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.LSTM(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'sigmoid'</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>, recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>, kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>,</span><br><span class="line">    return_sequences=<span class="literal">False</span>, return_state=<span class="literal">False</span>, go_backwards=<span class="literal">False</span>, stateful=<span class="literal">False</span>,</span><br><span class="line">    time_major=<span class="literal">False</span>, unroll=<span class="literal">False</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="input-dim、input-length、input-shape-的关系"><a href="#input-dim、input-length、input-shape-的关系" class="headerlink" title="input_dim、input_length、input_shape 的关系"></a>input_dim、input_length、input_shape 的关系</h3><p>LSTM 的输入是一个三维的张量（numpy narray), 三维张量的 shape 是[samples, time steps, features]，也就是[样本数量，时间步长（序列数量），特征长度]。LSTM layer 的参数需要确定其中的两个，在 model.fit 时，就能够对 trainX 进行训练。因此 input_dim 表示单个样本的特征长度，可以用 trainX.shape[2]赋值； input_length 表示的就是时间步长，序列长度，可以用 trainX.shape[1]进行赋值。</p>
<p>另外一种写法是 input_shape，其实就是这两个量的结合：input_shape = (input_length, input_dim)</p>
<p>因此以下的两种写法是等价的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(LSTM(units=<span class="number">256</span>, return_sequences=<span class="literal">True</span>,</span><br><span class="line">            input_dim=trainX.shape[<span class="number">2</span>], input_length=trainX.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(LSTM(units=<span class="number">256</span>, return_sequences=<span class="literal">True</span>,</span><br><span class="line">            input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))</span><br></pre></td></tr></table></figure>

<p>但比较奇怪的是这样设置最终的结果第一维会是 None,最终输出的是<code>[None,timesteps, feature]</code>。如果设置<code>input_size=trainX.size</code>的话，会出现以下错误：<br><code>ValueError: Input 0 of layer lstm is incompatible with the layer: expected ndim=3, found ndim=4.</code><br>但是如果使用 batch_input_shape=trainX.shape就可以正常运行，并且最终得到训练的每一个样本的 <code>[timesteps,feature]</code>张量。</p>
<p>后来查了keras LSTM的官方文档，它对input的定义是<code>[batch, timesteps, feature]</code>，也就是说第一个参数指的是 batch 的大小，如果没有就默认为 None。在<code>model.fit</code>里有一个batch_size，如果设置了该batch_size的值，那么LSTM的层的input会自动根据trainX.shape[0]和batch_size的值来确定每一个输入的batch的大小。</p>
<p>batch size 限制了在可以执行权重更新之前向网络显示的样本数。拟合模型时使用的 batch size 控制一次必须进行多少预测。</p>
<h2 id="GRU-的输入"><a href="#GRU-的输入" class="headerlink" title="GRU 的输入"></a>GRU 的输入</h2><h3 id="tf-keras-layers-GRU-参数"><a href="#tf-keras-layers-GRU-参数" class="headerlink" title="tf.keras.layers.GRU()参数"></a><code>tf.keras.layers.GRU()</code>参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.GRU(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'sigmoid'</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, return_sequences=<span class="literal">False</span>, return_state=<span class="literal">False</span>,</span><br><span class="line">    go_backwards=<span class="literal">False</span>, stateful=<span class="literal">False</span>, unroll=<span class="literal">False</span>, time_major=<span class="literal">False</span>,</span><br><span class="line">    reset_after=<span class="literal">True</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/">gitbook+Typora打造舒适的笔记环境</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-06-22
        </span><span class="post-visits"
             data-url="/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/"
             data-title="gitbook+Typora打造舒适的笔记环境">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>GitBook 是一个基于 Node.js 的命令行工具，可使用它来制作精美的电子书。gitbook简洁而且高效，能够用一种结构化的方式组织文章或者笔记，所以不管是学习的输入还是撰写文章的输出，gitbook都不失为一个很好的工具。</p>
<p>网上关于如何安装gitbook的文章有很多，此处不进行总结了。</p>
          <div class="read-more">
            <a href="/2020/06/22/gitbook-Typora%E6%89%93%E9%80%A0%E8%88%92%E9%80%82%E7%9A%84%E7%AC%94%E8%AE%B0%E7%8E%AF%E5%A2%83/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/">文本数据的聚类分析综述</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-06-10
        </span><span class="post-visits"
             data-url="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/"
             data-title="文本数据的聚类分析综述">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>聚类分析是一种无监督学习方法，在模式识别中，对于给定的数据样本，类别标号已知的情况下，分类问题通过训练，使得能够对未知类别的样本进行分类。而现实世界中，相当多的数据是没有已知类别的，它们的类别缺失或者需要大量的人工标注才能获取类别。为了发现数据的内在知识、检测并分析异常点和从数据中提取模式，聚类分析是非常重要的。</p>
<p>聚类分析依据相似性，将给定数据样本划分成若干个类别，相似性越高的两个物体划分为同一类，最终会将数据形成若干个簇，簇与簇可根据它们的形状、大小和密度等有所区别。</p>
<p>生活中的多个方面聚类都能够辅助模式识别和数据挖掘。在产品市场上，聚类可以基于用户的购买对商品进行聚类，使得市场营销人员能够利用这些知识开发有针对性地计划；在城市规划上，聚类可以将相似性高的区域进行划分，为土地建设提供选址方案等。</p>
<p>随着全球信息化的不断发展，大量文本数据隐含着潜在的信息和知识。文本数据是一种非常常见的非结构化数据，针对文本数据的聚类应用领域也很广泛。在信息检索方向，文本聚类可对搜索引擎进行聚类，提升用户获取信息的精确度；在信息推荐方向，聚类还可以提取出热点主题或发现事件、自动归档文本并帮助完善文本可视化。</p>
<p>实现文本聚类主要由三个步骤组成：1.文档的表示（提取文档特征并对特征降维处理）；2.文本聚类算法的选择和应用；3.评估文本聚类算法的有效性。三个步骤将在接下来的4章中进行详细的探讨。</p>
<h1 id="二、文本数据的特征提取"><a href="#二、文本数据的特征提取" class="headerlink" title="二、文本数据的特征提取"></a>二、文本数据的特征提取</h1><p>计算机难以直接对字符串文本进行处理，需要将实际的文字转化成数值型数据。对文本本身来说，它具有一些显式的特征，如字数、词频、停止词数量、单词平均长度等。为了实现文本的聚类，上述的特征需要进行处理和调整，按照某种完整的模型对文档进行数值化或向量化。</p>
<p>当前的主要的文档模型可被分为五个类别：布尔模型、向量空间模型、概率模型、统计语言模型和分布表示模型。</p>
<h2 id="（一）布尔模型"><a href="#（一）布尔模型" class="headerlink" title="（一）布尔模型"></a>（一）布尔模型</h2><p>布尔模型具有简洁的形式，容易理解。它的基础是集合论和布尔代数。我们考虑单词在文档中出现或缺失时，一个文档能够用二进制向量表示。</p>
<h2 id="（二）向量空间模型"><a href="#（二）向量空间模型" class="headerlink" title="（二）向量空间模型"></a>（二）向量空间模型</h2><p>向量空间模型是将文档表达为向量空间的一个矢量或点，向量空间的维数是词的数量。在向量空间的文档向量的长度是由出现的词和词的权重共同决定的[1]。在向量空间中，单词的顺序并不被考虑，这种方法也称为词袋表示方法（Bag of Words）。它是一种简单、经典的表示方法，但它对出现在文本中的词无法判定其重要性的差异，导致准确率不高。</p>
<p>1983年，Salton等提出了扩展布尔模型[2]，它结合了布尔模型和向量空间模型，并表现出检索性能的提升。</p>
<p>1986年，TF-IDF被提出[3]，这种表示改进了词袋表示法，每个单词的词频都由逆文档频率（IDF）规范化。在单词集合中，出现频率更高的项权重更低，降低了常用词在文档中的重要性，保证后续文档聚类的结果更受文档出现频率低的词的影响。</p>
<h2 id="（三）概率模型"><a href="#（三）概率模型" class="headerlink" title="（三）概率模型"></a>（三）概率模型</h2><p>概率模型中，文档<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002.png" alt="img">)与查询<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004.png" alt="img">)的相似度有如下关系：<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)表示相关文档集，<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image008.png" alt="img">)表示<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">的补集。</p>
<p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001825039.png" alt="image-20200615001825039"></p>
<p>对文档而言，根据独立性假设，文档的各个词相互独立，用<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image012.png" alt="img">表示词可得到：</p>
<p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001859217.png" alt="image-20200615001859217"></p>
<p>其中词权重<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image016.png" alt="img">。</p>
<p>用<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018.png" alt="img">)表示相关文档数，<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image020.png" alt="img">)表示包含索引词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的文档数，相关文档中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image024.png" alt="img">, 不相关文档中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">)的分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001927832.png" alt="image-20200615001927832">),<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image028.png" alt="img">)表示包含索引词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image022.png" alt="img">的文档数。</p>
<p>则可推出：</p>
<p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615001955999.png" alt="image-20200615001955999"></p>
<p>概率模型的优点在于，文档可以按照相关概率递减顺序来计算秩；但概率模型需要把文档分为相关和不相关的两个集合，未考虑到单词的频率，没有权重系数[4]。 </p>
<h2 id="（四）-统计语言模型"><a href="#（四）-统计语言模型" class="headerlink" title="（四） 统计语言模型"></a>（四） 统计语言模型</h2><p>统计语言模型(Statistics Language Models)是基于统计学和概率论对语言进行建模的，主要思想是语言是字母表上的概率分布，该分布表示一种可能性：即任何一个字母序列成为该语言的一个句子。这一分布就是语言的统计语言模型。目前较流行的统计语言模型是n元模型（N-gram），表示一个词的出现与否和其前面的n-1个词有关。</p>
<p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591777871572.png" alt="img"></p>
<h2 id="（五）分布表示模型"><a href="#（五）分布表示模型" class="headerlink" title="（五）分布表示模型"></a>（五）分布表示模型</h2><p>分布式表示模型不仅考虑将单词符号化，还考虑将语义信息融入到词表示中。 1954 年，Harris提出了分布假说（ distributional hypothesis）上下文相似的词，其语义也相似[5]，这一假说为语义信息的融入提供了理论基础。</p>
<p>分布式表示根据任务、算法的区别，可被分为基于矩阵的分布表示、基于聚类的分布表示和基于神经网络的分布表示。在基于聚类的分布表示中，较典型的算法为布朗聚类方法(Brown clustering)，在第四章会具体介绍该算法。</p>
<h1 id="三、样本的相似性度量"><a href="#三、样本的相似性度量" class="headerlink" title="三、样本的相似性度量"></a>三、样本的相似性度量</h1><p>文本聚类根据不同的粒度可以分为文档、段落、语句或者单词的聚类。样本在不同的粒度下代表的事物也有所区别，如文档聚类时，每一个样本表示一个文档。对文档进行聚类时，我们需要获知文档样本与样本之间的相似度，需要相似性的度量标准。</p>
<p>相似性度量可使用空间两点的欧式距离、向量内积、余弦相似度、Jaccard相似度等。</p>
<p>相似度的度量会在一定程度上影响算法的效果，目前也有大量的研究针对聚类的相似性度量，如2009年，Luo[6]等人应用了邻居和链接的概念，将全局信息引入到两个文档的相似性度量上，提出了新的相似性度量方式：使用余弦和链接函数组合等，总而言之，相似性度量并不存在最优的方法，需要和聚类算法结合。</p>
<h1 id="四、文本聚类方法"><a href="#四、文本聚类方法" class="headerlink" title="四、文本聚类方法"></a>四、文本聚类方法</h1><p>传统的聚类分析算法不仅可以用在文本数据上，其他数据也是通用的。针对文本表示的不同形式，使用的聚类算法也有所区别，文本聚类主要可以分为三类方法：划分聚类方法、层次聚类方法和基于标准参数化模型的方法。</p>
<h2 id="（一）划分聚类方法"><a href="#（一）划分聚类方法" class="headerlink" title="（一）划分聚类方法"></a>（一）划分聚类方法</h2><p>划分方法符合我们对聚类的直观感受，将多个样本点组织成多个簇，通常簇的个数会在聚类前被给定，融合了相关领域的主观知识。</p>
<p>划分方法最初指定类别的初始数目，并不断迭代分配样本点，最终收敛时确定所有簇。划分方法运用在文本领域的主要有K-means和K-medoids两种聚类算法。</p>
<h3 id="1-K-means聚类算法"><a href="#1-K-means聚类算法" class="headerlink" title="1. K-means聚类算法"></a>1. K-means聚类算法</h3><p>K-means算法最早是从不同的科学领域中提出来的，包括1956年的Steinhaus[7], 和1957年的Lloyd[8]，至今已经提出了近60年，但它仍然是目前应用于聚类的算法之一。</p>
<p>K-means通过判断根据平方误差法计算出的目标函数是否达到最优解，而逐步对聚类结果进行优化。在运行前需要指定簇的类别、初始的簇的中心点，在每次迭代中，将每个点分配给中心最近的聚类。中心是群中所有点的平均值，平均点的坐标是簇中所有点上每个维度的算术平均值。</p>
<p>原始的K-means的缺点主要有以下几点：首先，它只考虑了样本点之间的距离，通常结果均为球状簇。若从样本点的密度考虑，以DBSCAN算法为代表的基于密度的方法能够发现任意形状的簇。其次，K值、初始化分方向等均是需要用户给定的，容易陷入局部最优。</p>
<h3 id="2-K-medoids聚类算法"><a href="#2-K-medoids聚类算法" class="headerlink" title="2.K-medoids聚类算法"></a>2.K-medoids聚类算法</h3><p>K-medoids聚类算法使用类中的某个点来代表簇，最早提出的K-mediods算法之一PAM(Partitioning Around Medoids) [9]的基本思想就是最初选取k个代表对象作为初始的中心点，依据当前cluster中所有其他点到该中心点的距离之和最小的准则函数，不断迭代找到更好的中心点。</p>
<p>该算法在一定程度上削弱了异常值的影响，但缺点是计算较为复杂，耗费的计算机时间比K-means多。它能处理任意类型的属性，但对异常数据不敏感。</p>
<h2 id="（二）-层次聚类方法"><a href="#（二）-层次聚类方法" class="headerlink" title="（二） 层次聚类方法"></a>（二） 层次聚类方法</h2><p>按照层次的聚类方法源于对数据需要组成层次结构的需求，数据需要进行层次结构上的汇总和特征化，因此层次划分方法被引入。层次划分方法可分为凝聚和分裂两种策略。</p>
<p>凝聚策略是将每个样本点在聚类最初都形成一个簇，随着迭代的进行，会将所有簇合并，直到终止条件为止。分类策略与凝聚策略正好相反，它将所有的样本点都看成同一个簇，相当于层次结构的根，将簇不断划分为更小的簇，直到划分的每一个簇都达到凝聚的条件。</p>
<p>以文档聚类为例，凝聚层次聚类方法可以被分为三类[10]：单连接算法（Single Linkage Clustering）、平均连接算法（Group-Average Linkage Clustering）、全连接算法（Complete Linkage Clustering）。</p>
<p>单连接算法的基本思想是两个簇的距离度量是从两个簇中抽取的每一对样本的最小距离<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591777984132.png" alt="img">,一旦最近的两个簇的距离超过某个任意给定的阈值，则算法结束。平均连接的基本算法是两个簇的距离度量是所有样本对的距离的平均值，全连接算法的距离度量则是两个簇所有样本对的最坏情况。</p>
<p>在针对文本数据的聚类中流行的层次聚类算法包括：综合的层次聚类方法BIRCH[11]，其优点在于能够通过单词扫描获取一个较好的聚类效果，但它只适用于数值型数据；基于质心和代表对象方法的CURE聚类方法[12]从每个类中抽取固定数量、分布较好的点作为代表点，并乘收缩收缩因子，减小噪音对聚类的影响；适用于分类属性层次的聚类算法ROCK[13],和使用动态模型的层次聚类算法Chameleon[14]。</p>
<p>1992年提出的布朗聚类方法[15]是一种针对词汇聚类的算法，它借鉴了层次聚类的凝聚策略，它的输入时一个语料库，语料库是一个词序列，输出是一个二叉树，二叉树的叶子节点是词，中间节点是对应的类别。它的评价函数是对于<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004-1591777984132.png" alt="img">)个连续的词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006-1591777984133.png" alt="img">)序列能否组成依据话的概率的对数的归一化结果，评价函数为:$Quality(C)=\frac{1}{n}logP(w_1,w_2…w_n)$。该函数描述了某个词上下文单词对当前聚类中单词的出现的预测程度。</p>
<p>Gil-García[16]等在2006年提出了一个基于图的凝聚层次聚类的通用框架，这一框架指定簇间相似度度量、β-相似度图的子图和覆盖例程，可以得到不同的层次的凝聚型的聚类算法；在2010年[17]，作者又提出了针对文档聚类的动态层次算法，该算法在获取和其他传统分层算法相似的聚类质量的前提下，层次结构更小、更利于浏览，可用于创建文档分类法和分层主题检测等模式识别问题。</p>
<p>层次聚类的鲁棒性较强，因为它通常需要比较所有的文档，因此复杂度达到<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image010-1591777984134.png" alt="img">。为了提升层次聚类方法的效率，多种改进方法被提出。如2018年，Zhang等人[18]提出了一个分区合并方案（PMHC）用于快速分层群集，它将数据对象分成适当的组并将它们合并到组中以节省计算成本。</p>
<h2 id="（三）基于标准参数化模型的方法"><a href="#（三）基于标准参数化模型的方法" class="headerlink" title="（三）基于标准参数化模型的方法"></a>（三）基于标准参数化模型的方法</h2><p>给定文档<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image012-1591777984134.png" alt="img">)，获取该文档属于不同簇的概率向量q，也是文档聚类的任务之一。考虑第二章中用统计语言模型表示文档的方式，可假定文档的生成过程是先以一定概率<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image014-1591777984134.png" alt="img">)选择簇<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image016-1591777984135.png" alt="img">),然后再按照词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018-1591777984135.png" alt="img">)的概率分布<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image020-1591777984135.png" alt="img">)选择词<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image018.png" alt="img">生成文档d,观测的所有文档在混合模型中被生成的概率为：</p>
<p>  <img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image024-1591777984136.png" alt="img"></p>
<p>其中<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image014-1591777984134.png" alt="img">为“聚簇参数”，可通过期望最大化算法学习。该方法会陷入局部最优导致收敛速度较慢。</p>
<p>基于EM算法进行聚类的研究主要是基于EM算法对聚类方法的改进和提升，如2005年，Rigutini[19]等人将EM算法与基于信息增益的特征选择技术相结合，该算法只需要少量文档初始化聚类，并且能够正确地提取隐藏在大量未标记集合中的规则。2011年，Kim[20]等人基于EM算法，提出了一种文本文档的主题聚类算法，使用EM方法确保文档被分配给正确的主题，从而收敛到局部最优解，其结果具有较好的性能和可解释性。</p>
<p>EM算法衍生出了主题建模，它是一种对文档进行聚类并提取主题的无监督学习方法，可用来识别大规模文档集或语料库中潜藏的主题信息，广泛应用在文本分类、文本聚类、摘要抽取、情感分析等领域。</p>
<p>主题建模起源于潜在语义分析（LSA）[21]，该方法通过奇异值分解，将高维文档向量近似地映射到一个低维潜在地语义空间上，以达到降低文档维数和消除词语存在的同义、多义等问题。在LSA基础上，Hofmann引入了概率统计的思想，提出了概率潜在语义分析模型[22]。然而pLSA模型的参数容易与特定的文档相关，有时会出现过拟合现象，因此，Blei等人在2003年提出了LDA概率主题模型[23]，把模型的参数也看作随机变量，引入控制参数的参数，实现进一步的概率化。LDA本质上是一种无监督无指导的机器学习模型，将高维文本单词空间表示为低维主题空间，忽略了和文本相关的类别信息。</p>
<h2 id="（四）其他聚类学习方法"><a href="#（四）其他聚类学习方法" class="headerlink" title="（四）其他聚类学习方法"></a>（四）其他聚类学习方法</h2><p>除了上述三点主要的聚类算法之外，针对文本数据的部分其他聚类算法将在本节进行简短的阐述。</p>
<p>模糊聚类需要根据研究对象本身的属性来构造模糊矩阵，并根据隶属度来构造模糊矩阵，最终确定聚类关系。它可允许一个文档属于不同的局促，使得聚类结果更稳定[24]。</p>
<p>半监督聚类是一种更新的研究算法，半监督聚类的核心思想是把半监督学习的思想结合到聚类中，通过少量的标签数据和先验知识提高聚类性能，得到性能更优的结果。在文本聚类中，使用半监督获取少量标签的聚类算法也有部分研究。</p>
<p>Zhang W 等提出了基于频繁项集和相似度计算的最大获取的文本聚类方法[25]。</p>
<h1 id="五、聚类结果的评价"><a href="#五、聚类结果的评价" class="headerlink" title="五、聚类结果的评价"></a>五、聚类结果的评价</h1><p>  聚类结果并没有没有适用于所有算法的统一的评价指标，聚类算法结果的好坏取决于聚类算法的使用的相似性度量和相应的聚类算法。首先好的聚类的簇需要满足两个特点：簇内高内聚，簇间低耦合。其次，好的聚类能够发现隐含的模式，簇的形状没有较大限制；最后从用户的角度来说，能够产生一个满足用户的聚类结果，结果具有可解释性、可理解性。</p>
<h2 id="（一）分类评价指标"><a href="#（一）分类评价指标" class="headerlink" title="（一）分类评价指标"></a>（一）分类评价指标</h2><p>  通常，聚类任务可以使用分类任务的数据集（包含分类标签），衡量聚类的质量可以使用分类任务的评价指标。</p>
<h3 id="1-召回率和准确率"><a href="#1-召回率和准确率" class="headerlink" title="1.召回率和准确率"></a>1.召回率和准确率</h3><p>对于信息检索的结果，其计算包括了两个指标：召回率（Recall Rate）和准确率（Precision Rate）。召回率表示检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率；准确率是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；F 值为两者的调和平均值。</p>
<h3 id="2-宏平均和微平均"><a href="#2-宏平均和微平均" class="headerlink" title="2.宏平均和微平均"></a>2.宏平均和微平均</h3><p>宏平均（Macro-averaging），是先对每一个类统计指标值，然后在对所有类求算术平均值。微平均（Micro-averaging**），是对数据集中的每个实例不分类别进行统计建立全局混淆矩阵，然后计算相应指标[26]。</p>
<h2 id="（二）交叉检验方法"><a href="#（二）交叉检验方法" class="headerlink" title="（二）交叉检验方法"></a>（二）交叉检验方法</h2><p>将用于聚类的数据集划分为m个部分，随机使用m-1个部分建立聚类模型，并用剩下的1个部分检验聚类的质量。这一部分可以计算与他们最近形心的距离平方和作为度量，重复m次后，总体质量度量由质量度量的平均值计算出来，对不同的k，可以比较总体质量度量，最终选取最佳拟合数据的簇数[27]。</p>
<h2 id="（三）聚类质量的测定"><a href="#（三）聚类质量的测定" class="headerlink" title="（三）聚类质量的测定"></a>（三）聚类质量的测定</h2><p>当有专家构建的基准时，可将聚类模型和基准进行比较，比较时聚类质量度量Q如满足以下4项基本标准：簇的同质性、簇的完全性、碎布袋、小簇保持性，那么可以使用Q进行比较和评估。</p>
<p>当基准不存在时，可以采用轮廓系数对距离进行内部评估。</p>
<p>假设数据集D有<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image002-1591778129766.png" alt="img">)个样本被分为<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image004-1591778129766.png" alt="img">)个类别，则对于任意一个样本<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006-1591778129767.png" alt="img">),计算<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)与<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)所在簇中其他对象的平均距离<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image008-1591778129767.png" alt="img">),<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">)与其他簇的最小平均距离为<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image010-1591778129768.png" alt="img">。轮廓系数的定义为：</p>
<p><img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/image-20200615002122028.png" alt="image-20200615002122028"></p>
<p>  当轮廓系数为越接近1时，包含<img src="/2020/06/10/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/clip_image006.png" alt="img">的簇是紧凑的，当轮廓系数值为负时，这种情况是糟糕的，应该避免。</p>
<h1 id="六、聚类的局限性和挑战"><a href="#六、聚类的局限性和挑战" class="headerlink" title="六、聚类的局限性和挑战"></a>六、聚类的局限性和挑战</h1><p>不同的文本数据有不同的特性，目前文本数据聚类的局限性也给文本聚类这一领域带来了新的挑战。</p>
<p>目前文本数据仍存在数据稀疏等问题，文档的词汇可能很多，但这些词汇是相互关联的，数据中主成分的数量远小于特征空间的特征数量。因此上述的所有聚类方法并不能解决所有文本的聚类问题。</p>
<p>近年来社交网络媒体和在线聊天应用创造了大量的文本数据，特别是短文本，短文本表示维数大，如何探索出更有效率、更节省空间的数据表示形式、如何将表示形式与聚类算法更好地结合在一起，是未来仍值得研究的课题。</p>
<p>文本数据也越来越多地出现在异构应用程序中，有效地将基于文本的算法应用于异构多媒体场景是非常关键的。P2P分布式文档聚类算法解决了其中的一些难题[28]，但对于开发结合优化技术的新型混合算法的研究仍有很大的需求。近年来的研究热点也集中在高维数据的处理上，不断提高处理速度和规模。</p>
<p>【后记-如果你还能看到这里】<br>这是模式识别课程的最终提交论文（我靠着这个论文得了98分），找了几十篇论文掐头去尾粗略的看了，还是有很多不懂的地方，但至少对于这个方向有了一个框架上的概念。写综述真的很锻炼人哇…</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Salton, G. Some experiments in the generation of word and document associations [A].Proceedings of the December 4–6, 1962, fall joint computer conference[C].1962.234–250. </p>
<p>[2] Salton, G.&amp; E. A. Fox.&amp; H. Wu. Extended Boolean information retrieval[J]. Communications of the ACM, 1983,26(11):1022–1036. </p>
<p>[3]Salton, G.&amp;M.J.McGill. Introduction to modern information retrieval[M].New York.The McGraw-Hill Companies,1986.</p>
<p>[4]McCullagh, P. What is a statistical model?[J]. Annals of Statistics,2002,30:1225–1310. </p>
<p>[5]Harris, Z. Distributional structure[J]. Word,1954,10(23):146-162.</p>
<p>[6]Luo, C., Li, Y., &amp; Chung, S. M. Text document clustering based on neighbors[J]. Data &amp; Knowledge Engineering,2009,68(11):1271–1288.</p>
<p>[7]Steinhaus, H. Sur la division des corp materiels en parties[J]. Bull. Acad. Polon. Sci,1956, IV (C1.III):801–804.</p>
<p>[8]Lloyd, S. Least squares quantization in PCM[J].IEEE Trans Inform Theory.1982,28:129–137. </p>
<p>[9]Kaufman,L.&amp;,P.J.Rousseeuw.,Clustering by means of Medoids[J].Statistical Data Analysis Based on the L1–Norm and Related Methods,1987: 405–416.</p>
<p>[10]Aggarwal, C. C.&amp;C.Zhai.A Survey of Text Clustering Algorithms[J]. Mining Text Data,2012: 77–128.</p>
<p>[11]Charikar,M.&amp;C.Chekuri. Incremental clustering and dynamic information retrieval[J]. SIAM J Comput, 2004,33(6):1417-1440.</p>
<p>[12]Guha,S.&amp;R.Rastogi.CURE: an efficient clustering algorithm for large databases[J]. Inf Syst,2003,26(1):35-58.</p>
<p>[13]Dutta,M.&amp;AK.Mahanta.QROCK: a quick version of the ROCK algorithm for clustering of categorical data[J]. Pattern Recognit Letter, 2005,26(15):2364-2373.</p>
<p>[14]Karypi,G.&amp;EH.Han.Chameleon: a hierarchical clustering algorithm using dynamic modeling. Computer,1999,32:68-75.</p>
<p>[15]Brown,P,F&amp;V.J.Della Pietra.Class-Based n-gram Models of Natural Language[J].Computational Linguistics,1992,18:467-480.</p>
<p>[16]Gil-García,J.&amp;M. Badía-Contelles&amp;A.Pons-Porrata. Extended Star Clustering Algorithm[J]. Lecture Notes on Computer Sciences,2003,2905:480-487.</p>
<p>[17]Gil-García,R.&amp;A.Pons-Porrata.Dynamic hierarchical algorithms for document clustering[J].Pattern Recognition Letters,2010,31(6):469-477.</p>
<p>[18]Zhang, Y.&amp; Cheung, Y. A fast hierarchical clustering approach based on partition and merging scheme[A]. 2018 Tenth International Conference on Advanced Computational Intelligence (ICACI).[C].Xiamen,2018.846-851.</p>
<p>[19]Kim, S.&amp; Wilbur, W. Thematic clustering of text documents using an EM-based approach[J]. Journal of Biomedical Semantics, 2012,3(Suppl 3), S6.</p>
<p>[20]Rigutini,L&amp;U.Adegli Studi di Siena.A semi-supervised document clustering algorithm based on EM[A].IEEE/WIC/ACM International Conference on Web Intelligence[C], Compiègne (France): Proceedings of the IEEE/ACM/WI International Conference on Web Intelligence,2005.200-206.</p>
<p>[21]Deerwester,S&amp;S.Dumais.Indexing by latent semantic analysis[J].Journal of the American Society for Informatlon Science,1990,41(6):391-407.</p>
<p>[22]Hofmann,T.Probabilistic latent semantic analysis[A].Proc.of the Conference on Uncertainty in Artificial Intelligence[C].1999:289—296.</p>
<p>[23]Blei,D&amp;A.Ng A.Latent Dirichlet Allocation[J].Journal of Machine Learning Research,2003,3:993—1022．</p>
<p>[24]C. Borgelt and A. Nurnberger.Fast Fuzzy Clustering of Web Page Collections[A].Proc. of PKDD Workshop on Statistical Approaches for WebMining（SAWM)[C],Pisa(Italy) 2004.</p>
<p>[25]Zhang,W.&amp;T.Yoshida.Text Clustering Using Frequent Itemsets[J]. Knowledge-Based Systems,2010,23(5):379-388.</p>
<p>[26]Yang Y. An evaluation of statistical approaches to text categorization[J]. Information retrieval, 1999, 1(1-2): 69-90.</p>
<p>[27]Han,J&amp;M.Kamber.数据挖掘：概念与技术(原书第3版)[M].北京：机械工业出版社.2012.</p>
<p>[28]Judith, J.E.&amp;J.Jayakumari.Distributed document clustering algorithms: a recent survey[J].Int. J. Enterprise Network Management,2015,Vol. 6, No. 3:207–221.</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/23/%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/">【编译原理复习专题5】中间代码生成</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-23
        </span><span class="post-visits"
             data-url="/2020/05/23/%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"
             data-title="【编译原理复习专题5】中间代码生成">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>中间代码生成就是把经过语法分析和语义分析的源程序中间表示翻译为中间代码展示，中间表示可能有多个种类，如语法树、DAG、后缀式、三地址代码等。</p>
<p>如果中间代码独立于机器的话，那么各便于编译系统的建立和移植，并且便于进行独立于机器的代码优化工作。</p>
<h1 id="三地址代码"><a href="#三地址代码" class="headerlink" title="三地址代码"></a>三地址代码</h1><p>三地址代码包含一个运算和三个地址，两个地址用于存放运算对象，一个用于存放运算结果。</p>
<p>具体实现：四元式、三元式、间接三元式。</p>
<h2 id="四元式"><a href="#四元式" class="headerlink" title="四元式"></a>四元式</h2><p>op、arg1、arg2、result</p>
<h2 id="三元式"><a href="#三元式" class="headerlink" title="三元式"></a>三元式</h2><p>op、arg1、arg2 使用运算x op y 的位置来表示计算的结果</p>
<h2 id="间接三元式"><a href="#间接三元式" class="headerlink" title="间接三元式"></a>间接三元式</h2><h1 id="类型和声明"><a href="#类型和声明" class="headerlink" title="类型和声明"></a>类型和声明</h1><p>类型表达式是用于表示类型的结构的，如基本类型int、char、float，</p>
<p>类型表达式名也是类型表达式。</p>
<p>类型构造算子:作用于类型表达式可以构造新的类型表达式。</p>
<p><strong>数组构造符array</strong></p>
<table>
<thead>
<tr>
<th align="center">类型</th>
<th align="center">类型表达式</th>
</tr>
</thead>
<tbody><tr>
<td align="center">int[3]</td>
<td align="center">array(3,int)</td>
</tr>
<tr>
<td align="center">int[2][3]</td>
<td align="center">array(2,array(3,int))</td>
</tr>
</tbody></table>
<p><strong>指针构造符pointer</strong></p>
<p><strong>笛卡尔乘积构造符x</strong></p>
<p><strong>函数构造符-&gt;</strong></p>
<p><strong>记录构造符record</strong></p>
<h2 id="类型检查-type-checking"><a href="#类型检查-type-checking" class="headerlink" title="类型检查 type checking"></a>类型检查 type checking</h2><p>保证参与的运算分量和运算符预期的类型相匹配。</p>
<p><strong>如果两个类型表达式相等，那么返回某种类型，否则出错</strong></p>
<h3 id="类型等价"><a href="#类型等价" class="headerlink" title="类型等价"></a>类型等价</h3><blockquote>
<p>两种类型之间结构等价当且仅当下面某个条件为真： </p>
<p>1.是相同的类型</p>
<p>2.是相同的类型构造算子应用于结构等价的类型而构造得到的。</p>
<p>3.一个类型是另一个类型表达式的名字</p>
</blockquote>
<p><strong>类型检查有两种形式：类型综合和类型推导。</strong></p>
<p>类型综合是根据子表达式的类型构造出表达式的类型，<strong>要求名字先声明再使用</strong>。表达式$E1+E2$的类型是根据$E1$和$E2$的类型定义的。</p>
<p>类型推导是根据一个语言结构的使用来确定结构的类型，就类似如果使用了某个类型才能用的函数的话，那么可以指出使用该函数的变量就是对应的类型。</p>
<h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>浮点数和整型相加，编译器内部需要进行转换。</p>
<p>不同的语言有不同的类型转换，主要转换有两种：拓宽转换（保持信息）、窄化转换（丢失信息）。</p>
<h2 id="类型翻译"><a href="#类型翻译" class="headerlink" title="类型翻译"></a>类型翻译</h2><h2 id="类型的声明"><a href="#类型的声明" class="headerlink" title="类型的声明"></a>类型的声明</h2><p>语义分析在遇到声明语句时，主要做两件事情：1.收集标识符的类型等属性信息；2.为每一个名字分配一个相对地址。</p>
<h3 id="声明的SDT"><a href="#声明的SDT" class="headerlink" title="声明的SDT"></a>声明的SDT</h3><h2 id="表达式和赋值语句的翻译"><a href="#表达式和赋值语句的翻译" class="headerlink" title="表达式和赋值语句的翻译"></a>表达式和赋值语句的翻译</h2><h3 id="为赋值语句生成三地址码的SDD"><a href="#为赋值语句生成三地址码的SDD" class="headerlink" title="为赋值语句生成三地址码的SDD"></a>为赋值语句生成三地址码的SDD</h3><p>gen 一个函数，生成括号内代表信息的三地址码</p>
<table>
<thead>
<tr>
<th>Production</th>
<th>Semantic Rules</th>
</tr>
</thead>
<tbody><tr>
<td>$S\rightarrow id=E$</td>
<td>$S.code=E.code</td>
</tr>
<tr>
<td>$E\rightarrow E_1+E_2$</td>
<td>$E.addr=new Temp()$, $E.code=E1.code</td>
</tr>
<tr>
<td>$E\rightarrow -E_1$</td>
<td>$E.addr=new Temp()$ ,$E.code=E_1.code</td>
</tr>
<tr>
<td>$E\rightarrow (E_1)$</td>
<td>$E.addr=E1.addr$,$E.code=E_1.code$</td>
</tr>
<tr>
<td>$E\rightarrow id$</td>
<td>$E.addr=top.get(id.lexeme)$, $E.code=’’$</td>
</tr>
</tbody></table>
<p>将$a=b+-c;$ 编译成三地址码：</p>
<p>$S\Rightarrow id=E_0;$</p>
<p>$\Rightarrow id=E_1+E_2;$</p>
<p>$\Rightarrow id=E_1+-E_3;$ </p>
<p>$\Rightarrow id=E_1+-id;$</p>
<p>$\Rightarrow id=id+-id;$</p>
<table>
<thead>
<tr>
<th>产生式</th>
<th>属性变化</th>
</tr>
</thead>
<tbody><tr>
<td>$E_1\rightarrow id$</td>
<td>$E_1.addr=addr(b)$, $E_1.code=’’$</td>
</tr>
<tr>
<td>$E3\rightarrow id$</td>
<td>$E_3.addr=addr(c)$, $E_3.code=’’$</td>
</tr>
<tr>
<td>$E_2\rightarrow -E_3$</td>
<td>$E_2.addr=t1$ ,$E_2.code=E_3.code</td>
</tr>
<tr>
<td>$E_0\rightarrow E_1+E_2$</td>
<td>$E_0.addr=t2$,$E_0.code=E_1.code</td>
</tr>
<tr>
<td>$S\rightarrow id=E_0$</td>
<td>$S.code=E_0.code</td>
</tr>
</tbody></table>
<p>刚好三行就是赋值语句的三地址码。</p>
<h3 id="布尔表达式的翻译"><a href="#布尔表达式的翻译" class="headerlink" title="布尔表达式的翻译"></a>布尔表达式的翻译</h3><h4 id="短路代码"><a href="#短路代码" class="headerlink" title="短路代码"></a>短路代码</h4><p>跳转代码中&amp;&amp; || ！都被翻译成跳转指令。</p>
<p>语句：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(x&lt;<span class="number">100</span>||x&gt;<span class="number">200</span> &amp;&amp; x!=y)</span><br><span class="line">	x=<span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>三地址代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if x&lt;100 goto L2</span><br><span class="line">goto L3</span><br><span class="line">L3: if x&gt;200 goto L4</span><br><span class="line">goto L1</span><br><span class="line">L4: if x!&#x3D;y goto L2</span><br><span class="line">goto L1</span><br><span class="line">L2:x&#x3D;0</span><br><span class="line">L1:</span><br></pre></td></tr></table></figure>

<p>其实运算符并不在代码中，布尔表达式的值是通过代码序列中的位置来表示的。</p>
<h3 id="控制流语句"><a href="#控制流语句" class="headerlink" title="控制流语句"></a>控制流语句</h3><p>控制流语句：(S表示语句，B表示布尔表达式)</p>
<p>1.$P\rightarrow S$</p>
<p>2.$S\rightarrow assign$</p>
<p>3.$S\rightarrow if(B) S1$</p>
<p>4.$S\rightarrow if(B) \quad S1 \quad else \quad S2$</p>
<p>5.$S\rightarrow while(B)\quad S1$</p>
<p>6.$S\rightarrow S1 \quad S2$</p>
<p>SDD</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>$P\rightarrow S$</td>
<td>$S.next=newlable()$</td>
</tr>
<tr>
<td>$S\rightarrow assign$</td>
<td>$S.code=assign.code$</td>
</tr>
<tr>
<td>$S\rightarrow if(B) S1$</td>
<td>$B.true=newlabel()$,$B.false=S_1.next=S.next$, $S.code=B.code</td>
</tr>
<tr>
<td>$S\rightarrow if(B) \quad S1 \quad else \quad S2$</td>
<td>$B.true=newlabel()$,$B.false=newlabel()$,$S_1.next=S_2.next=S.next$,$S.code=B.code</td>
</tr>
<tr>
<td>$S\rightarrow while(B)\quad S1$</td>
<td></td>
</tr>
</tbody></table>
<p><strong>(1) $B\rightarrow E1 \quad rel \quad R2$ (假设形如$a&lt;b$)</strong></p>
<p>$B.true: if \quad a&lt;b\quad goto \quad B.true$ (j&lt;,a,b,B.true)</p>
<p>$B.FALSE: goto B.false$     (j,,,B.false)</p>
<p>(2) <strong>B是常量</strong>, 就直接翻译为跳转指令。</p>
<p>(3) 不需要为$B\rightarrow!B$产生新的代码，只需要将真假出口交换就可以了。(继承属性)。</p>
<p>(4) 对$B\rightarrow B1||B2$,</p>
<p>如果B1为真则B为真，B1.true从B.true继承而来，如果B1为假，则对B2求值，B1.false就可以设置为B2的代码的第一条指令的标号。B2的真假出口标号可直接从B继承获得。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/">【编译原理复习专题4】语法制导翻译</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-22
        </span><span class="post-visits"
             data-url="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/"
             data-title="【编译原理复习专题4】语法制导翻译">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>语法制导翻译，边做语法分析，边做语义分析。它使用CFG引导对语言的翻译，是一种面向文法的翻译技术。</p>
<h1 id="语义信息"><a href="#语义信息" class="headerlink" title="语义信息"></a>语义信息</h1><p><strong>如何表示语义信息？</strong></p>
<p>将语言结构的语义以属性(attribute)的形式赋予代表此结构的文法符号。</p>
<p><strong>如何计算语义属性？</strong></p>
<p>属性的计算以语义规则(semantic rules)的形式赋予由文法符号组成的产生式。在语法分析推导或归约的每一步骤中，通过语义规则实现对属性的计算，以达到对语义的处理。</p>
<p>换句话说就是：为每一个产生式配上语义规则并且在适当的时候执行这些规则。</p>
<h1 id="SDD-语法制导定义"><a href="#SDD-语法制导定义" class="headerlink" title="SDD 语法制导定义"></a>SDD 语法制导定义</h1><p>SDD是一个上下文无关文法和属性及规则的结合。属性和文法符号相关联，而规则和产生式相关联，有时也称为属性文法。<br>如果𝑿是一个符号，而𝒂是𝑿的一个属性，那么用𝑿.𝒂来表示在某个标号为𝑿的分析树节点上的属性值。属性可以有很多类型，比如变量的数据类型、表达式的值、变量的地址、数字的有效位数等等。</p>
<h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p>属性分为综合属性和继承属性。</p>
<p><strong>综合属性</strong>只能由当前结点或者结点的子节点的属性值来计算。通常，产生式左侧的属性都来自右侧的话，那么左侧的属性就是综合属性。</p>
<p><strong>继承属性</strong>是由当前结点的父节点或兄弟节点或本身的属性值来定义的。（只要有父节点或兄弟结点定义就是继承属性了）</p>
<blockquote>
<p>终结符可以有综合属性，就是词法分析的词法值。终结符没有继承属性。</p>
</blockquote>
<p>属性文法写成表格形式，相同的非终结符需要用下标区分。</p>
<h2 id="S属性的SDD"><a href="#S属性的SDD" class="headerlink" title="S属性的SDD"></a>S属性的SDD</h2><p>只包含综合属性的SDD称为S属性的SDD。它可以按照任何自底向上的顺序进行求值。</p>
<p>L属性SDD的特例。</p>
<h2 id="L属性的SDD"><a href="#L属性的SDD" class="headerlink" title="L属性的SDD"></a>L属性的SDD</h2><p>要么是综合属性，要么是继承属性，且满足以下i条件：</p>
<p>对于产生式$A\rightarrow X_1 X_2 …X_n$,$X_i$的继承属性仅能依赖于：</p>
<ul>
<li><p>A的继承属性（如果是综合属性可能会有环路）</p>
</li>
<li><p>产生式$X_i$左侧的属性。（继承属性只能右侧的继承左侧的，规定了依赖图的边只能从左往右)</p>
</li>
</ul>
<h2 id="SDD的求值"><a href="#SDD的求值" class="headerlink" title="SDD的求值"></a>SDD的求值</h2><p>如果是综合属性，就可以按照任何自底向上的顺序进行求值，如果是同时具有继承属性和综合属性的话，首先要看有没有出现环状的依赖关系，最好不要出现循环的情况。</p>
<p>1.绘制依赖图dependency graph</p>
<p>2.求DAG的依赖图的拓扑排序（如果图存在环，就不存在拓扑排序）</p>
<p>拓扑排序不是唯一的，平行关系可以交换。</p>
<h1 id="SDT-语法制导的翻译方案"><a href="#SDT-语法制导的翻译方案" class="headerlink" title="SDT 语法制导的翻译方案"></a>SDT 语法制导的翻译方案</h1><p>SDT是在产生式中嵌入了程序片段的一个上下文无关文法。这些片段称为语义动作，它们可以出现在产生式的任何位置。默认用{}括起来。</p>
<blockquote>
<p>SDD时语言翻译的高层次规格说明，隐藏了很多具体实现细节，使用户不必显式地说明翻译发生的顺序。</p>
<p>SDT是SDD的一种补充，是SDD的具体实施方案，显式地指明了语义规则的计算顺序，以便说明某些实现细节。</p>
</blockquote>
<p>语法制导翻译可以用于抽象语法树的构建，</p>
<h2 id="如何用SDT实现两类重要的SDD"><a href="#如何用SDT实现两类重要的SDD" class="headerlink" title="如何用SDT实现两类重要的SDD"></a>如何用SDT实现两类重要的SDD</h2><p>产生式右侧的动作在它左边的所有文法符号后被匹配后立即执行。</p>
<p>将内嵌语义动作替换成一个新的非终结符，可以执行相应的语义动作。</p>
<h3 id="S属性的SDD-1"><a href="#S属性的SDD-1" class="headerlink" title="S属性的SDD"></a>S属性的SDD</h3><p><strong>后缀翻译方案：</strong></p>
<p>S属性的SDD可以构造出SDT: <strong>每个动作都放在产生式的结尾。</strong></p>
<p>所有属性都是综合属性。</p>
<h3 id="产生式内部带有语义动作的SDT"><a href="#产生式内部带有语义动作的SDT" class="headerlink" title="产生式内部带有语义动作的SDT"></a>产生式内部带有语义动作的SDT</h3><p>$B\rightarrow X{a}Y$</p>
<p>自底向上，X出现在分析栈栈顶时，立即执行动作a。</p>
<p>自顶向下，在展开Y的本次出现或者在输入中检测Y之前执行动作a。</p>
<h3 id="L属性的SDD-1"><a href="#L属性的SDD-1" class="headerlink" title="L属性的SDD"></a>L属性的SDD</h3><p>将计算某个非终结符号A的<strong>继承属性</strong>的动作插入到产生式<strong>右部中紧靠在A的本次出现之前的位置上</strong>。</p>
<p>将计算一个产生式左部符号的<strong>综合属性</strong>的动作放置在这个产生式右部的<strong>最右端</strong> <strong>。</strong></p>
<p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200226341.png" alt="image-20200523200226341"></p>
<p>如果基本文法可以用LL分析，那么可以用递归下降、在LL预测分析过程中翻译(属性值存放在语法分析栈中)或者用LR分析。</p>
<h3 id="在递归下降分析中加入语义翻译"><a href="#在递归下降分析中加入语义翻译" class="headerlink" title="在递归下降分析中加入语义翻译"></a>在递归下降分析中加入语义翻译</h3><p>函数A的参数是非终结符A的继承属性<br>函数A的返回值是非终结符A的综合属性</p>
<p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200609909.png" alt="image-20200523200609909"></p>
<p><img src="/2020/05/22/%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image-20200523200643560.png" alt="image-20200523200643560"></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/">【编译原理复习专题3】语法分析的例子整理</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-21
        </span><span class="post-visits"
             data-url="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/"
             data-title="【编译原理复习专题3】语法分析的例子整理">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="SLR-1"><a href="#SLR-1" class="headerlink" title="SLR(1)"></a>SLR(1)</h2><p>考虑文法：</p>
<p>$E\rightarrow E+T|T$</p>
<p>$T\rightarrow T*F|F$</p>
<p>$F\rightarrow (E) |id$</p>
<p>1.扩展文法：</p>
<p>$E’\rightarrow E$<br>$E\rightarrow E+T|T$<br>$T\rightarrow T*F|F$<br>$F\rightarrow (E) |id$</p>
<p>2.LR(0)项：</p>
<p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200522080711106.png" alt="LR(0)项"></p>
<p>3.绘制LR(0)自动机：</p>
<p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200521205727392.png" alt="LR(0)自动机"></p>
<p>4.由状态1、2、9可发现，这个语法有移进归约冲突，因此不是LR(0)文法，</p>
<p>而在状态1中，Follow(E’)={$},+不在E’的Follow集里面的，因此无歧义，在状态2和9中，Follow(E)={+,(,$},*不在E的Follow集里，也无歧义，该文法是SLR(1)文法。</p>
<p>5.构建SLR(1)分析表。</p>
<p><img src="/2020/05/21/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E4%BE%8B%E5%AD%90%E6%95%B4%E7%90%86/image-20200522095458808.png" alt="image-20200522095458808"></p>
<p>6.串(id+id)*id的分析过程:</p>
<table>
<thead>
<tr>
<th></th>
<th>stack</th>
<th>input</th>
<th>action</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>$0</td>
<td>(id+id)*id$</td>
<td>S4</td>
</tr>
<tr>
<td>2</td>
<td>$0(4</td>
<td>id+id)*id$</td>
<td>S5</td>
</tr>
<tr>
<td>3</td>
<td>$0(4id5</td>
<td>+id)*id$</td>
<td>$r(F\rightarrow id)$</td>
</tr>
<tr>
<td>4</td>
<td>$0(4F3</td>
<td>+id)*id$</td>
<td>$r(T\rightarrow F)$</td>
</tr>
<tr>
<td>5</td>
<td>$0(4T2</td>
<td>+id)*id$</td>
<td>$r(E\rightarrow T)$</td>
</tr>
<tr>
<td>6</td>
<td>$0(4E8</td>
<td>+id)*id$</td>
<td>S6</td>
</tr>
<tr>
<td>7</td>
<td>$0(4E8+6</td>
<td>id)*id$</td>
<td>S5</td>
</tr>
<tr>
<td>8</td>
<td>$0(4E8+6id5</td>
<td>)*id$</td>
<td>$r(F\rightarrow id)$</td>
</tr>
<tr>
<td>9</td>
<td>$0(4E8+6F3</td>
<td>)*id$</td>
<td>$r(T\rightarrow F)$</td>
</tr>
<tr>
<td>10</td>
<td>$0(4E8+6T9</td>
<td>)*id$</td>
<td>$r(E\rightarrow E+T)$</td>
</tr>
<tr>
<td>11</td>
<td>$0(4E8</td>
<td>)*id$</td>
<td>S11</td>
</tr>
<tr>
<td>12</td>
<td>$0(4E8)11</td>
<td>*id$</td>
<td>$r(F\rightarrow (E))$</td>
</tr>
<tr>
<td>13</td>
<td>$0F3</td>
<td>*id$</td>
<td>$r(T\rightarrow F)$</td>
</tr>
<tr>
<td>14</td>
<td>$0T2</td>
<td>*id$</td>
<td>S7</td>
</tr>
<tr>
<td>15</td>
<td>$0T2*7</td>
<td>id$</td>
<td>S5</td>
</tr>
<tr>
<td>16</td>
<td>$0T2*7id5</td>
<td>$</td>
<td>$r(F\rightarrow id)$</td>
</tr>
<tr>
<td>17</td>
<td>$0T2*7F10</td>
<td>$</td>
<td>$r(T\rightarrow  T*F)$</td>
</tr>
<tr>
<td>18</td>
<td>$0T2</td>
<td>$</td>
<td>$r(E\rightarrow T)$</td>
</tr>
<tr>
<td>19</td>
<td>$0E1</td>
<td>$</td>
<td>accept</td>
</tr>
</tbody></table>
<p>因此该串被接受。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/">【编译原理复习专题2】关于语法分析</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-21
        </span><span class="post-visits"
             data-url="/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"
             data-title="【编译原理复习专题2】关于语法分析">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p>这将是一个非常口语化的总结，因为这就是我口述的总结。</p>
</blockquote>
<p>语法分析过程主要包括两种方法：自底向上的语法分析和自顶向下的语法分析。其中，“底”指的就是原始串，而“顶”指的是开始符号。分析的目的就是确定某一个确定的字符串是否属于文法描述的语言。</p>
<p>而这些分析方法，最终都是要让串形成对应的语法分析树，因此它们将一个判定问题，转化成了生成语法分析树的过程。</p>
<h1 id="First集和Follow集"><a href="#First集和Follow集" class="headerlink" title="First集和Follow集"></a>First集和Follow集</h1><p>First集和Follow集应该是对于任意的文法都是能够确定的。</p>
<p>文法中的任意文法符号串都是有First集的，First集相当于这个文法符号串能推出的串中最左侧的终结符的集合。First集可以包含$\epsilon$。</p>
<blockquote>
<p>求First集的规则：</p>
<ol>
<li><p>把所有的终结符语法规则列出来（我感觉First集求的时候不能有或？还是也可以）</p>
</li>
<li><p>如果X是终结符或者$\epsilon$,$First(X)={X}$</p>
<p>如果X是非终结符，对每个产生式$X-&gt;X_1X_2…X_n$,$First(X_1)$是$First(X)$的子集。</p>
<p>如果有$X_1X_2…X_i\Rightarrow\epsilon(i&lt;n)$,那么$First(X_{i+1})$是$First(X)$的子集。</p>
</li>
</ol>
</blockquote>
<p>Follow集能够让一个非终结符消失（推出空），就是说Follow是确定当某一个非终结符后面出现了哪些终结符的时候，我们需要用推出空这个产生式。</p>
<blockquote>
<p>求Follow集的规则：</p>
<p>1.先将$放入Follow(S)中，S为开始字符。(构建LL(1)分析表的时候，如果有$S\Rightarrow\epsilon$,那么就可以写在[S,$]里，表示如果接受的是一个空串，就可以用这个产生式)</p>
<p>2.如果存在产生式$A\rightarrow\alpha B\beta$,那么求解Follow(B)的时候，要将$First(\beta)$中除了$\epsilon$所有的元素都加入Follow(B)。$\beta$可包含终结符或非终结符。</p>
<p>3.产生式右侧被推导出之后，左侧的Follow集就是右侧最右（需要考虑右侧是否为空，若为空就不断考虑向左移动的符号）的非终结符的Follow集的子集。</p>
<p>【如果存在产生式$A\rightarrow\alpha B\beta$,且$\beta$可空（或者说B的First集包含$\epsilon$)，那么$Follow(B)\Leftarrow Follow(A)$】</p>
</blockquote>
<p>因为我们确定某个非终结符的Follow集，都是通过它在右侧才能确定的，因此我们不需要考虑那些右侧全是终结符的产生式。</p>
<p>LL(1)分析表做的是这件事：横轴是预测的下一个字符，然后当前的栈顶的非终结符已知，那么要通过哪一个产生式能够最终推出预测的下一个字符。所以我们需要通过计算First集和Follow集来确定LL(1)分析表。</p>
<h1 id="自顶向下的语法分析"><a href="#自顶向下的语法分析" class="headerlink" title="自顶向下的语法分析"></a>自顶向下的语法分析</h1><p>从开始符号最终到实际的字符串，<strong>自顶向下</strong>中主要分为<strong>回溯分析程序</strong>和<strong>预测分析程序</strong>。我们主要学了两种预测分析方法：<strong>递归下降和LL(1)</strong>。</p>
<p><strong>为何叫“预测分析”，</strong>我们可以这么理解：首先，自顶向下分析方法的基础就是将字符串看成输入串，就是说从开始到结束，我们可以认为是逐步读取这个串的，因此字符之间有了先后被读取的，那么我们构建语法分析树也就是一个先根次序创建树的过程，我们也可以说<strong>自顶向下分析就是要找到对应串的最左推导</strong>。因此预测分析首先是要求给定的文法中没有左因子、左递归，文法不能是二义性的，其次预测分析需要看文法的下一个字符，也就是<strong>下一个输出符号</strong>，所以我们称之为“预测”。</p>
<h2 id="回溯分析程序"><a href="#回溯分析程序" class="headerlink" title="回溯分析程序"></a>回溯分析程序</h2><h2 id="预测分析程序"><a href="#预测分析程序" class="headerlink" title="预测分析程序"></a>预测分析程序</h2><h3 id="递归下降"><a href="#递归下降" class="headerlink" title="递归下降"></a>递归下降</h3><p>改写为$EBNF$(消除左递归、去除左因子)</p>
<h3 id="LL-1-分析算法"><a href="#LL-1-分析算法" class="headerlink" title="LL(1)分析算法"></a>LL(1)分析算法</h3><p>第一个L表示从左向右扫描输入，第二个L表示最左推导，1表示每一步中只需要向前看一个输入符号来决定语法分析动作。</p>
<h4 id="预测分析表的构建"><a href="#预测分析表的构建" class="headerlink" title="预测分析表的构建"></a>预测分析表的构建</h4><blockquote>
<p>$LL(1)$构建预测分析表的步骤：</p>
<ol>
<li>$First(\alpha)$中的每个记号$s$，都将$A\rightarrow\alpha$添加至$M[A,s]$中。</li>
<li>$\alpha$可空的话，对$Follow(A)$中的每一个元素$k$，将$A\rightarrow\alpha$添加到$M[A,k]$中。</li>
</ol>
<p>如果$M[A,\alpha]$没有产生式的话，就将其设置为$error$。</p>
</blockquote>
<h4 id="LL-1-文法"><a href="#LL-1-文法" class="headerlink" title="LL(1)文法"></a>LL(1)文法</h4><p>一个文法若满足以下条件，则该文法就是LL(1)文法：</p>
<p>在每个产生式$A\rightarrow{\alpha}_1 |{\alpha}_2⋯|{\alpha}_n$中，对于所有的i和j:$1≤i, j≤n, i≠j$，$First(α_i )∩First(α_j )$为空。（若不为空，假设有一个相同元素$k$,那么在$M[A,k]$就会加入两个产生式：$A\rightarrow{\alpha}_i$和$A\rightarrow{\alpha}_j$)</p>
<p>若对于非终结符A可空，那么$First(A)∩Follow(A)$为空。(若有相同元素k，根据分析表也会发现$M[A,k]$有两个产生式)</p>
<p><strong>如果一个文法G，由它构造的LL(1)分析表中的每个子项最多只含有一个产生式，那么它就是LL(1)文法。</strong></p>
<p>在LL(1)分析表中有两项产生式的文法不一定是二义性的文法，可能是有左递归的。</p>
<blockquote>
<p>一个不是$LL(1)$的文法同样可以用$LL(1)$方法。</p>
</blockquote>
<p>LL(1）方法对应的是非递归的预测分析器，显示维护栈结构，应该和计算理论里的下推自动机类似。下推自动机所定义的语言恰好就是上下文无关语言。</p>
<h1 id="自底向上的语法分析"><a href="#自底向上的语法分析" class="headerlink" title="自底向上的语法分析"></a>自底向上的语法分析</h1><p>归约其实就是推导的反向操作。如果反向构造一个推导过程，那么就会是最右推导的。推导的方法是从记号串开始，使用产生式进行归约，期望得到开始符号，如果能够得到开始符号，那么这个字符串就是文法可以识别的语句。</p>
<p>两个动作：移进 shift和规约 reduce。</p>
<p>自底向下就是从输入串到开始符号的归约，归约的方向是从左到右，可以认为是最左归约，逆向的过程就是最右推导。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="短语、直接短语和句柄"><a href="#短语、直接短语和句柄" class="headerlink" title="短语、直接短语和句柄"></a>短语、直接短语和句柄</h3><p>短语就是在一个句型中对应的分析树，里以非终结符为根的子树的所有叶子节点构成的排列就是对于该非终结符的短语，如果子树只有两层，那么就是直接短语。最左侧的非终结符的子树对应的短语就是句柄。</p>
<p>句柄的定义：如果$S\Rightarrow_{lm}^{*}\alpha A\omega \Rightarrow_{lm} \alpha \beta \omega$，A是输入串中最右的非终结符，则$\beta$称为一个句柄。</p>
<p>句柄可以理解为一个归约点，可以允许解析器通过进一步的归约操作回到开始符号的位置。而实际上我们做的归约就是最左归约。</p>
<p>对于下列文法：</p>
<p>$E\rightarrow E+T|T$<br>$T\rightarrow T*F|F$<br>$F\rightarrow (E) |id$</p>
<p>对于输入串$id*id$，从左到右相当于一个最左归约的过程。从左至右：</p>
<table>
<thead>
<tr>
<th>产生式</th>
<th>句柄</th>
<th>最右句型</th>
</tr>
</thead>
<tbody><tr>
<td>$F\rightarrow id$</td>
<td>$id$</td>
<td>id*id</td>
</tr>
<tr>
<td>$T\rightarrow F$</td>
<td>$F$</td>
<td>F*id</td>
</tr>
<tr>
<td>$F\rightarrow id $</td>
<td>$id$</td>
<td>T*id</td>
</tr>
<tr>
<td>$T\rightarrow T*F$</td>
<td>$T*F$</td>
<td>T*F</td>
</tr>
<tr>
<td>$E\rightarrow T$</td>
<td>$T$</td>
<td>T</td>
</tr>
</tbody></table>
<p><img src="/2020/05/21/%E5%85%B3%E4%BA%8E%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image-20200521195029382.png" alt="image-20200521195029382"></p>
<h3 id="可行前缀"><a href="#可行前缀" class="headerlink" title="可行前缀"></a>可行前缀</h3><h2 id="LR-0-分析算法"><a href="#LR-0-分析算法" class="headerlink" title="LR(0)分析算法"></a>LR(0)分析算法</h2><p><strong>LR(0)文法中L指的是从左到右扫描输入串，R代表了最右推导，0表示进行分析动作的决策只考虑栈顶状态，不需要看输入串。（没有lookahead)</strong></p>
<p><strong>1.扩展文法。</strong></p>
<p>在决定状态间的转移前，我们必须先加入一条扩展文法：$S\rightarrow E$其中$S$是新的起始符号（start symbol）而<em>E</em>是原先的起始符号。这一做法是为了保证分析器能有一个唯一的起始状态。</p>
<p><strong>2.列LR(0)项。</strong>(点号的左侧是已经读入的，点号的剩余是还没有读入的)</p>
<p><strong>3.起始状态是所有点在最左侧的LR(0)项组成的封闭集,构建LR(0)自动机</strong></p>
<p><strong>4.构建LR(0)分析表。</strong></p>
<p><strong>5.进行分析。</strong></p>
<p>如果X是终结符，只要有移进项先移进。</p>
<h4 id="LR-0-文法"><a href="#LR-0-文法" class="headerlink" title="LR(0)文法"></a>LR(0)文法</h4><p>无歧义需要没有归约归约冲突或移进归约冲突。</p>
<h2 id="SLR-1-分析算法"><a href="#SLR-1-分析算法" class="headerlink" title="SLR(1)分析算法"></a>SLR(1)分析算法</h2><p>如果当前栈顶状态可以支持终结符移进，并且<strong>下一个记号也就是该终结符</strong>，才会移进。如果当前栈顶状态包含了归约项$A\rightarrow\gamma.$，且<strong>下一个记号在$Follow（A)$</strong>时，才会使用$A\rightarrow\gamma$归约，如果不在$Follow(A)$也不会做归约。$GOTO$项与LR(0)类似。</p>
<blockquote>
<p>歧义的产生：</p>
<p>1)有归约项和移进项，且移进项$A\rightarrow \alpha . X \beta$的下一个字符$X$在$Follow（B）$中,当然如果下一个记号不是$X$那么就没有歧义了。</p>
<p>2)有两个不同的归约项$A\rightarrow\beta.$，$B\rightarrow\gamma.$，且下一个记号即在A的Follow集也在B的Follow集，或者两个Follow集都没有$X$,此时要报错。</p>
</blockquote>
<p>当确认没有歧义的时候，归约项$r(A\rightarrow \gamma)$就会被填入A的Follow集对应的Input下。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/21/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">【编译原理复习专题1】上下文无关文法和正则表达式</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-21
        </span><span class="post-visits"
             data-url="/2020/05/21/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"
             data-title="【编译原理复习专题1】上下文无关文法和正则表达式">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>扫描器是词法分析器，它接收输入的源程序，对源程序进行词法分析并识别出一个个单词符号，输出单词符号。</p>
<h1 id="上下文无关语言"><a href="#上下文无关语言" class="headerlink" title="上下文无关语言"></a>上下文无关语言</h1><p>表示上下文无关文法规则的形式被称为BNF，其扩展表示就是EBNF。</p>
<p>在BNF中，重复是使用递归表示的，重复实际分两种：嵌套重复和并列重复，并列重复对应到程序是可以用循环来实现的。</p>
<h2 id="EBNF"><a href="#EBNF" class="headerlink" title="EBNF"></a>EBNF</h2><p><strong>重复表示{…}</strong></p>
<blockquote>
<p>下面两种重复的递归形式表达的就是并列重复：</p>
<p>$A\rightarrow A \alpha|\beta$</p>
<p>$A\rightarrow \alpha A |\beta$</p>
<p>其中第一条中要求$\beta$ 不能以A开头， 而第二条中要求$\beta$不能以A结尾。对应的正则表达式为：$\beta \alpha^<em>$和$\alpha^</em>\beta$<br>EBNF中使用{…}来表示这种重复：<br>$A\rightarrow \beta {\alpha}$</p>
<p>$A\rightarrow{\alpha} \beta$</p>
</blockquote>
<p><strong>可选表示[…]</strong> 有点类似消除左因子。</p>
<blockquote>
<p>语句序列：<br>$stmt-sequence \rightarrow stmt; stmt-sequence | stmt$<br>可以表示为：<br>$stmt-sequence \rightarrow  stmt [ ; stmt-sequence ]$<br>$stmt-sequence \rightarrow  stmt { ; stmt }  $       </p>
</blockquote>
<h2 id="消除左递归"><a href="#消除左递归" class="headerlink" title="消除左递归"></a>消除左递归</h2><h3 id="直接简单左递归"><a href="#直接简单左递归" class="headerlink" title="直接简单左递归"></a>直接简单左递归</h3><p>$A\rightarrow A \alpha |\beta$</p>
<p>改写文法为：</p>
<p>$A\rightarrow \beta A’$</p>
<p>$A’\rightarrow \alpha A’ |\epsilon$</p>
<h3 id="间接左递归"><a href="#间接左递归" class="headerlink" title="间接左递归"></a>间接左递归</h3><p>会出现$A\Rightarrow^*A$的左递归。</p>
<p>处理方法：</p>
<p>将文法的所有非终结符按任意一种顺序排序，得到$A_1,A_2…A_n$</p>
<p>对每个$A_i$，如果存在一个编号比它小的非终结符，编号大的非终结符可以含有推出编号小的非终结符的句型，而且编号小的非终结符还能够推出一个句型，那么就可以进行代入操作。<br>如果有直接左递归，那么直接消除即可。</p>
<blockquote>
<p>$S\rightarrow Qc|c$</p>
<p>$Q\rightarrow Rb|b$</p>
<p>$R\rightarrow Sa|a$</p>
<p>1) 对S、Q、R编号1、2、3</p>
<p>2）i=1，无法代入，i=2，无法代入</p>
<p>i=3, 代入有 $R\rightarrow Qca|ca|a$,可再次代入：$R\rightarrow Rbca|bca|ca|a$</p>
<p>3)化简直接左递归：</p>
<p>$R\rightarrow bcaR’|caR’|aR’$</p>
<p>$R\rightarrow bcaR’|\epsilon$</p>
</blockquote>
<h2 id="消除左公因子"><a href="#消除左公因子" class="headerlink" title="消除左公因子"></a><strong>消除左公因子</strong></h2><p>对每个非终结符A，找出它的两个或多个选项之间的最长公共前缀$\alpha$,如果$\alpha$不为空，即存在一个非平凡的公共前缀，那么将所有A的产生式$A\rightarrow \alpha\beta_1|\alpha\beta_2|…\alpha\beta_n|\gamma$,</p>
<p>替换为：</p>
<p>$A\rightarrow \alpha A’|\gamma$</p>
<p>$A’\rightarrow \beta_1|\beta_2|…|\beta_n$</p>
<h2 id="递归构造上下文无关文法"><a href="#递归构造上下文无关文法" class="headerlink" title="递归构造上下文无关文法"></a>递归构造上下文无关文法</h2><p>左递归：左侧非终结符出现在右侧第一个位置。<br>$A\rightarrow A a | a$<br>右递归：左侧非终结符出现在右侧最后一个位置<br>$A \rightarrow a A | a$</p>
<blockquote>
<p>表示$\alpha\beta^*\gamma$一样的语言：</p>
<p>1）$A\rightarrow B\gamma$ ,$B\rightarrow B\beta|\alpha$</p>
<p>2) $A\rightarrow \alpha B$ ,$B\rightarrow \beta B|\gamma$</p>
<p>3)$A\rightarrow\alpha B\gamma$,$B\rightarrow\beta B| \epsilon$</p>
</blockquote>
<hr>
<p>所有的正则语言都能被上下文无关文法表示。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/20/%E4%B8%80%E4%B8%AA%E8%A7%A3%E5%86%B3word%E9%A1%B5%E7%A0%81%E9%94%99%E4%B9%B1%E7%9A%84%E5%B0%8F%E6%96%B9%E6%B3%95/">一个解决word页码错乱的小方法</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-20
        </span><span class="post-visits"
             data-url="/2020/05/20/%E4%B8%80%E4%B8%AA%E8%A7%A3%E5%86%B3word%E9%A1%B5%E7%A0%81%E9%94%99%E4%B9%B1%E7%9A%84%E5%B0%8F%E6%96%B9%E6%B3%95/"
             data-title="一个解决word页码错乱的小方法">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>说实话，我常常因为word多此一举的方便用户而感到困扰。</p>
<p>比如拿到了一个页码错乱的文档模板，然后强迫症的我页码绝对不能错一个。</p>
<p>那么如果出现了这样恐怖的情况:文档页码在某一页开始一直往下都相同的话，其实是因为word看见的文档并不和你看见的一样，如果一个节没有结束的话，那么word就默认这一页还没有结束，可以理解为word看见的文档按照节来说实际上是一个不知道多长的羊皮卷。</p>
<p>通常如果出现页码相同的情况，可以双击页码并注意看导航栏里是否勾选了链接到前一节。我们看字面意思就能猜到，链接到前一节就指的是前后两个页面(不一定是你看到的页面，而是word认为的页面，总之）它们被绑定在一起了，修改一个另一个也会被更改。如果你发现勾选了这项的话，把它取消。我们不需要自作多情的链接。</p>
<p>但是还有一种情况是你发现链接到前一节没有被勾选，但页码也还是从某一页往下相同，那么就是因为word把”节“理解成了”页“，对于未完成的节，它是不会变换页码的。所以，你要做的就是告诉word这一页已经结束了。</p>
<p>那么具体的方法如下：</p>
<blockquote>
<p>1.光标移动到相同页面中的第一张的最末尾，点击布局-&gt; 分隔符，选择下一页，就会在该页插入分节符（下一页）</p>
<p>2.选中第二页的页码，就会发现此时会显示勾选了链接到前一节，取消它</p>
<p>3.正确地命名页码</p>
<p>4.如此往复直到问题解决</p>
</blockquote>
<p>不知道这个方法是不是正确，总之页码错乱问题是能够解决了，但是随之而来的是新的问题，自动目录并不能识别到对应的页码，还好自动页码可以手动改页码。</p>
<p>结尾也不知道要说我是该去学习一下Word呢，还是高喊”Latex真香“, 那就这样吧。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/05/02/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93-2/">【综述总结2】More Data,More Relations,More Context and More Openness:A Review and Outlook for Relation Extraction</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-05-02
        </span><span class="post-visits"
             data-url="/2020/05/02/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93-2/"
             data-title="【综述总结2】More Data,More Relations,More Context and More Openness:A Review and Outlook for Relation Extraction">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="行文结构"><a href="#行文结构" class="headerlink" title="行文结构"></a>行文结构</h2><p>先关注于现有的工作，按照模型分类，其次探讨了关系提取的更多方向，主要是从数据量、学习表现、场景、领域四个方面，恰好和题目呼应；最后提出了其他的挑战。</p>
<h3 id="Section-1-Introduction"><a href="#Section-1-Introduction" class="headerlink" title="Section 1 Introduction"></a>Section 1 Introduction</h3><p>RE: relation extraction</p>
<h3 id="Section-2-背景和现有的工作"><a href="#Section-2-背景和现有的工作" class="headerlink" title="Section 2 背景和现有的工作"></a>Section 2 背景和现有的工作</h3><h4 id="2-1-模式提取模型"><a href="#2-1-模式提取模型" class="headerlink" title="2.1 模式提取模型"></a>2.1 模式提取模型</h4><h4 id="2-2-统计关系提取模型"><a href="#2-2-统计关系提取模型" class="headerlink" title="2.2 统计关系提取模型"></a>2.2 统计关系提取模型</h4><h4 id="2-3-神经网络关系提取模型"><a href="#2-3-神经网络关系提取模型" class="headerlink" title="2.3 神经网络关系提取模型"></a>2.3 神经网络关系提取模型</h4><h3 id="Section-3-RE的更多方向"><a href="#Section-3-RE的更多方向" class="headerlink" title="Section 3 RE的更多方向"></a>Section 3 RE的更多方向</h3><h4 id="3-1-使用更多数据"><a href="#3-1-使用更多数据" class="headerlink" title="3.1 使用更多数据"></a>3.1 使用更多数据</h4><h4 id="3-2-学习表现更有效"><a href="#3-2-学习表现更有效" class="headerlink" title="3.2  学习表现更有效"></a>3.2  学习表现更有效</h4><h4 id="3-3-在更复杂的场景中实现"><a href="#3-3-在更复杂的场景中实现" class="headerlink" title="3.3 在更复杂的场景中实现"></a>3.3 在更复杂的场景中实现</h4><h4 id="3-4-面向更开放的领域"><a href="#3-4-面向更开放的领域" class="headerlink" title="3.4 面向更开放的领域"></a>3.4 面向更开放的领域</h4><h3 id="Section-4-其他挑战"><a href="#Section-4-其他挑战" class="headerlink" title="Section  4 其他挑战"></a>Section  4 其他挑战</h3><h4 id="4-1-从文本或实体名中学习"><a href="#4-1-从文本或实体名中学习" class="headerlink" title="4.1 从文本或实体名中学习"></a>4.1 从文本或实体名中学习</h4><h4 id="4-2关系提取数据集"><a href="#4-2关系提取数据集" class="headerlink" title="4.2关系提取数据集"></a>4.2关系提取数据集</h4>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/04/30/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93/">【综述总结1】Analysis Methods in Neural Language Processing:A Survey</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-04-30
        </span><span class="post-visits"
             data-url="/2020/04/30/%E7%BB%BC%E8%BF%B0%E6%80%BB%E7%BB%93/"
             data-title="【综述总结1】Analysis Methods in Neural Language Processing:A Survey">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="行文结构"><a href="#行文结构" class="headerlink" title="行文结构"></a>行文结构</h2><p>论文进行综述时很善于从多个维度对工作进行分类，比如使用的方法、语言现象等。（作者也输出了一张表格、通过不同的维度归纳了相关的工作）。整体来说是按照不同角度下的方法进行综述，比如有一章专门写了自然语言处理中的可视化方法和衡量的难度性。同时最后将所有本文的结论写在了结语。</p>
<h3 id="Section-1-Introduction"><a href="#Section-1-Introduction" class="headerlink" title="Section 1 Introduction"></a>Section 1 Introduction</h3><p>对全文脉络进行梳理</p>
<h3 id="Section-2-什么样的语言信息会被神经网络使用？"><a href="#Section-2-什么样的语言信息会被神经网络使用？" class="headerlink" title="Section 2 什么样的语言信息会被神经网络使用？"></a>Section 2 什么样的语言信息会被神经网络使用？</h3><p>阐述从三个方面回答这一问题（和小标题对应）：</p>
<ul>
<li>which method are used  使用什么方法</li>
<li>what kind of linguistic information is sought 什么信息</li>
<li>which objects in the neural network are being investigated  什么被观测</li>
</ul>
<h4 id="2-2-Linguistic-Phenomena"><a href="#2-2-Linguistic-Phenomena" class="headerlink" title="2.2 Linguistic Phenomena"></a>2.2 Linguistic Phenomena</h4><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>sentence length</td>
<td>句子长度</td>
<td></td>
</tr>
<tr>
<td>word position</td>
<td>单词位置</td>
<td></td>
</tr>
<tr>
<td>word presence</td>
<td>文字出现</td>
<td></td>
</tr>
<tr>
<td>simple word order</td>
<td>简单词序</td>
<td></td>
</tr>
<tr>
<td>morphological information</td>
<td>形态信息</td>
<td></td>
</tr>
<tr>
<td>syntactic information</td>
<td>句法信息</td>
<td></td>
</tr>
<tr>
<td>semantic information</td>
<td>语义信息</td>
<td></td>
</tr>
</tbody></table>
<p><a href="https://boknilev.github.io/nlp-analysis-methods/table2.html" target="_blank" rel="noopener">other phenomena</a></p>
<h3 id="Section-3-可视化方法和衡量可视化工作的难度性"><a href="#Section-3-可视化方法和衡量可视化工作的难度性" class="headerlink" title="Section 3 可视化方法和衡量可视化工作的难度性"></a>Section 3 可视化方法和衡量可视化工作的难度性</h3><h3 id="Section-4-用于细粒度评估的挑战集的编译"><a href="#Section-4-用于细粒度评估的挑战集的编译" class="headerlink" title="Section 4 用于细粒度评估的挑战集的编译"></a>Section 4 用于细粒度评估的挑战集的编译</h3><p>datasets used for evaluating neural network models that diverge from the common average case evaluatio</p>
<blockquote>
<p>分类数据集的依据：</p>
<ul>
<li>the task they seek to evaluate</li>
<li>the linguistic phenomena they aim to study</li>
<li>the language(s) they target</li>
<li>their size</li>
<li>their method of construction</li>
<li>how performance is evaluated</li>
</ul>
</blockquote>
<h3 id="Section-5-对抗性例子的产生和使用、神经网络的弱点"><a href="#Section-5-对抗性例子的产生和使用、神经网络的弱点" class="headerlink" title="Section 5 对抗性例子的产生和使用、神经网络的弱点"></a>Section 5 对抗性例子的产生和使用、神经网络的弱点</h3><h3 id="Section-6-解释模型预测的工作"><a href="#Section-6-解释模型预测的工作" class="headerlink" title="Section 6 解释模型预测的工作"></a>Section 6 解释模型预测的工作</h3><h3 id="Section-7-其他不归于上述主题的方法"><a href="#Section-7-其他不归于上述主题的方法" class="headerlink" title="Section 7 其他不归于上述主题的方法"></a>Section 7 其他不归于上述主题的方法</h3><h2 id="引用他人工作的句式"><a href="#引用他人工作的句式" class="headerlink" title="引用他人工作的句式"></a>引用他人工作的句式</h2><ul>
<li><p>see somebody for example</p>
</li>
<li><p>They found … suggesting that </p>
</li>
<li><p>In contrast,</p>
</li>
<li><p>Somebody <strong>made some headway on</strong> this question.</p>
</li>
<li><p>Somebody noted several key properties…</p>
</li>
<li><p>conducted behavioral experiments</p>
</li>
</ul>
<h2 id="其他句式"><a href="#其他句式" class="headerlink" title="其他句式"></a>其他句式</h2><ul>
<li><p>enable them to draw conclusions about…</p>
</li>
<li><p>synthesize a holistic picture from this diverse body of work</p>
</li>
<li><p>Another theme that emerges in several  studies is…</p>
</li>
<li><p>Much recent work has focused on …</p>
</li>
<li><p>… have gained renewed popularity in the NLP community.</p>
</li>
<li><p>Most of the relevant analysis work is concerned with…</p>
</li>
<li><p>Method … may shed new light on some of these questions.</p>
</li>
<li><p>A long tradition in work on (domain) is to …</p>
</li>
</ul>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/04/03/D3%E7%AC%94%E8%AE%B0/">D3笔记</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-04-03
        </span><span class="post-visits"
             data-url="/2020/04/03/D3%E7%AC%94%E8%AE%B0/"
             data-title="D3笔记">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>loading data onto the page</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">waitSeconds=<span class="function"><span class="params">numSeconds</span>=&gt;</span><span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="params">resolve</span>=&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">const</span> message=<span class="string">`<span class="subst">$&#123;numSeconds&#125;</span> seconds have passed!`</span>;</span><br><span class="line">    setTimeout(<span class="function"><span class="params">()</span>=&gt;</span>resolve(message),numSeconds*<span class="number">1000</span>);</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">waitSeconds(<span class="number">2</span>).then(<span class="function"><span class="params">message</span>=&gt;</span><span class="built_in">console</span>.log(message));</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结果：等待两秒后显示 2 seconds have passed!</p>
</blockquote>
<h2 id="ECMAScript-6-Features"><a href="#ECMAScript-6-Features" class="headerlink" title="ECMAScript 6 Features"></a>ECMAScript 6 Features</h2><h2 id="HTML-CSS-SVG"><a href="#HTML-CSS-SVG" class="headerlink" title="HTML CSS SVG"></a>HTML CSS SVG</h2><p>Scalable Vector Graph</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>&#123;select,arc&#125; <span class="keyword">from</span> <span class="string">'d3'</span></span><br></pre></td></tr></table></figure>



<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> width=+svg.attr(<span class="string">'width'</span>) <span class="comment">//string转换为float</span></span><br><span class="line"><span class="keyword">const</span> width=<span class="built_in">parseFloat</span>(svg.attr(<span class="string">'width'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> circle=svg.append(<span class="string">'circle'</span>)</span><br><span class="line">	.attr(<span class="string">'fill'</span>,<span class="string">'yellow'</span>) </span><br><span class="line">	.attr(<span class="string">'stroke'</span>,<span class="string">'black'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> g=svg.append(<span class="string">'g'</span>)</span><br><span class="line">	.attr(<span class="string">'transform'</span>,<span class="string">'translate($&#123;width/2&#125;,$&#123;height/2&#125;)'</span>);</span><br><span class="line"><span class="keyword">const</span> mouth=svg.append(<span class="string">'path'</span>)</span><br><span class="line">	.attr(<span class="string">'d'</span>,acr()(&#123;</span><br><span class="line">        innerRadius:<span class="number">80</span>,</span><br><span class="line">        outerRadius:<span class="number">100</span>,</span><br><span class="line">        startAngle:<span class="built_in">Math</span>.PI/<span class="number">2</span>,</span><br><span class="line">        endAngle:<span class="built_in">Math</span>,PI*<span class="number">3</span>/<span class="number">2</span></span><br><span class="line">    &#125;));</span><br></pre></td></tr></table></figure>

<h2 id="d3"><a href="#d3" class="headerlink" title="d3"></a>d3</h2><p>csv comma seperated value</p>
<h3 id="customizing-axis"><a href="#customizing-axis" class="headerlink" title="customizing  axis"></a>customizing  axis</h3><p>d3.format() 函数</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/03/31/hexo%E7%9A%84%E5%9D%91%E5%92%8C%E6%96%B0%E5%8D%9A%E5%AE%A2/">hexo的坑和新博客</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-03-31
        </span><span class="post-visits"
             data-url="/2020/03/31/hexo%E7%9A%84%E5%9D%91%E5%92%8C%E6%96%B0%E5%8D%9A%E5%AE%A2/"
             data-title="hexo的坑和新博客">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><h3 id="给一篇文章加多个tags"><a href="#给一篇文章加多个tags" class="headerlink" title="给一篇文章加多个tags"></a>给一篇文章加多个tags</h3><p>tags:[‘a’,’b’]</p>
<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
<h2 id="markdown"><a href="#markdown" class="headerlink" title="markdown"></a>markdown</h2><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>嵌入HTML代码，使用img标签：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"./xxx.png"</span> <span class="attr">width</span> = <span class="string">"300"</span> <span class="attr">height</span> = <span class="string">"200"</span> <span class="attr">alt</span>=<span class="string">"图片名称"</span> <span class="attr">align</span>=<span class="string">center</span> /&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>  <span class="attr">align</span>=<span class="string">"center"</span>&gt;</span>    </span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="文字"><a href="#文字" class="headerlink" title="文字"></a>文字</h2><h3 id="居中"><a href="#居中" class="headerlink" title="居中"></a>居中</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">i</span>&gt;</span> <span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br></pre></td></tr></table></figure>




        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/11/26/%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/">文档主题建模</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-11-26
        </span><span class="post-visits"
             data-url="/2019/11/26/%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/"
             data-title="文档主题建模">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>对于一篇文章来说，分析它的主题能够达到理解文本的效果。主题建模就是通过在文档集合里面学习、识别和提取主题的过程。对于一篇文章 或者说一个文档来说，它包含着多个主题，而如何去区分不同的主题，是通过主题下面包含的多个单词来进行分析，我们能够将文档转化为一个数值向量，每一个维度对应一个主题。</p>
<h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ul>
<li><strong>分类文档</strong> （比如说不同领域的新闻：科技、金融、体育新闻。通过对新闻的主题建模，能够将文本按照主题来归类）</li>
<li><strong>检索</strong>（当用户输入关键字的时候，就能够确认检索的文本的主题，从而在数据库进行匹配，最终返回相符的文本）</li>
</ul>
<h2 id="文本模型的可交换性"><a href="#文本模型的可交换性" class="headerlink" title="文本模型的可交换性"></a>文本模型的可交换性</h2><p>目前，大多数文本模型都基于“bag-of-words”的假设，即</p>
<ul>
<li>1.一篇文档内N个词之间的顺序可以随意互换，不影响建模过程</li>
<li>2.一个语料库内M个文档可以随意互换顺序，哪个文档在前哪个文档在后都无所谓。这两个性质合称为文本模型的可交换性</li>
</ul>
<h2 id="四种流行的用于主题建模的算法"><a href="#四种流行的用于主题建模的算法" class="headerlink" title="四种流行的用于主题建模的算法"></a>四种流行的用于主题建模的算法</h2><h3 id="1-LSA-Latent-semantic-analysis"><a href="#1-LSA-Latent-semantic-analysis" class="headerlink" title="1.LSA(Latent semantic analysis)"></a>1.LSA(Latent semantic analysis)</h3><p>LSA的核心思想就是将我们所拥有的文档-术语矩阵分解成相互独立的文档-主题矩阵和主题-术语矩阵。词和文档是用向量来表示的，通过向量之间的关系，来判断词与词之间 或者文档与文档之间的关系。</p>
<h3 id="2-pLSA"><a href="#2-pLSA" class="headerlink" title="2.pLSA"></a>2.pLSA</h3><p>pLSA，即概率潜在语义分析，采取概率方法替代 SVD 以解决问题。其核心思想是找到一个潜在主题的概率模型，该模型可以生成我们在文档-术语矩阵中观察到的数据。</p>
<h3 id="3-LDA"><a href="#3-LDA" class="headerlink" title="3.LDA"></a>3.LDA</h3><p>将狄利克雷视为「分布的分布」。本质上，它回答了这样一个问题：「给定某种分布，我看到的实际概率分布可能是什么样子？」</p>
<p>一篇文档，可以看成是一组有序的词的序列。从统计学角度来看，文档的生成可以看成是上帝抛掷骰子生成的结果，每一次抛掷骰子都生成一个词汇，抛掷N词生成一篇文档。在统计文本建模中，我们希望猜测出上帝是如何玩这个游戏的，这会涉及到两个最核心的问题：上帝都有什么样的骰子；上帝是如何抛掷这些骰子的；第一个问题就是表示模型中都有哪些参数，骰子的每一个面的概率都对应于模型中的参数；第二个问题就表示游戏规则是什么，上帝可能有各种不同类型的骰子，上帝可以按照一定的规则抛掷这些骰子从而产生词序列。</p>
<h3 id="4-lda2vec"><a href="#4-lda2vec" class="headerlink" title="4.lda2vec"></a>4.lda2vec</h3><p>社交媒体如微博、脸书上也会有大量值得研究的文本，这些文本规模大、更新速度更快而且语义信息不丰富、噪声高。传统的pLSA和LDA模型泛化能力弱、主题词可解释性差、分类准确性低。</p>
<p>文档向量表示随着word2vec模型的提出和深度学习的发展,近年来出现了很多相关研究成果。以LDA为代表的主题模型认为文档的生成是不同主题混合的结果;神经网络模型习惯于将文档表示为稠密向量。如果结合前者覆盖范围广和后者维度低的特点生成新的模型,可以做到快速检测,同对隐含语义的解释也会更好。lda2vec模型就是基于这一思想提出的。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/10/13/%E4%B8%80%E4%BB%BD%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/">一份不完全的数据可视化入门指南</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-10-13
        </span><span class="post-visits"
             data-url="/2019/10/13/%E4%B8%80%E4%BB%BD%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"
             data-title="一份不完全的数据可视化入门指南">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="1-如何快速上手数据可视化？"><a href="#1-如何快速上手数据可视化？" class="headerlink" title="1. 如何快速上手数据可视化？"></a>1. 如何快速上手数据可视化？</h2><p>1.【FreeCodeCamp】<a href="https://www.freecodecamp.cn/home" target="_blank" rel="noopener">https://www.freecodecamp.cn/home</a> (学习Html/Css/JavaScript)</p>
<p>2.【Echarts.js】<a href="https://www.echartsjs.com/zh/index.html" target="_blank" rel="noopener">https://www.echartsjs.com/zh/index.html</a></p>
<p>3.【D3】<a href="https://d3js.org/" target="_blank" rel="noopener">https://d3js.org/</a></p>
<p>4.【更多的工具总结】 <a href="https://zhuanlan.zhihu.com/p/24089938" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24089938</a></p>
<h2 id="2-有哪些值得借鉴的优秀的数据可视化设计作品？"><a href="#2-有哪些值得借鉴的优秀的数据可视化设计作品？" class="headerlink" title="2.有哪些值得借鉴的优秀的数据可视化设计作品？"></a>2.有哪些值得借鉴的优秀的数据可视化设计作品？</h2><p>【使用Tableau Public 制作的优秀作品】<a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">https://public.tableau.com/</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">zh-cn</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">/gallery/?</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">tab=</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">viz-of-the-day&amp;type</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">=</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">viz</a><a href="https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day" target="_blank" rel="noopener">-of-the-day</a></p>
<p>【使用Echarts制作的优秀作品】 <a href="https://gallery.echartsjs.com/explore.html" target="_blank" rel="noopener">https</a><a href="https://gallery.echartsjs.com/explore.html" target="_blank" rel="noopener">://</a><a href="https://gallery.echartsjs.com/explore.html" target="_blank" rel="noopener">gallery.echartsjs.com/explore.html#sort=rank<del>timeframe=all</del>author=all</a></p>
<p>【信息之美获奖作品】<a href="https://www.informationisbeautifulawards.com/" target="_blank" rel="noopener">https://www.informationisbeautifulawards.com/</a></p>
<p>【数据可视化领域的五大趋势】<a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc" target="_blank" rel="noopener">s?id</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc" target="_blank" rel="noopener">=1614710364563883354&amp;wfr=</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc" target="_blank" rel="noopener">spider&amp;for</a><a href="https://baijiahao.baidu.com/s?id=1614710364563883354&wfr=spider&for=pc" target="_blank" rel="noopener">=pc</a></p>
<p>【一位自由数据可视化设计师（ Nadieh Bremer ）的作品集】<a href="https://www.visualcinnamon.com/portfolio/" target="_blank" rel="noopener">https://www.visualcinnamon.com/portfolio/</a></p>
<h2 id="3-数据可视化的学术研究发展情况？"><a href="#3-数据可视化的学术研究发展情况？" class="headerlink" title="3.数据可视化的学术研究发展情况？"></a>3.数据可视化的学术研究发展情况？</h2><h3 id="CCF-A类会议-刊物"><a href="#CCF-A类会议-刊物" class="headerlink" title="CCF A类会议/刊物"></a>CCF A类会议/刊物</h3><p>【IEEE Visualization Conference (IEEE VIS)】<a href="http://dblp.uni-trier.de/db/conf/visualization/index.html" target="_blank" rel="noopener">http://dblp.uni-trier.de/db/conf/visualization/index.html</a></p>
<p>【IEEE Transactions on Visualization and Computer Graphics(TVCG)】 <a href="http://dblp.uni-trier.de/db/journals/tvcg/" target="_blank" rel="noopener">http://dblp.uni-trier.de/db/journals/tvcg/</a></p>
<p>【ACM Knowledge Discovery and Data Mining （SIGKDD）】<a href="http://dblp.uni-trier.de/db/conf/kdd/" target="_blank" rel="noopener">http://dblp.uni-trier.de/db/conf/kdd/</a></p>
<h3 id="国内的实验室-学者"><a href="#国内的实验室-学者" class="headerlink" title="国内的实验室/学者"></a><strong>国内的实验室/学者</strong></h3><p>【北京大学，袁晓如】 <a href="http://vis.pku.edu.cn/wiki/" target="_blank" rel="noopener">http://vis.pku.edu.cn/wiki/</a></p>
<p>【浙江大学，陈为】 <a href="http://www.cad.zju.edu.cn/home/vagblog/" target="_blank" rel="noopener">http://www.cad.zju.edu.cn/home/vagblog/</a></p>
<p>【同济大学，曹楠】<a href="http://www.nancao.org/" target="_blank" rel="noopener">http://www.nancao.org/</a></p>
<p>【清华大学，刘世霞】 <a href="http://www.shixialiu.com/" target="_blank" rel="noopener">http://www.shixialiu.com/</a></p>
<p>【四川大学，朱敏】 <a href="http://scuvis.org/" target="_blank" rel="noopener">http://scuvis.org/</a></p>
<h2 id="4-有哪些书籍可以进行学习？"><a href="#4-有哪些书籍可以进行学习？" class="headerlink" title="4.有哪些书籍可以进行学习？"></a>4.有哪些书籍可以进行学习？</h2><p>《Knowledge Is Beautiful》<a href="https://book.douban.com/subject/11650561/" target="_blank" rel="noopener">https://book.douban.com/subject/11650561/</a></p>
<p>《数据可视化》 <a href="https://book.douban.com/subject/25760272/" target="_blank" rel="noopener">https://book.douban.com/subject/25760272/</a></p>
<p>《数据可视化(40位数据设计师访谈录)》 <a href="https://book.douban.com/subject/27049704/" target="_blank" rel="noopener">https://book.douban.com/subject/27049704/</a></p>
<h2 id="5-相关的比赛？"><a href="#5-相关的比赛？" class="headerlink" title="5.相关的比赛？"></a>5.相关的比赛？</h2><p>【China Vis 挑战赛】 <a href="http://www.chinavis.org/2019/challenge.html" target="_blank" rel="noopener">http://www.chinavis.org/2019/challenge.html</a></p>
<p>【Kaggle】 <a href="http://kaggle.com/" target="_blank" rel="noopener">http://kaggle.com/</a></p>
<p>【天池大数据比赛】<a href="https://tianchi.aliyun.com/competition/gameList/activeList" target="_blank" rel="noopener">https://tianchi.aliyun.com/competition/gameList/activeList</a></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/10/11/git%E6%80%BB%E7%BB%93/">git总结</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-10-11
        </span><span class="post-visits"
             data-url="/2019/10/11/git%E6%80%BB%E7%BB%93/"
             data-title="git总结">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>最近不知为什么git desktop崩了，遂重新使用命令行，总结一下git的相关命令。 </p>
<h2 id="本地库管理"><a href="#本地库管理" class="headerlink" title="本地库管理"></a>本地库管理</h2><ol>
<li><p>切换到工作目录</p>
</li>
<li><p>将文件xxx（也可以添加文件夹）添加到仓库<br><code>git add xxx</code></p>
</li>
<li><p>将文件提交到仓库<br><code>git commit -m &quot;关于此次commit的描述&quot;</code></p>
</li>
<li><p>查看当前状态<br><code>git status</code></p>
</li>
<li><p>查看修改内容<br> <code>git diff</code></p>
</li>
<li><p>查看更新日志</p>
<p><code>git log</code></p>
</li>
</ol>
<h2 id="新建远程库"><a href="#新建远程库" class="headerlink" title="新建远程库"></a>新建远程库</h2><ol>
<li>在github上创建仓库</li>
<li>在本地创建文件夹作为本地仓库，在文件夹下使用命令行<br><code>git init</code>，使本地文件夹成为仓库</li>
<li>切换到工作目录并与本地的库关联<br><code>git remote add origin git@github.com:michaelliao/learngit.git</code></li>
<li><code>git pull origin branchxx</code>将远程仓库branchxx的内容下拉到本地库，branchxx一般是master或者main，在github网站的远程仓库页面可以找到</li>
<li>把本地库的内容推到远程库上（之后可以不用写-u)<br><code>git push -u origin master</code></li>
</ol>
<h2 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h2><p>当使用github协同工作，使用分支可以使工作更加整洁。</p>
<h3 id="切分支开发"><a href="#切分支开发" class="headerlink" title="切分支开发"></a>切分支开发</h3><p>git的分支可以看作指向当前结点的指针，HEAD指针始终指向文件的最新的地方。</p>
<p>分支的创建：<code>git branch branch1</code></p>
<p>分支的切换：<code>git checkout branch1</code></p>
<p>分支切换意味着，如果在该分支上产生的所有改动add或commit都将是在该分支下。</p>
<h3 id="分支的合并"><a href="#分支的合并" class="headerlink" title="分支的合并"></a>分支的合并</h3><h4 id="一、本地多个不同分支的合并"><a href="#一、本地多个不同分支的合并" class="headerlink" title="一、本地多个不同分支的合并"></a>一、本地多个不同分支的合并</h4><p>本地有多个分支时，在branch1分支下，使用<code>git merge branch2</code>就会将branch2合并到branch1分支。</p>
<h4 id="二、远程分支和本地分支的合并"><a href="#二、远程分支和本地分支的合并" class="headerlink" title="二、远程分支和本地分支的合并"></a>二、远程分支和本地分支的合并</h4><p><code>git pull</code>拉取远程分之后直接与本地分支进行合并，其作用相当于<code>git fetch</code>和<code>git merge</code></p>
<p>但是远程和本地合并时较长涉及到一致性的问题。</p>
<p><strong>1.如果本地分支已有未提交的修改，此时又需要pull，可使用如下命令：</strong></p>
<p>1）用<code>git add</code>将需要隐藏的文件保存在暂存区</p>
<p>2）隐藏本地分支工作：<code>git stash save &quot;message&quot;</code>  </p>
<p>3）执行<code>git pull</code>命令，将远程分支下拉下来，此时不会出现冲突情况</p>
<p>4）使用<code>git stash list</code>可查看有哪些stash。使用<code>git stash show stash@{num}</code>可以看到第num-1个stash了存储了那些内容,默认是0号存储。</p>
<p>5） 若要恢复原来的文件，可使用<code>git stash pop</code>命令恢复。该命令会将缓存堆栈中的对应stash删除，并将对应修改应用到当前的工作目录下,默认为第一个stash。</p>
<p>6）若隐藏的文件可丢弃，则可使用<code>git stash drop stash@{$num}</code>丢弃该文件的内容。</p>
<p>注意，使用<code>git stash</code>后，暂存区的所有文件都会被隐藏，意味着如果再次进行<code>git add</code> 暂存区是不会有东西的，使用<code>git commit</code>也是无法提交更新的，只有恢复后才能解除文件的隐藏。</p>
<h4 id="三、某个分支的diverged"><a href="#三、某个分支的diverged" class="headerlink" title="三、某个分支的diverged"></a>三、某个分支的diverged</h4><p>当出现了<code>Your branch and origin/master have diverged,and have...different commits each respectively</code></p>
<p>此时可使用<code>git rebase origin/master</code>将分叉的分支重新合并。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/">关于人工智能，最近想谈的一些东西</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-09-22
        </span><span class="post-visits"
             data-url="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/"
             data-title="关于人工智能，最近想谈的一些东西">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>最近终于把郝景芳《人之彼岸》书后面的小科普看完并且做完了思维导图，把这个拖了太久的事情结束是因为人工智能导论课的一次作业：“人工智能是否会超越人的智力？”，下面是正文：</p>
<p>人工智能是否会超越人的智力？我的答案是有可能，不过目前还有很多挑战。<br>首先，这一问题将比较限定在了人的智力，更准确地说，就是人认识、理解事物并且运用知识、经验等解决问题的能力。此处不探讨人工智能是否会拥有人的情感、人的意识或是人的欲望，仅仅从“解决问题的能力”这一层面来探讨人工智能的“智力有没有可能超越人类。<br>人工智能的研究和发展目的之一，就是因为人工智能可以借由计算机来模拟人的思考和行动，让计算机能够辅助甚至代替人类完成一系列复杂的工作。因此，目前的人工智能，可以说在某些特定的领域，已经超越了人的智力。就拿AlphaGo获胜的棋局来说，可以说在围棋这一领域，人工智能已经超越了人的智力。<br>除了围棋，在语言翻译、语音识别、图像检测等诸多方面，人工智能都可以说是超越了人的智力。但承认人工智能在单个领域上的卓越性，并不等于我们认同人工智能完全超越了人的智力。<br>且不说人工智能还没有应用完任何一个微小的分支领域，即使存在那么一个时间结点，人工智能在任何一个可以应用的小分支下都能够比人类完成得更高效、更好，在那时，人工智能也只是将在这些领域中的“经验”进行叠加。如果没有综合将多个领域的结果产生出创造性的洞见，那么人工智能也仅仅只是一个有强大思考和计算能力的机器罢了，它无法拥有人类的智力。<br>人的思考过程并不只是多个领域结果的简单叠加，我们的智力不是单一的分辨图像，翻译句子或是解数学题，我们的智力高明在我们能够以我们的一切认识作为输入，输出一个非常复杂的结果。换句话说，我们能够综合地考虑问题，触类旁通，从多个角度去思考问题，而不是割裂地分解每个子问题，得到每一个答案。<br>我们能够基于我们的常识，即使只知道一个线索，通过想象、推测出整个事件。我们能够根据我们的世界观，和一系列我们意识到或者没有意识到的规则，对某件事情进行决策。我们的智力在于“综合”，而这种综合，目前还没有人工智能能够做到。如果人工智能想要拥有超越人类的智力，那么它们至少需要大量的数据集，能够将整个世界的规则、机制全部都输入来训练。<br> 上述提到的“综合的能力”，可以认为是一种需要靠智商的思考，但除此之外，人类的智力还运用在生活的方方面面，甚至在我们没有意识的情况下，就已经被使用到了。 通常，这种智力也被称为“快思考”，它们被本能驱动，但同样是由大脑的相互配合而完成的，也因此人产生了感知、情绪、情感等。而这种类型的智力，人工智能超越人类的难度要更大。<br>另外，人还具有创造力（这是否算是一种智力）。在审美和艺术上，就算我们让人工智能学习绘画、写诗、写文章，那并不是真正的创造力，只是在既定的输入下精准的模仿。人类创作的艺术品通常都会被人的经历、性格、周遭发生的事情所影响，而人工智能因为常识体系没有构建，没有自己的世界观，也没有自己的意识、情感，它们的艺术作品仍然是缺乏灵魂的。如果想要让人工智能具有这一类型的智力，那么绕不开的还是得先实现“综合”能力，注入意识，将人工智能铸造得几乎和一个人类没有什么区别才有可能实现这种类型的创作。<br>不过，如果以上所说，未来的人工智能都完美地实现了，那时人工智能会因为其强大的计算性和极高的效率而能够轻易地掌握人类所拥有的能力，在和人类的竞赛中成为永远的胜者，甚至发现了人类从未发现的规律和捷径，那时人工智能才算是真正超越了人类。<br>当然，如果它们不存在感情、不存在个人意志，也无法超越人类，也不会对人类有什么威胁。而反过来想，作为人类的我们其实是一个比目前的人工智能神奇和有智慧千百倍的生物。我们有思想、有感情、具有创造力，虽然我们也没有那么理性，在但我觉得那也是作为人的骄傲，是我们的生气之所在。<br> 当然我的观点也借鉴了郝景芳的那两篇科普文章，如果想了解可以先看看思维导图，或者直接找原文来看。</p>
<p><img src="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/%E7%A6%BB%E8%B6%85%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%88%B0%E6%9D%A5%E8%BF%98%E6%9C%89%E5%A4%9A%E8%BF%9C.png" alt="离超级人工智能到来还有多远"></p>
<p><img src="/2019/09/22/%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%8C%E6%9C%80%E8%BF%91%E6%83%B3%E8%B0%88%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3%E5%BA%94%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%EF%BC%9F.png" alt="人工智能时代应如何学习？"></p>
<p>从大一开始，我的周围很多人都在学人工智能，不过彼时它还没有很吸引我。我对人工智能最初的印象是高中的时候，因为AlphaGo写过一篇关于人工智能的议论文，那时我也是第一次知道“深度学习”。（哎想想当时的我也根本不知道那些看起来无足轻重的词汇会在未来的日子支配我的时间）上了大学以后写过一些人工智能的短篇小说和小段落，不过也都是没有理论支撑的软科幻罢了。<br>等到上学期选了机器学习的课，才稍微开始入了门，这学期也选了深度学习引论和人工智能导论两个选修。虽然我没读过几篇论文，网络也没跑过，但是我隐隐地感觉这是更加激动人心的事情。幸好我现在确实可以像一句话说的那样“做组里来无影去无踪的本科生”，真正的参与一点点事情，更多的是看到新的东西。<br>如果真的做不出什么成绩也无所谓，我只希望回忆起来的时候，我会觉得幸好那时学会了那么有意思的东西。那就已经够好了。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/09/09/2019%E5%B7%9D%E5%A4%A7%E6%96%B0%E7%94%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%88python-wordcloud-echarts%EF%BC%89/">2019川大新生数据可视化（python wordcloud + echarts）</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-09-09
        </span><span class="post-visits"
             data-url="/2019/09/09/2019%E5%B7%9D%E5%A4%A7%E6%96%B0%E7%94%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%88python-wordcloud-echarts%EF%BC%89/"
             data-title="2019川大新生数据可视化（python wordcloud + echarts）">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>8月底和同学一起为川大新生制作了一个新生数据可视化的<a href="https://mp.weixin.qq.com/s?__biz=MzA5Mzc2MDYxMw==&mid=2650063145&idx=1&sn=3516ccd3dcac87558debbd942c3ead1d&chksm=88589c23bf2f1535b19bc75f306d37682868670959df835e8e5c67bbc4adaeec278465b3c6f8&mpshare=1&scene=24&srcid=&sharer_sharetime=1567422683641&sharer_shareid=a49052cb76c97bd4594f8f49e94ec7ca#rd" target="_blank" rel="noopener">推送</a>。这篇推送中插入的图片，主要使用了python的wordcloud制作词云，用echarts中的一些图表。这篇博客主要会记录一下我制作的部分。</p>
<h1 id="一、wordcloud制作姓名词云"><a href="#一、wordcloud制作姓名词云" class="headerlink" title="一、wordcloud制作姓名词云"></a>一、wordcloud制作姓名词云</h1><h2 id="1-Anaconda下安装wordcloud模块"><a href="#1-Anaconda下安装wordcloud模块" class="headerlink" title="1.Anaconda下安装wordcloud模块"></a>1.Anaconda下安装wordcloud模块</h2><p>如果没有安装wordcloud，可以在<a href="https://pypi.org/project/wordcloud/#files" target="_blank" rel="noopener">官网</a>下载whl文件。下载好文件后，使用Anconda命令行，切到whl所在的文件目录，输入命令行：<code>pip install wordcloud-1.5.0-cp36-cp36m-win_amd64.whl</code>，然后安装成功后就可导入该模块了。<br><img src="https://img-blog.csdnimg.cn/20190908103647749.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="安装成功wordcloud"></p>
<h2 id="2-导入模块"><a href="#2-导入模块" class="headerlink" title="2.导入模块"></a>2.导入模块</h2><p>要制作词云，主要需导入wordcloud,matplotlib这两个模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="comment">#导入wordcloud模块和matplotlib模块</span></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud,ImageColorGenerator,STOPWORDS</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> chardet</span><br></pre></td></tr></table></figure>
<h2 id="3-处理数据"><a href="#3-处理数据" class="headerlink" title="3. 处理数据"></a>3. 处理数据</h2><p>由于当时得到的excel表格中，学生包括新疆、西藏等民族，姓名不是普通的姓+名的结构，给姓名的处理带来了一定困难。因此没有统计他们的姓氏。当时不了解python也可以处理excel，于是是将姓名按行存入一个txt文件，再通过python进行处理。</p>
<h3 id="1）-处理名字"><a href="#1）-处理名字" class="headerlink" title="1） 处理名字"></a>1） 处理名字</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取原始的姓名txt文件</span></span><br><span class="line">fileObj = open(<span class="string">'name4.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8-sig'</span>)</span><br><span class="line">ming=[]</span><br><span class="line"><span class="comment">#按行读取,姓名是三个字的同学的姓删除</span></span><br><span class="line">line=fileObj.readline()</span><br><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">if</span> (len(line)&lt;=<span class="number">4</span> <span class="keyword">and</span> len(line)&gt;<span class="number">0</span>):</span><br><span class="line">        line=line.replace(line[<span class="number">0</span>],<span class="string">""</span>)</span><br><span class="line">    ming.append(line)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">m=<span class="string">""</span>.join(ming)</span><br><span class="line">print(ming)</span><br><span class="line">fileObj2 = open(<span class="string">'ming.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">fileObj2.write(m)</span><br><span class="line">fileObj2.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 姓名全部以单字形式排列，并存入新的文档</span></span><br><span class="line">name=open(<span class="string">'ming.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line">name=name.replace(<span class="string">'·'</span>,<span class="string">''</span>)</span><br><span class="line">name=name.replace(<span class="string">'\n'</span>,<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">result=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> name:</span><br><span class="line">    result.append(i)</span><br><span class="line">    result.append(<span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line">s = <span class="string">""</span>.join(result) <span class="comment">#列表转字符串</span></span><br><span class="line"></span><br><span class="line">save = open(<span class="string">'name7.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">save.write(s)</span><br><span class="line">save.close()</span><br></pre></td></tr></table></figure>

<p>得到处理的结果：<br><img src="https://img-blog.csdnimg.cn/2019090919322293.png" alt="名处理结果"></p>
<h3 id="2）处理姓氏"><a href="#2）处理姓氏" class="headerlink" title="2）处理姓氏"></a>2）处理姓氏</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 姓</span></span><br><span class="line"></span><br><span class="line">fileObj = open(<span class="string">'name4.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8-sig'</span>)</span><br><span class="line">surname=[]</span><br><span class="line">line=fileObj.readline()</span><br><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">if</span> (len(line)&lt;=<span class="number">4</span> <span class="keyword">and</span> len(line)&gt;<span class="number">0</span>):</span><br><span class="line">        surname.append(line[<span class="number">0</span>])</span><br><span class="line">        surname.append(<span class="string">" "</span>)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">sur=<span class="string">""</span>.join(surname)</span><br><span class="line">print(surname)</span><br><span class="line">fileObj2 = open(<span class="string">'surname.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">fileObj2.write(sur)</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure>
<p>得到处理的结果：<br><img src="https://img-blog.csdnimg.cn/20190909193128546.png" alt="姓处理结果"></p>
<h2 id="4-生成词云"><a href="#4-生成词云" class="headerlink" title="4.生成词云"></a>4.生成词云</h2><p>处理完名和姓的结果后，就可以使用wordcloud函数来绘制词云。当时遇到了一个问题就是词云只能生成两个字及以上的词云，对于单个字会认为这不是一个词。解决办法是修改参数中的regexp（正则表达式）有<code>regexp=r&quot;\w[\w&#39;]*&quot;</code>，这样wordcloud就会将单字也认为是词，从而生成字云。<br>除此之外还使用到了以下几个参数：</p>
<blockquote>
<p>mask：设置为pic是为了让生成的词云具有图片的形状。#FFFFFF是不会显示字的，因此如果画面背景不是纯白也会显示字。<br>prefer_horizontal： 这个属性是让竖直的字的出现概率为1，因此词云的所有字都是竖直排列的，可读性会更强。<br>background_color=None和mode=’RGBA’ ：这两个一起设置，能够让图片的背景是透明的。（这里主要是需要和美工交接，让她帮忙上一个底色）<br>stopwords：停止词，因为处理数据是先生成了姓，因此当时考虑将姓作为停止词（也就是不会出现在词云上），但鉴于有些姓同样会出现在名字中，会影响准确性，因此并没有这样做。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读入处理过的姓名文件</span></span><br><span class="line">text2= open(<span class="string">'name7.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"><span class="comment">#读入背景图片</span></span><br><span class="line">pic = imread(<span class="string">'panda16.png'</span>)</span><br><span class="line"><span class="comment">#生成词云</span></span><br><span class="line">cloud = WordCloud(mask=pic,prefer_horizontal=<span class="number">1</span>,<span class="comment">#width=800,height=800,</span></span><br><span class="line">                  font_path=<span class="string">'C:\\Windows\\Fonts\\Nk728iWCZ.TTF'</span>,</span><br><span class="line">                  background_color=<span class="literal">None</span>,scale=<span class="number">5</span>,regexp=<span class="string">r"\w[\w']*"</span>,</span><br><span class="line">                  max_font_size = <span class="number">100</span>,mode=<span class="string">'RGBA'</span>) <span class="comment">#,stopwords=stop)</span></span><br><span class="line">cloud.generate(text2)</span><br><span class="line">image_colors = ImageColorGenerator(pic)</span><br><span class="line">cloud.recolor(color_func=image_colors)</span><br><span class="line"><span class="comment">#显示词云图片</span></span><br><span class="line">plt.imshow(cloud)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#保存图片</span></span><br><span class="line">cloud.to_file(<span class="string">'test26.png'</span>)</span><br></pre></td></tr></table></figure>

<p>最后生成的词云如下：<br><img src="https://img-blog.csdnimg.cn/20190909195400163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="姓氏"><br><img src="https://img-blog.csdnimg.cn/20190909195440150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="名字"></p>
<h1 id="二、用Python处理数据"><a href="#二、用Python处理数据" class="headerlink" title="二、用Python处理数据"></a>二、用Python处理数据</h1><p>除了用python处理词云之外，python还用于处理一些数据，比如将数据从excel格式调成json格式(便于echarts使用）。当然，当时我python处理excel文件还不太熟，因此整个处理数据（包括年龄、星座等制作后面的表格时使用到的数据）的步骤可以归纳为以下的几点：<br>1.在excel中用数据透视表进行统计，然后将得到的结果以txt文本保存。<br>2.在notepad进行简单的查找替换，将文件编码设置为utf-8。<br>3.转化为json数组时通过python读取txt文件，然后对其进行相应的处理，得到符合要求的json数组。<br>（当然后续知道可以直接在excel中转json，不过写数据处理的代码也算是让我更熟悉了python)</p>
<p>这里放部分的代码：</p>
<h3 id="1-处理日期"><a href="#1-处理日期" class="headerlink" title="1) 处理日期"></a>1) 处理日期</h3><p>因为生日的日期有多种格式（斜杠、全数值、横杠），为了让他们格式相同，所以进行了处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    <span class="keyword">if</span>(line.find(<span class="string">'/'</span>)&gt;=<span class="number">0</span>):</span><br><span class="line">        print(line)</span><br><span class="line">        line=line.replace(<span class="string">'/'</span>,<span class="string">'-'</span>)</span><br><span class="line">        fileObj2.write(line)   </span><br><span class="line">    <span class="keyword">elif</span>(line.find(<span class="string">'-'</span>)&lt;<span class="number">0</span>):</span><br><span class="line">        line_list=[]</span><br><span class="line">        line_list=list(line)</span><br><span class="line">        line_list.insert(<span class="number">4</span>,<span class="string">'-'</span>)</span><br><span class="line">        print(line_list)</span><br><span class="line">        line_list.insert(<span class="number">7</span>,<span class="string">'-'</span>)</span><br><span class="line">        print(line_list)</span><br><span class="line">        newline=<span class="string">""</span>.join(line_list)</span><br><span class="line">        print(newline)</span><br><span class="line">        fileObj2.write(newline) </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fileObj2.write(line)</span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure>
<h3 id="2）其他数据转换成json数组"><a href="#2）其他数据转换成json数组" class="headerlink" title="2）其他数据转换成json数组"></a>2）其他数据转换成json数组</h3><p>这是用来生成桑基图中的links中的数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> line:   </span><br><span class="line">    index=line.find(<span class="string">'\n'</span>)</span><br><span class="line">    blank=line.find(<span class="string">' '</span>)</span><br><span class="line">    line_list = list(line)</span><br><span class="line">    line_list.insert(index+<span class="number">1</span>,<span class="string">"&#125;,"</span>)</span><br><span class="line">    line_list.insert(<span class="number">0</span>,<span class="string">"&#123; 'name':'"</span>)</span><br><span class="line">    line_list.insert(blank+<span class="number">2</span>,<span class="string">"',\n"</span>)</span><br><span class="line">    line_list.insert(blank+<span class="number">3</span>,<span class="string">"value:"</span>)</span><br><span class="line">    </span><br><span class="line">    print(line_list)</span><br><span class="line">    <span class="comment">#转回字符串</span></span><br><span class="line">    newline=<span class="string">''</span>.join(line_list)</span><br><span class="line">    print(newline)</span><br><span class="line">    fileObj2.write(newline) </span><br><span class="line">    line=fileObj.readline()</span><br><span class="line">fileObj2.close()</span><br></pre></td></tr></table></figure>

<h1 id="三、echarts制作其他图表"><a href="#三、echarts制作其他图表" class="headerlink" title="三、echarts制作其他图表"></a>三、echarts制作其他图表</h1><h2 id="1-矩形树图-Treemap-制作专业人数分布图"><a href="#1-矩形树图-Treemap-制作专业人数分布图" class="headerlink" title="1.矩形树图(Treemap)制作专业人数分布图"></a>1.矩形树图(Treemap)制作专业人数分布图</h2><p>在这张图中，主要通过矩形的大小来映射专业的人数多少。图片的尺寸考虑到看推送的清晰度问题，因此设置得较长。<br><img src="https://img-blog.csdnimg.cn/20190908105527724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="矩形树图"><br>在做的时候，遇到的问题主要是字体不能够换行以及调整字体大小的问题。<br>解决办法是用：series-&gt;upperLable-&gt;normal加入<code>formatter: &#39;{b}&#39;,</code>，然后通过data中的name进行换行处理（由于矩形树图的特殊性，为了让排版更好看，手动对每一个需要换行的name进行了换行）。</p>
<p>series-&gt;levels中的两个元素分别表示的是学院层和学院下的专业层的不同设置。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> myChart = echarts.init(<span class="built_in">document</span>.getElementById(<span class="string">'treemap'</span>));</span><br><span class="line">option = &#123;</span><br><span class="line">    series: [&#123;</span><br><span class="line">        type: <span class="string">'treemap'</span>,</span><br><span class="line">        data: [</span><br><span class="line">            &#123;</span><br><span class="line">                name: <span class="string">'材料科学与工程学院'</span>,          </span><br><span class="line">                value: xxx,</span><br><span class="line">                children: [&#123;</span><br><span class="line">                    name: <span class="string">'材料类'</span>, </span><br><span class="line">                    value: xx,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line">                    name: <span class="string">'生物医学工程'</span>,        </span><br><span class="line">                    value: xx</span><br><span class="line">                &#125;]</span><br><span class="line">                <span class="comment">//每一个学院下的专业</span></span><br><span class="line">            &#125;,</span><br><span class="line">        ],</span><br><span class="line">        upperLabel:&#123;</span><br><span class="line">            normal:&#123;</span><br><span class="line">                ellipsis:<span class="literal">false</span>,</span><br><span class="line">                color: <span class="string">'#555'</span>,</span><br><span class="line">                show:<span class="literal">true</span>,</span><br><span class="line">                fontSize:<span class="number">10</span>,</span><br><span class="line">                fontWeight:<span class="string">'bold'</span>,</span><br><span class="line">                formatter: <span class="string">'&#123;b&#125;'</span>,</span><br><span class="line">                backgroundColor:<span class="string">'#e6eae3'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        levels:[</span><br><span class="line">            &#123;</span><br><span class="line">                color:[<span class="string">'#5bbdc8'</span>,<span class="string">'#83ccd2'</span>,<span class="string">'#7ebea5'</span>,<span class="string">'#ffefa1'</span>],</span><br><span class="line">                itemStyle: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        borderColor:<span class="string">'#e6eae3'</span>,</span><br><span class="line">                        borderWidth: <span class="number">6</span>,</span><br><span class="line">                        gapWidth: <span class="number">5</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                itemStyle: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        borderColor:<span class="string">'#e6eae3'</span>,</span><br><span class="line">                        borderWidth: <span class="number">4</span>,</span><br><span class="line">                        gapWidth: <span class="number">1</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        ],</span><br><span class="line">        label:&#123;</span><br><span class="line">            position:<span class="string">'insideLeft'</span>,</span><br><span class="line">            ellipsis:<span class="literal">false</span>,</span><br><span class="line">            color: <span class="string">'#555'</span>,</span><br><span class="line">            fontWeight:<span class="string">'bold'</span>,</span><br><span class="line">            fontSize:<span class="number">13</span>,</span><br><span class="line">            formatter:<span class="string">'&#123;b&#125;'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;]</span><br><span class="line">&#125;;</span><br><span class="line">myChart.setOption(option);</span><br></pre></td></tr></table></figure>

<h2 id="2-桑基图-Sankey-制作年龄流动图"><a href="#2-桑基图-Sankey-制作年龄流动图" class="headerlink" title="2.桑基图(Sankey)制作年龄流动图"></a>2.桑基图(Sankey)制作年龄流动图</h2><p><img src="https://img-blog.csdnimg.cn/20190909191646223.gif" alt="桑基图"></p>
<p>从桑基图中，能够看到不同年龄占男女生总人数的比例，以及占学院总人数的比例。<br>在制作桑基图时，主要遇到的问题是：年龄最小/大的人数过少，表现在echarts的图表中就会发现根本无法选中和显示出来，为了解决这个问题，将series-&gt;data-&gt;itemStyle-&gt;borderWidth中的数值改大（即增大边框宽度），这样就能够正常显示和交互了。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">option = &#123;</span><br><span class="line">    series: &#123;</span><br><span class="line">        type: <span class="string">'sankey'</span>,</span><br><span class="line">        layout: <span class="string">'none'</span>,</span><br><span class="line">        layoutIterations: <span class="number">0</span>,</span><br><span class="line">        nodeWidth: <span class="number">30</span>,</span><br><span class="line">        nodeGap: <span class="number">10</span>,</span><br><span class="line">        height: <span class="number">300</span>,</span><br><span class="line">        focusNodeAdjacency: <span class="string">'allEdges'</span>,</span><br><span class="line">        orient: <span class="string">'vertical'</span>,</span><br><span class="line">        label: &#123;</span><br><span class="line">            show: <span class="literal">true</span>,</span><br><span class="line">            position: <span class="string">'bottom'</span>,</span><br><span class="line">            <span class="comment">//[-10,60],</span></span><br><span class="line">            formatter: <span class="function"><span class="keyword">function</span>(<span class="params">val</span>) </span>&#123;</span><br><span class="line">                <span class="comment">//x轴的文字改为竖版显示</span></span><br><span class="line">                <span class="keyword">var</span> str = val.name.split(<span class="string">""</span>);</span><br><span class="line">                <span class="keyword">return</span> str.join(<span class="string">"\n"</span>);</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        data: [&#123;</span><br><span class="line">            name: <span class="string">'14岁'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#e95295'</span>,</span><br><span class="line">                borderWidth: <span class="number">6</span>,</span><br><span class="line">                borderColor: <span class="string">'#e95295'</span>,</span><br><span class="line">                opacity: <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">//其余每一个年龄除了color的设置之外，其他都是相同的</span></span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'材料科学与工程学院'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">                borderWidth: <span class="number">0</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">//其他所有学院的格式都如上所示</span></span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'男'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            name: <span class="string">'女'</span>,</span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                color: <span class="string">'#595857'</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;],</span><br><span class="line">        </span><br><span class="line">        links: [&#123;</span><br><span class="line">            source: <span class="string">'男'</span>,</span><br><span class="line">            target: <span class="string">'15岁'</span>,</span><br><span class="line">            value: <span class="number">7</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">/*...</span></span><br><span class="line"><span class="comment">        男和女两种性别和到每一个年龄的所有link</span></span><br><span class="line"><span class="comment">        此处不公开数据*/</span></span><br><span class="line">        &#123;</span><br><span class="line">            source: <span class="string">'15岁'</span>,</span><br><span class="line">            target: <span class="string">'材料科学与工程学院'</span>,</span><br><span class="line">            value: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">          <span class="comment">/*...</span></span><br><span class="line"><span class="comment">          每一个年龄流动到每一个学院的所有link</span></span><br><span class="line"><span class="comment">        此处不公开数据*/</span></span><br><span class="line">        ],</span><br><span class="line">        lineStyle: &#123;</span><br><span class="line">            normal: &#123;</span><br><span class="line">                color: <span class="string">'source'</span>,</span><br><span class="line">                curveness: <span class="number">0.75</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 使用刚指定的配置项和数据显示图表。</span></span><br><span class="line">myChart.setOption(option);</span><br></pre></td></tr></table></figure>

<h2 id="3-柱状图制作男女比例图"><a href="#3-柱状图制作男女比例图" class="headerlink" title="3.柱状图制作男女比例图"></a>3.柱状图制作男女比例图</h2><p><img src="https://img-blog.csdnimg.cn/20190908105606347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1cnVvdGluZ19jbGFpcmU=,size_16,color_FFFFFF,t_70" alt="男女比例图"><br>柱状图制作的比较顺利。右侧的数值可以通过设置两个y轴来解决。另外，圆角的柱状图可以在series-&gt;itemStyle-&gt;barBorderRadius中设置圆角的半径。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> myChart = echarts.init(<span class="built_in">document</span>.getElementById(<span class="string">'gendermap'</span>));</span><br><span class="line"></span><br><span class="line">option = &#123;</span><br><span class="line">    backgroundColor: <span class="string">'#fff'</span>,</span><br><span class="line">    tooltip: &#123;</span><br><span class="line">        trigger: <span class="string">'axis'</span>,</span><br><span class="line">        axisPointer: &#123;<span class="comment">// 坐标轴指示器，坐标轴触发有效</span></span><br><span class="line">            type: <span class="string">'shadow'</span>        </span><br><span class="line">            <span class="comment">// 默认为直线，可选为：'line'或'shadow'</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    legend: &#123;</span><br><span class="line">        data: [<span class="string">'男生'</span>, <span class="string">'女生'</span>],</span><br><span class="line">    &#125;,</span><br><span class="line">    grid: &#123;</span><br><span class="line">        left: <span class="string">'3%'</span>,</span><br><span class="line">        right: <span class="string">'4%'</span>,</span><br><span class="line">        bottom: <span class="string">'3%'</span>,</span><br><span class="line">        containLabel: <span class="literal">true</span></span><br><span class="line">    &#125;,</span><br><span class="line">    yAxis: [</span><br><span class="line">        &#123;</span><br><span class="line">            type: <span class="string">'category'</span>,</span><br><span class="line">            data: [<span class="string">'外国语学院'</span>,</span><br><span class="line">                <span class="string">'文学与新闻学院'</span>,</span><br><span class="line">                ...],</span><br><span class="line">                <span class="comment">/*这里存储的是图中左侧显示的每一个学院</span></span><br><span class="line"><span class="comment">                为了减少篇幅就不写完了*/</span></span><br><span class="line">            splitLine: &#123;</span><br><span class="line">                show: <span class="literal">true</span>,</span><br><span class="line">                ineStyle:&#123;<span class="attr">type</span>:<span class="string">'dashed'</span>&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">            axisLine: &#123;</span><br><span class="line">                lineStyle: &#123;</span><br><span class="line">                    color: <span class="string">'#000'</span>,</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            axisLabel: &#123;</span><br><span class="line">                color: <span class="string">'#000'</span>,</span><br><span class="line">                fontSize:<span class="number">15</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            type: <span class="string">'category'</span>,</span><br><span class="line">            data: [<span class="string">'0.24:1'</span>,...],</span><br><span class="line">            <span class="comment">/*这里存储的是图中右边显示的所有的比例（用字符串存储）</span></span><br><span class="line"><span class="comment">            为了减少篇幅就不写完了*/</span></span><br><span class="line">            text:<span class="string">'男女比'</span>,</span><br><span class="line">            splitLine: &#123;</span><br><span class="line">                show: <span class="literal">false</span></span><br><span class="line">            &#125;,</span><br><span class="line">            axisLine: &#123;</span><br><span class="line">                lineStyle: &#123;</span><br><span class="line">                    color: <span class="string">'#000'</span>,</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            axisLabel: &#123;</span><br><span class="line">                color: <span class="string">'#000'</span>,</span><br><span class="line">                fontSize:<span class="number">15</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    ],</span><br><span class="line">    xAxis: [</span><br><span class="line">        &#123;</span><br><span class="line">            show: <span class="literal">false</span>,</span><br><span class="line">            type: <span class="string">'value'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    series : [</span><br><span class="line">        &#123;</span><br><span class="line">            name:<span class="string">'女生'</span>,</span><br><span class="line">            type:<span class="string">'bar'</span>,</span><br><span class="line">            stack: <span class="string">'总量'</span>,</span><br><span class="line">            data:[],</span><br><span class="line">            <span class="comment">/*这里的data包括每一个学院的女生的数量</span></span><br><span class="line"><span class="comment">            此处就不公开该数据了*/</span></span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                barBorderRadius: <span class="number">20</span>,</span><br><span class="line">                <span class="comment">//设置柱形的圆角，可以设置该半径</span></span><br><span class="line">                color: <span class="keyword">new</span> echarts.graphic.LinearGradient(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, [&#123;</span><br><span class="line">                    offset: <span class="number">0.4</span>,</span><br><span class="line">                    color: <span class="string">"#ffefa1"</span></span><br><span class="line">                &#125;,</span><br><span class="line"></span><br><span class="line">                ])</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            name:<span class="string">'男生'</span>,</span><br><span class="line">            type:<span class="string">'bar'</span>,</span><br><span class="line">            stack: <span class="string">'总量'</span>,</span><br><span class="line">            data:[],</span><br><span class="line">            <span class="comment">/*这里的data包括每一个学院的男生的数量</span></span><br><span class="line"><span class="comment">            需要将数量取成负数</span></span><br><span class="line"><span class="comment">            这样能够让男女数量分布在坐标轴的两边（中轴对齐）*/</span></span><br><span class="line">            itemStyle: &#123;</span><br><span class="line">                barBorderRadius: <span class="number">20</span>,</span><br><span class="line">                color: <span class="keyword">new</span> echarts.graphic.LinearGradient(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, [&#123;</span><br><span class="line">                    offset: <span class="number">0.4</span>,</span><br><span class="line">                    color: <span class="string">"#5bbdc8"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                ])</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (option &amp;&amp; <span class="keyword">typeof</span> option === <span class="string">"object"</span>) &#123;</span><br><span class="line">    myChart.setOption(option, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="四、设计与配色"><a href="#四、设计与配色" class="headerlink" title="四、设计与配色"></a>四、设计与配色</h1><p>使用了echarts和python，可视化看上去的确没有什么难度，但如果说要做出来能够放在推送上的视觉美观的作品，就不得不考虑设计和配色了。<br>首先是两个姓氏和名字的词云，大川的美工小姐姐基于原图，帮我们画了底色，让整个图案变得更鲜明。<br>其次，最初我们制作的图表的风格不统一，配色也非常混乱。在讨论后我们选择用了蓝色和黄色作为两种主色调。在这个基础上做好的图都要重新换一身衣服。当看到统一的配色的时候，风格自然地就融入在一起了。<br>关于配色当时我们参考了一些网站，包括 <a href="http://www.360doc.com/content/19/0524/11/12235645_837879925.shtml" target="_blank" rel="noopener">配色方案</a>，还有其他的一些网上常见的有RGB值的色卡，最后定下来颜色。</p>
<h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>这个可视化推送我们断断续续做了一周左右。因为我python其实不算熟，做词云、数据处理的时候是边学边做，绕了不少弯路，配色那里也是反复修改，每张图都是十几稿，词云生成了差不多三十张（笑哭）。不过总算也将一个相对成熟的可视化作品完成了，3万点击量和很多令人感动的留言真的是让人成就感满满呐。<br>还有一点我很惊讶，我司空见惯，甚至觉得有点难看的echarts，在不是计算机专业的美工看来非常稀奇，希望更多不是计算机的人也能使用这些可视化工具，如果这篇文章能有些帮助的话，那就太好了。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/">【论文精读笔记2】利用文本挖掘估计作者的出生死亡年份</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-19
        </span><span class="post-visits"
             data-url="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/"
             data-title="【论文精读笔记2】利用文本挖掘估计作者的出生死亡年份">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>这篇文章发表于TKDD，作者的主要工作是提供了一种文本挖掘的方法来估计作者的出生死亡年份。 对于一本书来说，确定它所属的年代以及它作者的身份是一项有趣的工作，其中它的引用和被引能够帮助我们解决这样的问题。 研究实验的对象主要是一些没有标注日期的希伯来语文献。通过对文本中的关键短语、关键词以及引用等信息的利用，作者提出了Heuristic(探索式）和Greedy(贪心的）定律和算法来估计一位作者的出生年份以及死亡年份。</p>
<h1 id="1-来源"><a href="#1-来源" class="headerlink" title="1.来源"></a>1.来源</h1><p>[1]Dror Moghaz,Yaakov Hacohen-Kerner,Dov Gabbay. Text Mining for Evaluating Authors’ Birth and Death Years[J]. ACM Transactions on Knowledge Discovery from Data (TKDD),2019,13(1).<br>完整版本： <a href="https://dl.acm.org/citation.cfm?doid=3301280.3281631" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?doid=3301280.3281631</a> </p>
<h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2.背景"></a>2.背景</h1><p>我们常能发现一些古籍被发现，这些古籍可能对于历史研究非常重要，我们希望知道它的作者。因此通过估计作品完成的时间，就能够推测出完成该作品的作者的人选。从另一个角度，如果知道了作者的出生和死亡年份，我们也能够推算出它的作者。<br>我们考虑古籍中不同的作者会有相互引用的关系，如果能发掘和分析这些引用，就能够实现我们的目的。这些用于挖掘时序数据的定理是基于两种引用：一种是常规的引用（没有特定词），另一种是具有特定的代表时间的词，比如”Late”(表示对提及的作者的怀念，即提及的作者已经逝世了），”Friend”，”Rabbi”等。<br>但古籍和一般的学术论文不同。在一篇学术文章中，文档具有良好的结构，想要发现关键词和关键短语更容易；同时，学术论文中的引用格式有明确的规定。对于Rabbinic Responsa( 一本古籍的名称）来说，它使用的引用在结构上比学术论文更为复杂，这就使得检索的难度增大。<br>具体地说有以下几点原因：<br>1.犹太教文本并没有类似学术论文中地的引用部分。<br>2.该文本由三种语言写成，语言的形态较多。<br>3.自然语言处理需要处理三种语言（希伯来语、阿拉姆语和意第绪语），目前的工作还没有很多进展。<br>4.许多引用是有歧义的。<br>5.引用没有标注时间。<br>6.在引用中有很多由不同的结构和语法风格组成的冗余和半结构化的数据。<br>目前对于希伯来语文本的研究目前并不算多，Mughaz使用机器学习的方法来分辨作者的写作风格。他的研究基于一系列不同时期的不同作家，这一研究的丰富性让Mughaz将他们集合在一起作为特征，得到函数。词缀集的使用是有效的，词缀时识别任务所使用的主要特征。（还有其他的一些工作在综述中，关于使用引用、用引用估计时间、关键词和信息检索的等，这里不详述了）</p>
<h1 id="3-研究过程"><a href="#3-研究过程" class="headerlink" title="3.研究过程"></a>3.研究过程</h1><h2 id="3-1-原理"><a href="#3-1-原理" class="headerlink" title="3.1 原理"></a>3.1 原理</h2><p>我们用X表示我们要估计出生/死亡年份的作家，Yi表示其余他引用或者被他引用的作家。加是我们知道所有Yi作家的生平，但并不知道X的。用B表示出生年份，D表示死亡年份，MIN表示一个作家能够开始写作的最小岁数（因为一位作家并不是生下来就会写作），MAX表示一个作家的最大寿命，RABBI_DIS表示一位犹太作家成为father的最小年龄。 MIN、MAX和RABBI_DIS的取值是需要探索的。<br>对于年份的古籍，作者提出了三种具有不同程度上的确定性的规律：Iron-rules(I)、Heuristic-rules(H)和Greedy-rules(G)。<br>Iron-rules如其名铁律，就是在任何时间都成立，Heuristic-rules在大部分的时间都成立，一些例外可能会出现，因为MAX、MIN以及RABBI_DIS这些常数的估计值会有误。 Greedy-rules 在实验中是符合的，但是仍然会导致其他文本中的出生死亡年份的估计。</p>
<h3 id="所有的I和H的公式"><a href="#所有的I和H的公式" class="headerlink" title="所有的I和H的公式"></a>所有的I和H的公式</h3><p>首先，以下是根据经验推断出的所有的I和H的公式。<br>D(X) &gt;= MAX(B(Yi))                         (0(I))<br>D(X) &gt;= MAX(B(Yi)) + MIN             (1(H))<br>B(X)&lt;= MIN(D(Yi))-MIN                  (2(H))<br>D(X)&gt;= MAX(Y)                                  (3(I))<br>D(X)&lt;= MIN(D(Yi))                            (4(I))<br>D(X)&gt;= MAX(D(Yi))                           (5(I))<br>B(X)&gt;= MAX(D(Yi))-MAX                 (6(H))<br>B(X)&gt;= MIN(B(Yi))-(MAX-MIN)      (7(H))<br>D(X)&lt;= MAX(D(Yi)) + (MAX-MIN)  (8(H)).</p>
<p>0.X引用其他人的时候，他在最年轻的被引用者出生前还没有死去。<br>1.MIN更限定了X的死亡时间 因为MIN是预估出来的人能够开始写作的时间(不是一出生就能写作的)。<br>2.X的出生日期，一定比被引用的人中最年轻的那位的死亡时间减去MIN要早。<br>3.如果在特定年限中出现了X的作品，那么他的死亡年龄必然比该年晚(或等于该年）<br>4.如果引用X的Yi中都明确地说过X去世的话 那么X的死亡时间必然比这群人中最早死去的人要早。<br>5.如果X引用Yi 其中明确提到了Yi已经逝世，那么X的死亡时间必然比这群人中最晚死去的人还晚。<br>6.一个作者的出生时间必然晚于引用他并且提到他已经死亡的其他作者中死亡时间最晚者减去MAX。<br>7. MAX和MIN的差表征的是一个作家能够进行写作的时间段。最早出生的引用X的作家出生后 X出生最多要在MAX-MIN年后（否则最早的出生的引用作家就去世了）。<br>8.X在引用他的最后一个作家死去后 不可能再活过MAX-MIN年。</p>
<h3 id="ALL函数"><a href="#ALL函数" class="headerlink" title="ALL函数"></a>ALL函数</h3><p>ALL函数是使用Iron和Heuristic函数中的所有公式结合起来的。<br>B min B = MIN ({ B’ (B ≤I (i) ∧B ≤H (i))∀ i} ).<br>B max B = MAX ({ B’ (B ≥I (i) ∧B ≥H (i))∀ i} ).<br>D min D = MIN ({ D’ (D ≤I (i) ∧D ≤H (i))∀ i} ).<br>D max D = MAX ({ D’ (D ≥I (i) ∧D ≥H (i))∀ i} ).<br>最终对年龄的估计就是B（D)的最大值和最小值的均值。</p>
<h3 id="Greedy-Constraints（-贪心约束）"><a href="#Greedy-Constraints（-贪心约束）" class="headerlink" title="Greedy Constraints（ 贪心约束）"></a>Greedy Constraints（ 贪心约束）</h3><p>B(X)&gt;= MAX(B(Yi))-MIN                     (9(G))<br>B(X)&gt;= MAX(Y)-MIN                           (10(G))<br>D(X)&lt;= MIN(D(Yi))-MIN                     (11(G))<br>X引用Yi的情况：<br>B(X)&gt;= MAX(D(Yi))-MIN                    (12(G))<br>B(X)&lt;= MIN(B(Yi)) + RABBI_DIS      (13(G))<br>B(X)&lt;= MIN(B(Yi)) + RABBI_DIS      (14(G))<br>X被Yi引用的情况：<br>D(X)&lt;= MIN(B(Yi)) + MIN                  (15(G))<br>D(X)&gt;= MAX(D(Yi))-RABBI_DIS        (16(G))<br>D(X)&gt;= MAX(D(Yi))-RABBI_DIS        (17(G))</p>
<p>9.被X提到的Yi名作家 他们中最晚出生的不能超过X可以开始写作的年龄（BX+MIN) 假设在X能够写作时，Yi名作家都还不能写作。<br>10.X能够写作的年龄不能超过他在Y年写作的年龄，假设X引用的并不都是比他小的作者。<br>11.X死亡的年份不会超过最早死的那个他引用的作者。</p>
<h3 id="Turning-Rules"><a href="#Turning-Rules" class="headerlink" title="Turning Rules"></a>Turning Rules</h3><p>如果出现计算结果是一个作家活的年纪太大或太小，或者另一个情况是作者的死亡年份大于当前年份，需要对结果进行合理化。<br>Deinition: D - death year, B - birth year, age = D-B.<br>Current Year: if (D&gt;2017) {D = 2017}, i.e., if the current year is 2017, then the algorithm cannotresult in a death year greater than 2017.<br>Age: if (age&gt;101), {z = age-101; D = D-z/2; B = B+z/2}, and if (age &lt; 30), {z = 30 - age; D =D+z/2; B = B-z/2}.<br>同时假设作者的年龄不能超过101岁，不能低于30岁。</p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>1.清洗数据。<br>2. 挖掘半结构化的引用，根据关键词确定。<br>3.将引用的格式规范化。<br>4.建立索引，计算关键词出现的频次。<br>5.使用上述的三种算法进行计算。<br>6.计算三种算法最优值的均值。</p>
<h2 id="3-2-实验"><a href="#3-2-实验" class="headerlink" title="3.2 实验"></a>3.2 实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>来自Bar-Ilan大学的Responsa项目，包括24111篇Responsa（由36位作者完成）。时间跨度为1765-2015年。这些作品包括很多引用。将这些文章按照作者数量分为了三组（12位作者组，24位作者组合36位作者组）。<br>由于分为了三组，三组的时间跨度不同，需要将结果标准化进行比较。实验用G算法，I+H算法，以及ALL函数算法对于由或者没有year-feature分别进行了实验。即每一个组需要进行六次实验。</p>
<p><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table2.png" alt></p>
<h3 id="通过实验想要解决的问题"><a href="#通过实验想要解决的问题" class="headerlink" title="通过实验想要解决的问题"></a>通过实验想要解决的问题</h3><ol>
<li>哪一种算法是最优的算法？</li>
<li>使用turning rules的manipulation的效果是什么？</li>
<li>不同的常数会造成怎样的效果？</li>
<li>结合出的ALL函数是否起了帮助？</li>
<li>ALL函数是怎么进行帮助的？</li>
</ol>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>year-feature 使用了作者写某部作品的特定年份得到的结果<br>composition 使用了turning rules以及其他常数进行估计的结果<br>constant robustness: robustness包括实验层面上的和提纯层面上的。<br>衡量算法的好坏是通过鲁棒性。<br>STDV:standard deviation 标准差，用这个衡量结果的好坏。</p>
<h2 id="3-3-结论"><a href="#3-3-结论" class="headerlink" title="3.3 结论"></a>3.3 结论</h2><p>1.从鲁棒性的角度看，Iron 算法，其次是Iron-year(有year feature的）算法，然后是G 算法，最差的是G-year算法。<br>2.当观测STDV是，ALL函数的结果具有连续性（当作者越多，STDV降低），这就意味着当我们有更多的作者信息时，一些常数的变化不会影响到最终结果。I+H算法就没有这种连续性。</p>
<p><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table3.png" alt></p>
<ol>
<li>结合table4 和5，ALL函数也明显得到了更好的结果，并且随着作者的增加，结果也在变好，STDV在降低。</li>
</ol>
<p><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table4.png" alt></p>
<p><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table5.png" alt></p>
<ol>
<li>对于Greedy算法有和没有year feature的比较，越多作家数量，估计出生年份结果越好，但估计死亡年份时，当没有使用year feature，同样具有相同的趋势，当使用了year feature时，就不具有这样的趋势了。<br><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/trend.png?" alt></li>
</ol>
<p>论文中还提出了很多结论，以上只阐述了其中的几条，整个实验的总结如下。</p>
<h3 id="整个实验的总结"><a href="#整个实验的总结" class="headerlink" title="整个实验的总结"></a>整个实验的总结</h3><p>从稳定性的角度来说，ALL函数时最好的。ALL具有连续性，当作者的数量越多，结果越好。对于估计死亡年份来说，ALL函数使用year feature的实验结果最好。对于估计出生年份来说，ALL函数没有year feature的实验结果最好。综合来看，ALL函数是最优，因为他良好的连续性、稳定性和结果质量。</p>
<h2 id="3-4-评估"><a href="#3-4-评估" class="headerlink" title="3.4 评估"></a>3.4 评估</h2><h3 id="和之前的研究的对比"><a href="#和之前的研究的对比" class="headerlink" title="和之前的研究的对比"></a>和之前的研究的对比</h3><p>table11和12显示了ALL函数相较于其他函数的提升。</p>
<p><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD//2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table1112.png" alt><br>Mughaz et al的结果比较：<br><img src="/2019/07/19/%E5%88%A9%E7%94%A8%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E4%BC%B0%E8%AE%A1%E4%BD%9C%E8%80%85%E7%9A%84%E5%87%BA%E7%94%9F%E6%AD%BB%E4%BA%A1%E5%B9%B4%E4%BB%BD/table14-16.png" alt></p>
<h3 id="未来的研究"><a href="#未来的研究" class="headerlink" title="未来的研究"></a>未来的研究</h3><ol>
<li>测试以上提出的定律的新的组合，比如说将关键词组合在一起的结果。</li>
<li>更新相应的规则，生成新的规则。</li>
<li>考虑古籍中更多的关键词，比如事件、人名等。</li>
<li>用更多的资料对算法进行探究。</li>
<li>测试为什么这几种算法会给出更多的值为正的差（预估的比实际的更高）</li>
<li>通过更改上界，测试我们还能够获得多大的提高，并将其应用于更古老的作者的语料库中。</li>
</ol>
<h1 id="4-贡献"><a href="#4-贡献" class="headerlink" title="4.贡献"></a>4.贡献</h1><ol>
<li>标准化了选取不同数量作者得到的结果，对于年龄预测结果的比较更加准确。</li>
<li>在前人研究的基础上，提出了更准确预测的算法，同时分析了算法的稳健性、对于算法中涉及到的关键词和常数的选取等。</li>
</ol>
<hr>
<p>最后一点小感想：</p>
<p>算是看的第二篇数据挖掘方面的，感觉很多还是没有完全读懂。还有一个体会是看TVCG多了，感觉再看B类的语言好像确实没有顶刊精炼（会写论文好重要啊…<br>关于算法部分，我的一个疑问在于，为什么没有给出具体的实现算法，比如说ALL函数到底是怎么计算的(遍历吗？ 作者完全没有给出一行代码。另外还有一点，我认为这篇文章的数学公式里面应该把引用和被引用两种关系区分开来，用Yi表示其他作者（不区分引用和被引用关系）使读者在阅读的时候会有一点错乱。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/07/04/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E4%BA%A4%E6%B5%81note%E6%95%B4%E7%90%86/">实验室交流note整理</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-04
        </span><span class="post-visits"
             data-url="/2019/07/04/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E4%BA%A4%E6%B5%81note%E6%95%B4%E7%90%86/"
             data-title="实验室交流note整理">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>今晚鲍芝峰老师（BAO ZHIFENG, RMIT University, Australia)到实验室交流，主要是三四个学长学姐就自己的研究问题进行了汇报，或是提出了相关问题，然后鲍老师提出了质疑、建议以及可能的解决思路。<br>我国际周选了鲍老师的一门Big Data Exploration, 上课内容还是比较令我感兴趣的, 后面有机会再详述。鲍老师第一天的课恰好让我解释一个公式的内容，对我算有一点点印象。不过我觉得他今晚在实验室里展现出来的和上课时有很大的不同。一是因为目的不同，上课毕竟是普及知识，实验室交流需要直击痛点、发现问题；二是受众不同，对于本科生，只需清晰地解释明白固定的知识，而对于研究生来说，需要快速理解他们所做的工作，同时发现问题，提出质疑和建议，相较而言更能体现出他灵活的思维和在领域中丰富的经验。<br>鲍老师提出的建议基于研究生这一层次水平，但当他在讲的时候，我也觉得很有收获，想明白了一些事，然后突然就有很想静下心来多读一些论文的冲动（假期安排上）。以下列一些今天我觉得很值得记下来的东西。</p>
<h1 id="1-要看什么论文"><a href="#1-要看什么论文" class="headerlink" title="1.要看什么论文?"></a>1.要看什么论文?</h1><p>1）大牛的，不是国内的；建立自己的排名系统 CCF分类 CORE(澳洲系统）作者要看google scholar<br>2）了解某个领域 A类会议的tutorial(类似presentation形式的survey） 从会议网站上能找到，通过读这个分类 发掘自己的工作是否具有创新性<br>3）在整场分享中提到的会议和刊物: WWW KDD NIPS ICML CVPR（图好漂亮哇） AAAI(没劲）RECSYS(推荐系统） </p>
<h1 id="2-研究问题的创新性在于？"><a href="#2-研究问题的创新性在于？" class="headerlink" title="2.研究问题的创新性在于？"></a>2.研究问题的创新性在于？</h1><p>1）问题的solution很难有创新型，创新的可以是问题，对于问题细分，定义<br>2）进行大量且充分的实验（实验的完整性，对比实验不能忽略掉重要的算法）<br>一种写论文的思路：paper 的introduction很引人入胜 solution没人能看懂<br>但是其实没必要，要让即使不是这个领域的人也能看懂文章 可以有的方式是用一个漂亮的例子，以一贯之的例子（KDD最佳论文提名）<br>3） 和其他的baseline的对比，解决了某种方法的某个缺点。</p>
<h1 id="3-Related-work有多重要？"><a href="#3-Related-work有多重要？" class="headerlink" title="3. Related work有多重要？"></a>3. Related work有多重要？</h1><p>related work很重要，要对自己要求高一些，找文献看文献要看最好的，即使是你自己的工作只能发B类，也要瞄准A类的问题和缺点，说明你的工作和别人的工作的区别。</p>
<h1 id="4-只看自己领域的文章吗？"><a href="#4-只看自己领域的文章吗？" class="headerlink" title="4. 只看自己领域的文章吗？"></a>4. 只看自己领域的文章吗？</h1><p>要拓出自己的领域。比如说如果想做可视化的推荐系统，只看可视化领域的文章相关的研究就很少，而且会因为可视化研究相似的研究思路而思维受限。一定要抛弃掉“我不这样做我就不对”的想法，要多看到不同的见解。</p>
<h1 id="5-通常可视化面临的问题是做出来一个系统发一篇文章，工作难以延展和拓宽，怎么解决？"><a href="#5-通常可视化面临的问题是做出来一个系统发一篇文章，工作难以延展和拓宽，怎么解决？" class="headerlink" title="5. 通常可视化面临的问题是做出来一个系统发一篇文章，工作难以延展和拓宽，怎么解决？"></a>5. 通常可视化面临的问题是做出来一个系统发一篇文章，工作难以延展和拓宽，怎么解决？</h1><p>完全可以把一个系统拆分成多块内容，对于底层/上层等多个模块完全可以写出一篇文章，告诉别人，这个问题是独立的问题（垂直问题） [database领域也很少有人做可视化的工作]</p>
<h1 id="6-怎么根据时长、受众调整自己的presentation？"><a href="#6-怎么根据时长、受众调整自己的presentation？" class="headerlink" title="6.怎么根据时长、受众调整自己的presentation？"></a>6.怎么根据时长、受众调整自己的presentation？</h1><p>跟导师、同学交流要进行research，跟产业界更多地交流应用。<br>可以考虑做动画。（KDD展示他们文章的youtube视频）</p>
<h1 id="7-做实验的要求？"><a href="#7-做实验的要求？" class="headerlink" title="7.做实验的要求？"></a>7.做实验的要求？</h1><p>1）严谨<br>2）最开始的时候就应该有一个实验计划，把所有想到的实验都写出来，做多少个实验，画多少幅图。<br>3）对于没办法做的实验，可以合理回避，但是需要说明为什么不能做。</p>
<h1 id="8-哪怕不是自己领域的科研交流seminar，怎么听？"><a href="#8-哪怕不是自己领域的科研交流seminar，怎么听？" class="headerlink" title="8.哪怕不是自己领域的科研交流seminar，怎么听？"></a>8.哪怕不是自己领域的科研交流seminar，怎么听？</h1><p>(大三要听seminar的tips)<br>1.要抱着主动的心态，甚至可以主动找一找讲者的错误；或者抱着想要给讲者留下印象的想法，就可以思考一下。<br>2.可以提前搞清楚讲者的研究领域，准备交流。</p>
<h1 id="9-其他零碎的东西"><a href="#9-其他零碎的东西" class="headerlink" title="9. 其他零碎的东西"></a>9. 其他零碎的东西</h1><p>1.算法真的很重要。(假期安排吧）<br>2.周报可以写自己的工作思路，开会之后要提交post meeting update，这样才体现出收获。<br>3.LaTex上手容易精通难。可以用LaTex管理自己的reference(medenley) 避免duplicate(重复的论文引用）<br>4. 我们都很有热情，想要实现出自己的想法，不想“水”，是想着要做最好的工作的。<br>5.我们的学生如果前一天知道自己要在领域内的专家面前做presentation，哪怕前一天不睡觉，也一定要做出最棒的presentation，要让领域内的专家看到最好的自己。</p>
<hr>
<p>最后要加一张图，小wy制作。<br><img src="/2019/07/04/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E4%BA%A4%E6%B5%81note%E6%95%B4%E7%90%86/%E6%80%BB%E7%BB%93.png" alt></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/">【论文精读笔记1】文物数据可视化系统调查综述</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-02
        </span><span class="post-visits"
             data-url="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/"
             data-title="【论文精读笔记1】文物数据可视化系统调查综述">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h1 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h1><p>[1]Windhager Florian,Federico Paolo,Schreder Gunther,Glinka Katrin,Dork Marian,Miksch Silvia,Mayr Eva. Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges.[J]. IEEE Transactions on Visualization and Computer graphics,2019.</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>经过数十年的现代化，网络上出现了大量的来自美术馆、图书馆、档案馆和博物馆的文化遗产藏品，数字文化遗产数据不断增加，相关学者和一般用户的访问量也不断增多。最近许多方法已经开始允许可视化地访问文化收藏，并通过交互可视化的方式将其作为复杂全面的信息空间进行解释。与传统的Web界面不同，转为文化遗产部门的藏品设计的可视化类型更具有创新型和交互的多样性。</p>
<h1 id="研究方法和贡献"><a href="#研究方法和贡献" class="headerlink" title="研究方法和贡献"></a>研究方法和贡献</h1><p>1.论文作者团队调查并回顾了数字文化遗产藏品的信息可视化方法，分析了70个文化遗产藏品的可视化系统（主要搜索包括信息视觉、视觉分析、人机交互、数字人文关系、数字艺术史和博物馆研究领域中相关期刊、出版物和会议中的作品），多角度对文化遗产藏品可视化界面设计的现状进行了研究和分析，并设计了一个<a href="http://collectionvis.org" target="_blank" rel="noopener">网站</a>来探索这个集合的可视化。</p>
<p>2.作为一个跨学科的团队，论文作者团队讨论了新的设计原则和策略，以及它们是如何解决了文化遗产藏品相关研究的挑战的。</p>
<h2 id="什么是“CH-DATA”-（文化遗产藏品数据）"><a href="#什么是“CH-DATA”-（文化遗产藏品数据）" class="headerlink" title="什么是“CH DATA”? （文化遗产藏品数据）"></a>什么是“CH DATA”? （文化遗产藏品数据）</h2><p><strong>Tangible Assets:</strong>objects, tools, artworks, building</p>
<p><strong>Intangible Assets</strong>: arts, performing arts, crafts, expressions, customs, rites…</p>
<h2 id="Visualization-of-CH-collections-文物藏品的可视化系统"><a href="#Visualization-of-CH-collections-文物藏品的可视化系统" class="headerlink" title="Visualization of CH collections 文物藏品的可视化系统"></a>Visualization of CH collections 文物藏品的可视化系统</h2><p><img src="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/image.png" alt></p>
<p>作者团队选取了70个可视化系统，其中50个来自学术文献，20个来自面向公众的文物展示平台。在选择研究可视化系统时，遵循了以下的一系列限制:</p>
<ol>
<li>focus on approaches and<br>interface designs utilize InfoVis techniques</li>
</ol>
<p>3D objects ×</p>
<p>2.<br>the search space is restricted to the culture sector</p>
<p>personal photo/music × &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scientific text documents ×</p>
<p>3.<br>focus on CH object and asset collections</p>
<p>cultural-historical entities( e.g. actors, events) ×</p>
<p><img src="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/image-1.png" alt></p>
<p>这张图片中左侧显示了所有类型的文物数据，右侧是展现了单个文物的类型以及与它相关联的其他信息，如时间、创造地点、作者、时间或是与其他文物的关联。</p>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p>作者先就所有的文物可视化系统进行了分类，一共分出了七类。</p>
<h3 id="1-Data"><a href="#1-Data" class="headerlink" title="1.Data"></a>1.Data</h3><p> 1.Object-centric approach  2.Event-centric approach </p>
<h3 id="2-Users"><a href="#2-Users" class="headerlink" title="2.Users"></a>2.Users</h3><p>Distinguish 2 classes of users: 1.Experts 2.Casual users </p>
<h3 id="3-Tasks"><a href="#3-Tasks" class="headerlink" title="3. Tasks"></a>3. Tasks</h3><p> 1.Elementary tasks 2.Synoptic tasks </p>
<h3 id="4-Granularity"><a href="#4-Granularity" class="headerlink" title="4.Granularity"></a>4.Granularity</h3><p>1.Single Object Previews </p>
<p>2.Multi-Object Previews </p>
<p>3.Collection Overviews Utilizing Discrete Surrogates </p>
<p>4.Collection Overviews Utilizing Abstractions </p>
<h3 id="5-Interactivity"><a href="#5-Interactivity" class="headerlink" title="5.Interactivity"></a>5.Interactivity</h3><p>1.Object Search</p>
<p>2.Overview and Orientation</p>
<p>3.Vertical Immersion or Abstraction </p>
<p>4.Accessing Object Details </p>
<p>5.Horizontal Exploration 6.Curated Path</p>
<h3 id="6-Temporal-Visualization-Methods"><a href="#6-Temporal-Visualization-Methods" class="headerlink" title="6.Temporal Visualization Methods"></a>6.Temporal Visualization Methods</h3><h3 id="7-Non-Temporal-Visualization-Methods"><a href="#7-Non-Temporal-Visualization-Methods" class="headerlink" title="7.Non-Temporal Visualization Methods"></a>7.Non-Temporal Visualization Methods</h3><p><img src="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/image-2.png" alt></p>
<p>最终基于这些分类呈现出了一个很大的表格。</p>
<p><img src="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/image-3.png" alt></p>
<h2 id="Survey-And-Analysis-of-The-Interface"><a href="#Survey-And-Analysis-of-The-Interface" class="headerlink" title="**Survey And Analysis of The Interface"></a>**Survey And Analysis of The Interface</h2><p><strong>1.The development of CH visualization</strong></p>
<p><img src="/2019/07/02/%E6%96%87%E7%89%A9%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0/image-4.png" alt></p>
<p><strong>2.Casual VS. Expert Use</strong></p>
<p>&nbsp;Interfaces for casual users focus more on<br>image objects **than<br>approaches for professional<br>users, and<br>often also display a thumbnail of the image itself;</p>
<p>Expert interfaces use fewer lists, grids, and tag<br>clouds than casual<br>interfaces. </p>
<p>Casual users interface should be simpler and provide few ways of visualization data</p>
<p>*<em>3.A founding *</em></p>
<p>No hybrid systems integrating InfoVis techniques with 3D rendering techniques( e.g. of real or virtual museums)</p>
<p>a particularly interesting unexplored possibility and future potential (also for VR/AR guides)</p>
<p><strong>4.Intangible CH data</strong></p>
<p>a remarkable shortage of interfaces enabling access to intangible<br>objects or practices,<br>such as<br>music, film,<br>performing arts,<br>or linguistic entities(e.g., narratives, folk tales, or<br>poems).</p>
<h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><h3 id="1-Serendipity"><a href="#1-Serendipity" class="headerlink" title="1.Serendipity"></a>1.Serendipity</h3><p>Serendipity -&gt; concept in<br>library and information sciences</p>
<p>“the faculty or phenomenon of<br>finding valuable or agreeable things not sought for”</p>
<p><strong>Options for Operationalization</strong> </p>
<p>1.emulating the serendipitous information space of a library or museum in digital CH interfaces </p>
<p>2.offer a slightly more serendipitous access in the sense that related or similar objects to the one searched for are also recommended based on existing object taxonomies or user-generated tags  </p>
<h3 id="2-Generosity"><a href="#2-Generosity" class="headerlink" title="2.Generosity"></a>2.Generosity</h3><p>provide rich and navigable representations that encourage exploration and browsing， while overviews establish context and maintain orientation during<br>access to details at<br>multiple scales.</p>
<p>playful extensions of information seeking towards less goal-oriented information activities, such as satisfying curiosity, enjoying aesthetics, and avoiding boredom</p>
<h3 id="3-criticality"><a href="#3-criticality" class="headerlink" title="3.criticality"></a>3.criticality</h3><p>criticality -&gt; reflections and design strategies, that can help to meet<br>specific epistemic</p>
<p>standards in various humanities,<br>arts, and CH communities.</p>
<p>the understanding of CH collections as <strong>dynamic entities *<em>that can be formed, re-arranged, contextualized, and annotated through innovative forms of participation can be specifically supported. Equally, *</em>InfoVis and interface design holds the potential to allow for multiple, uncertain,</strong> and sometimes even conflicting perspectives and narratives to surface. </p>
<h3 id="4-User-Guidance-and-Narration"><a href="#4-User-Guidance-and-Narration" class="headerlink" title="4.User Guidance and Narration"></a>4.User Guidance and Narration</h3><p>User<br>Guidance: Existing<br>metadata<br>of CH<br>collections often<br>support faceted browsing and recommendations<br>corresponding<br>to data dimensions</p>
<p>narrating<br>the collection:telling a story by <strong>selecting</strong>and <strong>presenting</strong><br>objects in a purposeful manner, accompanying them<br>with additional information, and even guiding<br>visitors through<br>and between exhibits</p>
<p>&nbsp; narrative<br>guidance can be implemented, for example, as animated<br>movements across a map,<br>which may<br>include different textual and visual source materials .</p>
<h3 id="5-Remote-Access-VS-Being-There"><a href="#5-Remote-Access-VS-Being-There" class="headerlink" title="5.Remote Access VS Being There"></a>5.Remote Access VS Being There</h3><p>InfoVis systems developed primarily for remote use will not<br>necessarily serve the</p>
<p>information needs (or maybe rather<br>expectations) of museum<br>visitors</p>
<p>We consider the in-situ use of exploratory interfaces and collection visualizations inreal CH exhibition settings to be a largely unexplored area of application. </p>
<h3 id="6-Facets-of-Uncertainty"><a href="#6-Facets-of-Uncertainty" class="headerlink" title="6.Facets of Uncertainty"></a>6.Facets of Uncertainty</h3><p>Uncertainty:<br>how to deal with uncertain data already belongs to<br>one of the standard<br>exercises of<br>the field </p>
<p>a lack of discussion on the same level</p>
<p>challenging metadata :“date”</p>
<p>The acknowledgment of imprecision and interpretative openness that is present in textual sources in the humanities have hardly been acknowledged in the design of CH interfaces and visualizations. </p>
<h3 id="7-Contextualization"><a href="#7-Contextualization" class="headerlink" title="7.Contextualization"></a>7.Contextualization</h3><p>Linked data is a way of publishing structured<br>data that allows<br>metadata of<br>different local databases to be connected and enriched</p>
<p>uniquely <strong>identifying</strong> entities (such as cultural artifacts, creators, institutions, places, or events) and <strong>drawing</strong> typified (e.g., temporal, spatial, contextual, and conceptual)links between them, linked data initiatives weave CH-specific knowledge graphs and relational tissues into the Semantic Web.</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/05/05/FCC-Front%20End-Basic%20Javascript-%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/">FCC-Front End-Basic Javascript-资料整理</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-05-05
        </span><span class="post-visits"
             data-url="/2019/05/05/FCC-Front%20End-Basic%20Javascript-%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"
             data-title="FCC-Front End-Basic Javascript-资料整理">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><blockquote>
<p>因为做辛卫的作业迅速入门js,但是还是感觉不太清晰，于是上fcc补了这部分，整理了一些笔记，以供参考。</p>
</blockquote>
<p>当 JavaScript 中的变量被声明的时候，程序内部会给它一个初始值 undefined。当你对一个值为 undefined 的变量进行运算操作的时候，算出来的结果将会是NaN，NaN 的意思是 “Not a Number”。当你用一个没有定义的变量来做字符串连接操作的时候，它会如实的输出”undefined”。</p>
<p><code>var a=&quot;I am a string&quot;;</code></p>
<hr>
<p>在 JavaScript 中所有的变量都是大小写敏感的。这意味着你要区别对待大写字母和小写字母。MYVAR与MyVar和myvar 是截然不同的变量。这就有可能导致多个截然不同的变量却有着有相似的名字。正是由于以上原因所以强烈地建议你, 不要 使用这一特性。（以免给自己带来麻烦）最佳实践使用 驼峰命名法 来书写一个 Javascript 变量，在 驼峰命名法 中，变量名的第一个单词的首写字母小写，后面的单词的第一个字母大写。<br>举个栗子：<br><code>var someVariable;</code><br><code>var anotherVariableName;</code><br><code>var thisVariableNameIsTooLong;</code></p>
<hr>
<p>在 JavaScript 中的 字符串 要用单引号或双引号来包裹它，只要你在开始和结束都使用相同类型的引号，单引号和双引号的功能在JavaScript中是相同的。</p>
<hr>
<p>在 JavaScript 中，当 + 操作符与 字符串 一起使用的时候，它被称作<strong>连接</strong> 操作符。你可以通过和其他字符串连接 来创建一个新的字符串。举个例子：<br><code>&#39;My name is Alan,&#39; + &#39; I concatenate.&#39;</code><br>注意空格。连接操作不会添加两个字符串之外的空格，所以想加上空格的话，你需要自己在字符串里面添加。</p>
<hr>
<p>你可以通过在字符串变量或字符串后面写上 .length 来获得字符串变量 字符串 值的长度。</p>
<hr>
<h4 id="Use-Bracket-Notation-to-Find-the-First-Character-in-a-String"><a href="#Use-Bracket-Notation-to-Find-the-First-Character-in-a-String" class="headerlink" title="Use Bracket Notation to Find the First Character in a String"></a>Use Bracket Notation to Find the First Character in a String</h4><p>[]叫中括号，{}叫大括号，()叫小括号。JavaScript中只有字符串类型，没有字符类型。那么如何获取到字符串中的某个字符呢？我们通过[索引] 来获得对应的字符。大多数现代编程语言，如JavaScript，不同于人类从1开始计数。它们是从0开始计数，这被称为 基于零 的索引。例如, 在单词 “Charles” 中索引0上的字符为 “C”，所以在 var firstName = “Charles” 中，你可以使用 firstName[0] 来获得第一个位置上的字符。</p>
<hr>
<h4 id="Understand-String-Immutability"><a href="#Understand-String-Immutability" class="headerlink" title="Understand String Immutability"></a>Understand String Immutability</h4><p>当你搞懂不可变性后,immutable.js对于你就是小菜一碟了。在 JavaScript 中，字符串 的值是 不可变的，这意味着一旦字符串被创建就不能被改变。例如，下面的代码：<code>var myStr = &quot;Bob&quot;;</code><br>myStr[0] = “J”;是不会把变量 myStr 的值改变成 “Job” 的，因为变量 myStr 是不可变的。注意，这 并不 意味着 myStr 永远不能被改变，只是字符串字面量 string literal 的各个字符不能被改变。改变 myStr 中的唯一方法是重新给它赋一个值，就像这样：<code>var myStr = &quot;Bob&quot;;</code><br><code>myStr = &quot;Job&quot;;</code></p>
<hr>
<h4 id="Word-Blanks"><a href="#Word-Blanks" class="headerlink" title="Word Blanks"></a>Word Blanks</h4><p>现在，我们来用字符串的相关知识实现一个造句函数。通过使用提供的变量参数：名词myNoun、形容词myAdjective、动词myVerb、副词myAdverb，来创建一个新的句子 result。请注意，在英文中，句中的单词是必须用空格来分隔的举个例子，如果名词为 “dog”，形容词为 “big”，动词为 “run”，副词为”quickly”，那么函数返回值为 “dog big run quickly” 就是没问题的此外，为了句子通顺，你可以在包含所有传入单词的前提下自己添加一些其他单词。对于上面的例子，函数返回值为 “That big brown dog just run quickly” 也是没问题的</p>
<hr>
<h4 id="Store-Multiple-Values-in-one-Variable-using-JavaScript-Arrays"><a href="#Store-Multiple-Values-in-one-Variable-using-JavaScript-Arrays" class="headerlink" title="Store Multiple Values in one Variable using JavaScript Arrays"></a>Store Multiple Values in one Variable using JavaScript Arrays</h4><p>使用数组，我们可以在一个地方存储多个数据。你以左方括号[开始定义一个数组，以右方括号]结束定义，并把每个条目之间用逗号隔开，就像这样：var sandwich = [“peanut butter”, “jelly”, “bread”]。任务创建一个包含 字符串 和 数字 的数组 myArray。</p>
<hr>
<p>你也可以在数组中包含其他数组，就像这样: [[“Bulls”, 23], [“White Sox”, 45]]。这被称为一个 多维数组。</p>
<hr>
<p>一个简单的方法将数据追加到一个数组的末尾是通过 push() 函数。</p>
<hr>
<p>改变数组中数据的另一种方法是用 .pop() 函数。.pop() 函数用来”抛出”一个数组末尾的值。我们可以把这个”抛出”的值赋给一个变量存储起来。数组中任何类型的条目（数值，字符串，甚至是数组）可以被”抛出来” 。举个例子, 对于这段代码</p>
<p><code>var oneDown = [1, 4, 6].pop();</code><br>现在 oneDown 的值为 6 ，数组变成了 [1, 4]。</p>
<hr>
<h4 id="Manipulate-Arrays-With-shiftpop"><a href="#Manipulate-Arrays-With-shiftpop" class="headerlink" title="Manipulate Arrays With shiftpop()"></a>Manipulate Arrays With shiftpop()</h4><p>函数用来移出数组中最后一个元素。如果想要移出第一个元素要怎么办呢？这就是 .shift() 的用武之地。它的工作原理就像 .pop()，但它移除的是第一个元素，而不是最后一个。</p>
<hr>
<p>你不仅可以 shift（移出）数组中的第一个元素，你也可以 unshift（移入）一个元素到数组的头部。.unshift() 函数用起来就像 .push() 函数一样, 但不是在数组的末尾添加元素，而是在数组的头部添加元素。</p>
<hr>
<h4 id="Write-Reusable-JavaScript-with-Functions"><a href="#Write-Reusable-JavaScript-with-Functions" class="headerlink" title="Write Reusable JavaScript with Functions"></a>Write Reusable JavaScript with Functions</h4><p>在 JavaScript 中，我们可以把代码的重复部分抽取出来，放到一个函数（functions）中。这是一个函数（function）的例子：</p>
<pre><code>function functionName() {
        console.log(&quot;Hello World&quot;);
}</code></pre><p>调用函数functionName();每次调用函数时它会打印出消息的”Hello World”到开发的控制台上。所有的大括号之间的代码将在每次函数调用时执行。</p>
<hr>
<p>函数的参数parameters在函数中充当占位符(也叫形参)的作用，参数可以为一个或多个。调用一个函数时所传入的参数为实参，实参决定着形参真正的值。简单理解：形参即形式、实参即内容。这是带有两个参数的函数， param1 和 param2：</p>
<pre><code>function testFun(param1, param2) {
             console.log(param1, param2);
}</code></pre><p>接着我们调用 testFun：testFun(“Hello”, “World”);我们传递了两个参数， “Hello” 和 “World”。在函数内部，param1 等于”Hello”，param2 等于”World”。请注意，testFun 函数可以多次调用，每次调用时传递的参数会决定形参的实际值。</p>
<hr>
<h4 id="Global-Scope-and-Functions"><a href="#Global-Scope-and-Functions" class="headerlink" title="Global Scope and Functions"></a>Global Scope and Functions</h4><p>在 JavaScript 中， 作用域 涉及到变量的作用范围。在函数外定义的变量具有 全局 作用域。这意味着，具有全局作用域的变量可以在代码的任何地方被调用。这些没有使用var关键字定义的变量，会被自动创建在全局作用域中，形成全局变量。当在代码其他地方无意间定义了一个变量，刚好变量名与全局变量相同，这时会产生意想不到的后果。因此你应该总是使用var关键字来声明你的变量。</p>
<hr>
<p>在一个函数内声明的变量，以及该函数的参数都是局部变量，意味着它们只在该函数内可见。这是在函数 myTest内声明局部变量loc 的最佳例子：</p>
<pre><code>function myTest() {
    var loc = &quot;foo&quot;;
    console.log(loc);
}
myTest(); // &quot;foo&quot;
console.log(loc); // &quot;undefined&quot;在函数外，loc 是未定义的。</code></pre><hr>
<p>一个程序中有可能具有相同名称的 局部 变量 和 全局 变量。在这种情况下，局部 变量将会优先于 全局 变量。下面为例：</p>
<pre><code>var someVar = &quot;Hat&quot;;
function myFun() {
var someVar = &quot;Head&quot;;
return someVar;
}</code></pre><p>函数 myFun 将会返回 “Head”，因为 局部变量 优先级更高。</p>
<hr>
<h4 id="Stand-in-Line"><a href="#Stand-in-Line" class="headerlink" title="Stand in Line"></a>Stand in Line</h4><p>在计算机科学中 队列（queue）是一个抽象的数据结构，队列中的条目都是有秩序的。新的条目会被加到 队列 的末尾，旧的条目会从 队列 的头部被移出。写一个函数 queue ，用一个数组arr和一个数字item作为参数。数字item添加到数组的结尾，然后移出数组的第一个元素，最后<strong>队列函数应该返回被删除的元素</strong>。</p>
<hr>
<h4 id="Understanding-Boolean-Values"><a href="#Understanding-Boolean-Values" class="headerlink" title="Understanding Boolean Values"></a>Understanding Boolean Values</h4><p>另一种数据类型是布尔（Boolean）。布尔 值要么是true 要么是false。它非常像电路开关， true是”开”，false 是”关”。这两种状态是互斥的。注意Boolean 值绝不会写作被引号包裹起来的形式。字符串的 “true” 和 “false” 不是 布尔值，在 JavaScript 中也没有特殊含义。</p>
<hr>
<h4 id="Comparison-with-the-Strict-Equality-Operator"><a href="#Comparison-with-the-Strict-Equality-Operator" class="headerlink" title="Comparison with the Strict Equality Operator"></a>Comparison with the Strict Equality Operator</h4><p><strong>严格相等运算符（===）</strong>是相对于相等操作符（==）的一种操作符。与相等操作符不同的是，它会同时比较元素的值和 数据类型。举个例子3 === 3 // true<br>3 === ‘3’ // false<br>3 是一个<strong>数字</strong>类型的，而’3’ 是一个<strong>字符</strong>类型的，所以3不全等于’3’。</p>
<hr>
<p><strong>严格不相等运算符（!==）</strong>与全等运算符是相反的。这意味着严格不相等并返回 false 的地方，用严格相等运算符会返回 true，反之亦然。严格相等运算符不会转换值的数据类型。</p>
<hr>
<p>使用大于运算符（&gt;）来比较两个数字。如果大于运算符左边的数字大于右边的数字，将会返回 true。否则，它返回 false。与相等运算符一样，大于运算符在比较的时候，会转换值的数据类型。</p>
<hr>
<p>如果你有非常多的选项需要选择，可以使用switch语句。根据不同的参数值会匹配上不同的case分支，语句会从第一个匹配的case分支开始执行，直到碰到break就结束。这是一个伪代码案例：</p>
<pre><code>switch (num) {
    case value1:
    statement1;
    break;
    case value2:
    statement2;
    break;
    ...
    case valueN:
    statementN;
    break;
}</code></pre><p>测试case 值使用严格相等运算符进行比较，break关键字告诉javascript停止执行语句。如果没有break关键字，下一个语句会继续执行。</p>
<hr>
<h4 id="Adding-a-default-option-in-Switch-statements"><a href="#Adding-a-default-option-in-Switch-statements" class="headerlink" title="Adding a default option in Switch statements"></a>Adding a default option in Switch statements</h4><p>在switch 语句中你可能无法用case来指定所有情况，这时你可以添加default语句。当再也找不到case匹配的时候default语句会执行，非常类似于if/else组合中的else语句。default语句应该是最后一个case。</p>
<pre><code>switch (num) {
    case value1:
    statement1;
    break;
    case value2:
    statement2;
    break;
    ...
    default:
    defaultStatement;
}</code></pre><hr>
<h4 id="Build-JavaScript-Objects"><a href="#Build-JavaScript-Objects" class="headerlink" title="Build JavaScript Objects"></a>Build JavaScript Objects</h4><p>你之前可能听说过对象 object 。对象和数组很相似，数组是通过索引来访问和修改数据，对象是通过属性来访问和修改数据的。这是一个示例对象：</p>
<pre><code>var cat = {
    &quot;name&quot;: &quot;Whiskers&quot;,
    &quot;legs&quot;: 4,
    &quot;tails&quot;: 1,
    &quot;enemies&quot;: [&quot;Water&quot;, &quot;Dogs&quot;]
};</code></pre><p>对象适合用来存储结构化数据，就和真实世界的对象一模一样，比如一只猫。</p>
<hr>
<h4 id="Accessing-Objects-Properties-with-the-Dot-Operator"><a href="#Accessing-Objects-Properties-with-the-Dot-Operator" class="headerlink" title="Accessing Objects Properties with the Dot Operator"></a>Accessing Objects Properties with the Dot Operator</h4><p>有两种方式访问对象属性，一个是点操作符(.)，一个是中括号操作符([])。当你知道属性的名称的时候，使用点操作符。这是一个使用点操作符读取对象属性的例子：</p>
<pre><code>var myObj = {
    prop1: &quot;val1&quot;,
    prop2: &quot;val2&quot;
};
var prop1val = myObj.prop1; // val1
var prop2val = myObj.prop2; // val2任务通过点操作符读取对象testObj，把hat的属性值赋给变量hatValue，把shirt的属性值赋给shirtValue。</code></pre><hr>
<h4 id="Accessing-Objects-Properties-with-Bracket-Notation"><a href="#Accessing-Objects-Properties-with-Bracket-Notation" class="headerlink" title="Accessing Objects Properties with Bracket Notation"></a>Accessing Objects Properties with Bracket Notation</h4><p>第二种访问对象的方式就是中括号操作符([])，如果你想访问的属性的名称有一个空格，这时你只能使用中括号操作符([])。这是一个使用中括号操作符([])读取对象属性的例子：</p>
<pre><code>var myObj = {
    &quot;Space Name&quot;: &quot;Kirk&quot;,
    &quot;More Space&quot;: &quot;Spock&quot;
};
myObj[&quot;Space Name&quot;]; // Kirk
myObj[&apos;More Space&apos;]; // Spock提示：属性名称中如果有空格，必须把属性名称用单引号或双引号包裹起来。</code></pre><hr>
<p>中括号操作符的另一个使用方式是用变量来访问一个属性。当你需要遍历对象的属性列表或查表时，这种方式极为有用。</p>
<p>这有一个使用变量来访问属性的例子：</p>
<pre><code>var someProp = &quot;propName&quot;;
var myObj = {
  propName: &quot;Some Value&quot;
}
myObj[someProp]; // &quot;Some Value&quot;</code></pre><p>还有更多：</p>
<pre><code>var myDog = &quot;Hunter&quot;;
var dogs = {
  Fido: &quot;Mutt&quot;,
  Hunter: &quot;Doberman&quot;,
  Snoopie: &quot;Beagle&quot;
}
var breed = dogs[myDog]; 
console.log(breed)// &quot;Doberman&quot;</code></pre><p>提示：当我们通过变量名访问属性的时候，不需要给变量名包裹引号。因为实际上我们使用的是变量的值，而不是变量的名称。</p>
<hr>
<p>添加可以直接添加<br>我们同样可以删除对象的属性，例如：delete ourDog.bark;</p>
<hr>
<p>对象和字典一样，可以用来存储键/值对。如果你的数据跟对象一样，你可以用对象来查找你想要的值，而不是使用switch或if/else语句。当你知道你的输入数据在某个范围时，这种查找方式极为有效。这是简单的反向字母表：</p>
<pre><code>var alpha = {
    1:&quot;Z&quot;,
    2:&quot;Y&quot;,
    3:&quot;X&quot;,
    4:&quot;W&quot;,
    ...
    24:&quot;C&quot;,
    25:&quot;B&quot;,
    26:&quot;A&quot;
};
alpha[2]; // &quot;Y&quot;
alpha[24]; // &quot;C&quot;
var value = 2;
alpha[value]; // &quot;Y&quot;</code></pre><hr>
<h4 id="Testing-Objects-for-Properties"><a href="#Testing-Objects-for-Properties" class="headerlink" title="Testing Objects for Properties"></a>Testing Objects for Properties</h4><p>有时检查一个对象属性是否存在是非常有用的，我们可以用.hasOwnProperty(propname)方法来检查对象是否有该属性。如果有返回true，反之返回 false。举例：</p>
<pre><code>var myObj = {
    top: &quot;hat&quot;,
    bottom: &quot;pants&quot;
};
myObj.hasOwnProperty(&quot;top&quot;); // true
myObj.hasOwnProperty(&quot;middle&quot;); // false任务修改函数checkObj检查myObj
是否有checkProp属性，如果属性存在，返回属性对应的值，如果不存在，返回 &quot;Not Found&quot;。</code></pre><p>注意：如果你需要通过变量来访问对象的属性值，请用中括号操作符，点操作符不支持变量。</p>
<hr>
<h4 id="Introducing-JavaScript-Object-Notation-JSON"><a href="#Introducing-JavaScript-Object-Notation-JSON" class="headerlink" title="Introducing JavaScript Object Notation JSON"></a>Introducing JavaScript Object Notation JSON</h4><p>JavaScript Object Notation 简称 JSON，它使用JavaScript对象的格式来存储数据。JSON是灵活的，因为它允许 数据结构 是 字符串，数字，布尔值，字符串，和 对象 的任意组合。这里是一个JSON对象的示例：</p>
<pre><code>var ourMusic = [
{
    &quot;artist&quot;: &quot;Daft Punk&quot;,
    &quot;title&quot;: &quot;Homework&quot;,    
    &quot;release_year&quot;: 1997,
    &quot;formats&quot;: [
            &quot;CD&quot;,
            &quot;Cassette&quot;,
            &quot;LP&quot; ],
    &quot;gold&quot;: true
}
];</code></pre><p>这是一个对象数组，并且对象有各种关于专辑的 详细信息。它也有一个嵌套的 formats 的数组。附加专辑记录可以被添加到数组的最上层。提示<br>数组中有多个 JSON 对象的时候，对象与对象之间要用逗号隔开。</p>
<hr>
<h4 id="Accessing-Nested-Objects-in-JSON"><a href="#Accessing-Nested-Objects-in-JSON" class="headerlink" title="Accessing Nested Objects in JSON"></a>Accessing Nested Objects in JSON</h4><p>通过串联起来的点操作符或中括号操作符来访问JSON对象的嵌套属性。下面是一个嵌套的JSON对象：</p>
<pre><code>var ourStorage = {
    &quot;desk&quot;: {
       &quot;drawer&quot;: &quot;stapler&quot;
    },
    &quot;cabinet&quot;: {
        &quot;top drawer&quot;: {
            &quot;folder1&quot;: &quot;a file&quot;,
            &quot;folder2&quot;: &quot;secrets&quot;
            },
        &quot;bottom drawer&quot;: &quot;soda&quot;
        }
    }
ourStorage.cabinet[&quot;top drawer&quot;].folder2; // &quot;secrets&quot;
ourStorage.desk.drawer; // &quot;stapler&quot;</code></pre><hr>
<p>正如我们在前面的例子所见，JSON对象可以嵌套对象和数组。与访问嵌套对象一样，用中括号操作符同样可以访问嵌套数组。下面是如何访问嵌套数组的例子：</p>
<pre><code>var ourPets = {
      &quot;cats&quot;: [
            &quot;Meowzer&quot;,
            &quot;Fluffy&quot;,
            &quot;Kit-Cat&quot;
            ],
      &quot;dogs&quot;: [
            &quot;Spot&quot;,
            &quot;Bowser&quot;,
            &quot;Frankie&quot;
        ]
};
ourPets.cats[1]; // &quot;Fluffy&quot;
ourPets.dogs[0]; // &quot;Spot&quot;</code></pre><hr>
<h4 id="Iterate-with-JavaScript-For-Loops"><a href="#Iterate-with-JavaScript-For-Loops" class="headerlink" title="Iterate with JavaScript For Loops"></a>Iterate with JavaScript For Loops</h4><p>一个条件语句只能执行一次代码，而一个循环语句可以多次执行代码。JavaScript 中最常见的循环就是”for循环”。for循环中的三个表达式用分号隔开：for ([初始化]; [条件判断]; [计数器])初始化语句只会在执行循环开始之前执行一次。它通常用于定义和设置你的循环变量。条件判断语句会在每一轮循环的开始执行，只要条件判断为 true 就会继续执行循环。当条件为 false的时候，循环将停止执行。这意味着，如果条件在一开始就为 false，这个循环将不会执行。计数器是在每一轮循环结束时执行，通常用于递增或递减。在下面的例子中，先初始化i = 0，条件 i &lt; 5 为真，进入第一次循环，执行大括号里的代码，第一次循环结束。递增i的值，条件判断，就这样依次执行下去，直到条件判断为假，整个循环结束。</p>
<pre><code>var ourArray = [];
for (var i = 0; i &lt; 5; i++) {
ourArray.push(i);
}</code></pre><p>最终 ourArray 的值为 [0,1,2,3,4].</p>
<hr>
<h4 id="Nesting-For-Loops"><a href="#Nesting-For-Loops" class="headerlink" title="Nesting For Loops"></a>Nesting For Loops</h4><p>如果你有一个二维数组，可以使用相同的逻辑，先遍历外面的数组，再遍历里面的子数组。下面是一个例子：</p>
<pre><code>var arr = [
[1,2], [3,4], [5,6]
];
for (var i=0; i &lt; arr.length; i++) {
    for (var j=0; j &lt; arr[i].length; j++) {
        console.log(arr[i][j]);
}
}</code></pre><p>一次输出 arr 中的每个子元素。提示，对于内部循环，我们可以通过 arr[i] 的 .length 来获得子数组的长度，因为 arr[i] 的本身就是一个数组。</p>
<hr>
<h4 id="Generate-Random-Fractions-with-JavaScript"><a href="#Generate-Random-Fractions-with-JavaScript" class="headerlink" title="Generate Random Fractions with JavaScript"></a>Generate Random Fractions with JavaScript</h4><p>计算机的行为只有两种：确定性和随机性。当你一步步地闯关来到这里就是确定行为，当你随意点了个链接就来到这里就是随机行为。而随机数最适合用来创建这种随机行为。Math.random()用来生成一个在0(包括0)到1(不包括1)之间的随机小数，因此Math.random()可能返回0但绝不会返回1。提示<br>随后的函数都会在return执行前调用，所以我们可以直接返回Math.random()的值。任务更改myFunction 来生成一个随机数取代 0。</p>
<hr>
<h4 id="Sift-through-Text-with-Regular-Expressions"><a href="#Sift-through-Text-with-Regular-Expressions" class="headerlink" title="Sift through Text with Regular Expressions"></a>Sift through Text with Regular Expressions</h4><p>Regular expressions 正则表达式被用来根据某种匹配模式来寻找strings中的某些单词。</p>
<p>举例：如果我们想要找到字符串The dog chased the cat中单词 the，我们可以使用下面的正则表达式: /the/gi<br>我们可以把这个正则表达式分成几段：<br>/ 是这个正则表达式的头部<br>the 是我们想要匹配的模式<br>/ 是这个正则表达式的尾部<br>g 代表着 global(全局)，意味着返回所有的匹配而不仅仅是第一个。<br>i 代表着忽略大小写，意思是当我们寻找匹配的字符串的时候忽略掉字母的大小写。</p>
<hr>
<h4 id="Find-Numbers-with-Regular-Expressions"><a href="#Find-Numbers-with-Regular-Expressions" class="headerlink" title="Find Numbers with Regular Expressions"></a>Find Numbers with Regular Expressions</h4><p>我们可以在正则表达式中使用特殊选择器来选取特殊类型的值。特殊选择器中的一种就是数字选择器\d，意思是被用来获取一个字符串的数字。在JavaScript中, 数字选择器类似于: /\d/g。在选择器后面添加一个加号标记(+)，例如：/\d+/g，它允许这个正则表达式匹配一个或更多数字。尾部的g是’global’的简写，意思是允许这个正则表达式 找到所有的匹配而不是仅仅找到第一个匹配。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/05/02/%E7%9F%A5%E8%AF%86%EF%BC%9AWhy%E5%92%8C%E6%9C%AA%E4%B8%B2%E5%A5%BD%E7%9A%84%E9%A1%B9%E9%93%BE/">知识："Why"和未串好的项链</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-05-02
        </span><span class="post-visits"
             data-url="/2019/05/02/%E7%9F%A5%E8%AF%86%EF%BC%9AWhy%E5%92%8C%E6%9C%AA%E4%B8%B2%E5%A5%BD%E7%9A%84%E9%A1%B9%E9%93%BE/"
             data-title="知识："Why"和未串好的项链">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><h3 id="“规律”"><a href="#“规律”" class="headerlink" title="“规律”"></a>“规律”</h3><hr>
<p>这个世界的发展不是随机的。目前的我认为，世界的演变是由一系列的因果组成的。就像函数的映射，原因映射到结果。而目前呈现的状态是由无数的参数经过某种映射关系得到的结果。计算理论告诉我，由一个状态变为另一个状态，需要有一个转移函数。那么世界当前的状态，可能是由一个接受前一个状态的转移函数通过计算而得到的。</p>
<p>&nbsp;</p>
<p>或许存在一个答案，或者一个公式，是宇宙的运行的依据，或者那种东西可以称之为”道”。而这个道，人类还没有完全抓住，完全理解。而道本身从何而来，为何产生，那就是更高阶的问题，更不可能回答。”道”就是宇宙的转移函数。</p>
<p>&nbsp;</p>
<p>而我之所以是我，没有变成其他的样子，没有思考到别的东西，是由这个规律决定的，或者可以说，从出生，甚至出生之前的时间，都决定了我的存在。我认为是有更高的意志无形地在统治这个世界，同时也统治着我，但是这种统治我无法感知， 也无法证明它的存在。很多时候，我以为是我自己的思考，主观意识在决定我的行动，但其实我现在的状态可能也只是宇宙的那个终极的公式计算出来的产物。</p>
<p>&nbsp;</p>
<p>按照这种想法，所有的一切都不需要感到奇怪，包括阴暗的、变态的、丑陋的、邪恶的一切，因为所有的东西都是”合理”的，也就是说，终极函数计算出的结果，是准确的。</p>
<p>&nbsp;</p>
<h3 id="“好奇心”"><a href="#“好奇心”" class="headerlink" title="“好奇心”"></a>“好奇心”</h3><hr>
<p>人类的美妙之处，在于好奇心。我们人类有源源不断的好奇心，这让我们去思考，我们看到苹果掉下来，看到日月星辰的变化，看到高高低低的豌豆，但我们没有忽略它们。我们提出了很多很多的”为什么”，而同时也不断回答着为什么。</p>
<p>&nbsp;</p>
<p>科学的发展，就像是无数好奇心旺盛的人类在试图破解那个统治世界的”规律”。只是那个规律太大，太复杂，于是我们把它不断拆解、细分，分出不同的学科和领域，在领域里，甚至还加上很多的限定。靠着实验和现象，或者猜想和假设，我们推理出很多适用在小范围内的规律。</p>
<p>&nbsp;</p>
<p>人类科学家们就像是一群裁缝，世界的”规律”就像是一串完美又巨大的项链，而为了完成这串项链，目前科学家的工作，仅仅是将找到的珠子进行了排列。他们发现有些珠子之间还缺少着很多颗珠子，因此串珠子的工作根本无法开始。</p>
<p>&nbsp;</p>
<p>这是一项艰巨的工作，好在我们还有”好奇心”，向未知发问的能力我们不会丧失，即使越来越多的人失去，但火种还在， 尽管是微弱的光，我认为光还是在。</p>
<p>&nbsp;</p>
<h3 id="“存在”"><a href="#“存在”" class="headerlink" title="“存在”"></a>“存在”</h3><hr>
<p>我记得大概是五岁的时候，我突然对这个世界的存在产生了怀疑。为什么我能看见所有的颜色；为什么我能听见妈妈的声音或者电视机里传来的声音；为什么我会有意识，为什么我会存在。这种感觉给我带来一种超脱感和异常感。然而我慢慢地接受了，也就再也没有想过这样的问题。</p>
<p>&nbsp;</p>
<p>而随着年龄的增大，”为什么我会存在”这种问题，逐步转变为，”我存在是为了什么。” 我曾经的想法是，存在的意义在于体验。我所经历的一切都可以被称之为体验。但是这个回答不太能让我满足，”体验”之后呢？</p>
<p>&nbsp;</p>
<p>“体验”之后的东西太虚无了。我记得我在某个晚上突然想到，人是一个导管，苦乐流过，导管在这个过程中的颜色，形状都发生了改变，而最后，当时间河流停滞，我们这样的改变又有什么意义呢？仅仅如此吗？</p>
<p>&nbsp;</p>
<h3 id="“意义”"><a href="#“意义”" class="headerlink" title="“意义”"></a>“意义”</h3><hr>
<p><span data-tt="{}">追求知识的人们是在干什么呢？探索答案的人们是在干什么呢？我们人类是要干什么呀？我们存在于此是要为什么呀？</span></p>
<p>&nbsp;</p>
<p>是为了想要学习从未认识到的东西，<span data-tt="{}">是为了解答所有内心深处的”为什么”，是为了满足我们最原初的好奇心，是为了最终能够串起那串代表着世界的终极规律的项链。因此，</span><span data-tt="{}">存储在数据库的所有论文，所有的书籍，所有用英文用中文用各种各样的语言写成的东西，所有的信息，所有能被数据保存下来的东西，都是排列好的小部分珠子。</span></p>
<p>&nbsp;</p>
<p>我们想要<span data-tt="{}">弄懂这个宇宙运行的规律。</span></p>
<p>&nbsp;</p>
<p><span data-tt="{}">弄懂这个世界。</span></p>
<p>&nbsp;</p>
<p>我记得的大学里最美的一个场景，就是我走在一教A的走廊，当时两边的教室里都在上课，只言片语间，我仿佛置身于一条河流，不由自主地感觉到幸福和平静。尽管我不清楚每一间教室里讲的具体内容，但是我看见了那些前人所发现并排列好的珠子闪烁的光彩。</p>
<p>&nbsp;</p>
<p>如果从很大的层面来看，现在的我认为，人类的意义在于发现这个世界的规律。而对于个体来说，能够做的事情就是在串珠子这项工作中，再进行一些珠子的排列，这或许就是所谓”意义”。</p>
<p>&nbsp;</p>
<h3 id="“科学”"><a href="#“科学”" class="headerlink" title="“科学”"></a>“科学”</h3><hr>
<p>什么是科学？先前我说，这个世界是存在一个终极规律的，而科学就是发现这个终极规律的子集的过程。</p>
<p>&nbsp;</p>
<p>如果细分来说，科学又分为自然科学和人文科学。</p>
<p>&nbsp;</p>
<p>之前和LZX聊到科学的时候，我提到实验室学长分享的论文，有跟她说到终极规律这个问题。但是她说我们以为的因果关系很可能并不成立，我想到如果是自然科学依赖因果性推出的结论，很可能就根本不是正确的。而同时，对Humanities的短暂接触和阅读，也让我认同她说的，人文学科是建立在假设和猜想上的，它承认了它本身的主观性和不可靠。</p>
<p>&nbsp;</p>
<p>而某种程度上，我一直信仰的自然科学，或许根本就是一种宗教也不一定。依靠现想和推理产生的理论，正确率如我所想象的高吗？（这个问题我还没有想清楚，还是先读书叭）</p>
<p>而会不会还有一种可能，就是想得悲观一些，可能当我们终于串好了这串珠子，拿到上帝面前，去问他终极的规律究竟是什么的时候，他或许否认了终极规律的存在，或许答案就是一片混沌或是虚无的存在。（就像lulu之前讲过的上帝和科学家得故事，我们明白了事物的”为什么”，但是无法解答”为什么”本身的存在原因。）</p>
<p>&nbsp;</p>
<p>不过我首先会认为这串珠子很难串得好啦。</p>
<p>&nbsp;</p>
<p>再说到人文学科，我现在觉得它的研究范畴和我曾经以为的有很大不同。文学理论研究者费尽心思地去研究某个作者，某部作品，绝不是什么”无用之学”，我认为是在研究人的思想，人的精神，人的本质的演变过程，看起来是在研究他人，实际上是在研究我们自己。如果说自然科学更多的是向外研究，那么人文社科其实是在对内，向内去探索。</p>
<p>&nbsp;</p>
<h3 id="“时间线”"><a href="#“时间线”" class="headerlink" title="“时间线”"></a>“时间线”</h3><hr>
<p>周四学长分享的论文，是<span data-tt="{}">通过分析不同学生的学习规划（选的课、发的paper、参加的活动）以及最后的职业，当学生想要达到不同目标时能够基于之前的时间事件序列给出推荐的路线。</span></p>
<p>&nbsp;</p>
<p><span data-tt="{}">每个人的时间事件序列就是一条线，然后沿着那条线往前，自然而然就会得到某种结果。这是”终极规律”决定的。然后我就想，如果真的能够把所有的人的时间线都收集起来，进行处理，是不是可能实现个人的最优时间线推荐呢？我想要达到这样的目标，那么我就按照这样的时间线去进行就好了？</span></p>
<p>&nbsp;</p>
<p>这听上去很理性，科学，计算机。所谓”人生路径推荐系统”这样的东西，或许真的有可能实现吧。不过要想实现这样的机器，还是需要弄懂”规律”，难就难在是要弄懂一些难以量化的、向内的、充满主观性的规律。（这已经是人文学科的范畴了，因此用主观的方法去研究，本身就很难统一发现的规律）</p>
<p>&nbsp;</p>
<h3 id="“和解”"><a href="#“和解”" class="headerlink" title="“和解”"></a>“和解”</h3><hr>
<p>不过对于时间线的思考终究还是有它的意义。我感觉我终于慢慢地和自己和解了。</p>
<p>&nbsp;</p>
<p><span data-tt="{}">由于实时性，我们能看见所有人在当下的状态，却不能知道他的整个时间线。看见了同时刻的人的优秀，十分浮躁。但是想想如果按照时间线的逻辑，我在我的时间线里本应该潜心输入的时候却在羡慕别人时间线他们的输出，反而没把自己的时间线做好。</span></p>
<p>&nbsp;</p>
<p>我时而想起高中。那个搞化竞眼睛发光的人，我再也没有在大学里看到那样的人，可能有些人的气质跟他相近，但也没有他那样的热情和执着；那是就很羡慕周围的同学，自己暗暗地躲在小角落里，或者去图书馆找书看；最开心的时候就是跟同桌严肃地讨论人生观价值观，而我也再没有在大学和周围人那么深入地探讨过无关情感的思考（现在比较严肃的是在讨论婚姻观、LGBT啥的）。</p>
<p>&nbsp;</p>
<p>但是我终于渐渐不因为自己菜而失落。尽管包含着对知识的热爱，但是也明白自己的能力可能找不到珠子。但是还是会把这个视为追求，努力去实现。</p>
<p>&nbsp;</p>
<p>世界仍是未知的，为了解答”why？”, 找到珠子，我们要掌握到尽可能多的已知的珠子。而终极规律是否存在，也是要等到我们基本上串完项链之后再说吧。</p>
<p>&nbsp;</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><hr>
<p>事实上，我觉得探索自己的内心和他人的关系，其实也是在找珠子，只不过那样的珠子没有被严肃地记录下来，但他们终究是智慧。</p>
<p>&nbsp;</p>
<p>比如说恋爱可能也是一种找珠子的过程，你在这一过程中不断地认识自己，你发现了适用于两个人范围之间的规律，但其实你并不会把它以理论形式记录下来，而是实实在在地运用于生活，这就很好。（我还是想谈恋爱，因为想找到那个珠子，所以想脱单是因为好奇心：）</p>
<p>&nbsp;</p>
<p>但是当见识广了，找到想要发现的珠子所在的区域之后，这些生活上的小珠子带给我的好奇心，相比之下就没有那么大了。</p>
<p>&nbsp;</p>
<p>哎我竟然还有好多想写的，等我多读点书，应该就会又有不一样的思考吧，这时间段的思考先记录于此。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/04/22/%E4%BB%8E%E5%81%9C%E6%9C%BA%E9%97%AE%E9%A2%98%E5%88%B0%E4%B8%8D%E5%8F%AF%E7%9F%A5%E8%AE%BA/">从停机问题到不可知论</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-22
        </span><span class="post-visits"
             data-url="/2019/04/22/%E4%BB%8E%E5%81%9C%E6%9C%BA%E9%97%AE%E9%A2%98%E5%88%B0%E4%B8%8D%E5%8F%AF%E7%9F%A5%E8%AE%BA/"
             data-title="从停机问题到不可知论">
          阅读次数 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>你被关在在一个房间里，房间里挤满了很多台机器。对于你眼前的一台机器P，有一个小矮人坐在机器前，不断地向机器里敲打着序列，这时机器大声地喊了一句”hello world!”，说明条件满足了 。如果机器没有动静，说明输入的序列并不满足让它大喊的条件。对于每一台机器来说，它们满足的条件各不相同。</p>
<p>我告诉你，你的任务是，造出一台超级机器，这样你才能够出去。这台机器我要求对于房间里任意的一台机器和对应的输入，如果这台机器能够喊出”hello world”， 那么超级机器就会说”yes”, 如果这台机器不能”hello world”， 那么超级机器就会说”no”。</p>
<p>这看起来是个很简单的任务，因为超级机器只需要判断其他机器能不能喊”hello world”就可以了。这时候，我又对你提出了新的要求：”如果超级机器判断的机器没有喊’hello world’ ，那就让这台超级机器代替它喊一句’hello world’。”</p>
<p>好像和之前的任务也没什么差别，只是改变了喊话的内容而已。</p>
<p>现在我告诉你，对于某一台机器来说，你输入的序列，也完全可以是那台机器本身。什么意思呢，其实说到底，这里说的机器并不是实际存在的东西，而是一串序列，这听上去有一点恐怖，你能够把机器编成一串序列，让小矮人把这个序列敲到机器里。</p>
<p>总之，小矮人们不太情愿地把这个序列敲进了机器，对于机器接下来会怎么样，小矮人也不清楚。但这时候你会发现，有些机器发出了”hello world”， 有些机器十分安静。说”hello world” 或是不说，就这两种结果。</p>
<p>对于超级机器来说，你大概发现了，这台机器至少要有两个输入，也就是说，一个小矮人输入的是你要判断能不能发出”hello world” 的那台机器（所代表的序列P），而另一个小矮人要输入你要输入到待判断的机器里的那个序列I。</p>
<p>但是现在我说，没必要再找两个小矮人，直接让你来，输入的序列就是机器代表的序列，不需要输入I了，机器也不需要有两个输入口，一个就够了。相当于说，之前说的两个输入，都是机器代表的序列P。你会输入两次机器代表的序列P，但是，鉴于这台超级机器只有一个输入，那么当你第一次输入P时，这台只由你控制的机器也会有一个输出，也就是说，当你输入P的时候，这台超级机器也有可能因为满足它自身的条件而大喊”hello world”。</p>
<p>我想你可能也想不出来这样的机器要怎么做，但总之，我指着角落的一台机器，告诉你，其实那台机器就是超级机器。我让你过去，并且我告诉了你超级机器所代表的序列。</p>
<p>“输入吧。” 我说。</p>
<p>你开始敲打超级机器代表的序列，就像把超级机器自己塞进了自己的输入口里。</p>
<p>但最终你发现了，我骗了你，那台机器根本就不是超级机器。</p>
<p>如果这台超级机器，输入自己的序列，喊出了”hello world”， 那么根据最开始定义的规则，它会喊出”yes”, 而如果这台超级机器输入自己的序列并没有发出声音，按照定义，它输入的机器没有喊出”hello world”的时候，它会代替输入的机器，喊出”hello world”。</p>
<p>这根本不可能，超级机器根本没办法造出来。就是这样，你没法逃出房间。</p>
<hr>
<p>今天计算理论讲了停机问题，感觉非常有意思，于是写了一个小故事，尽可能简单地解释出这一构造的巧妙性，但是可能会有交代不清的地方，欢迎指正~</p>
<p>另外，关于停机问题，老师还扯到了很多有意思的东西，非常之”哲学”。</p>
<p>比如说，如果故事里的机器是杀毒软件的话，其实可以发现，杀毒软件是不能够检测出所有的病毒的，因为它不能知道自己是不是就是病毒（细思极恐）。而且停机问题的推导其实涉及到了一种自我指涉的矛盾。说到”自我”，其实就会发现，按照这样的逻辑，一个人是无法完全认识自己的，或者说一个人是无法完全理解自身的。</p>
<p>如果故事里的机器是我们的脑子，用我们的脑子去研究我们的脑子，其实就会有不能够认识到的地方。脑子是研究的主体，也是研究的客体；就像机器作为程序，但同时又作为程序的输入，而这时候你是不能认识到机器的输出的，所以你其实不能认识到这种脑子研究脑子的正确性甚至是可行性。所以说这就某种程度上支持了不可知论。</p>

        </div></article>
      <nav class="pagination"></nav></section></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/ahonn" target="_blank" rel="noopener" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2021<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Ruoting Wu</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
